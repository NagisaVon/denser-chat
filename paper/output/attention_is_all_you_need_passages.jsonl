{"page_content": "Provided proper attribution is provided, Google hereby grants permission to reproduce the tables and figures in this paper solely for use in journalistic or scholarly works. Attention Is All You Need Ashish Vaswani ∗ Google Brain avaswani@google.com Noam Shazeer ∗ Google Brain noam@google.com Niki Parmar ∗ Google Research nikip@google.com Jakob Uszkoreit ∗ Google Research usz@google.com Llion Jones ∗ Google Research llion@google.com Aidan N. Gomez ∗† University of Toronto aidan@cs.toronto.edu Łukasz Kaiser ∗ Google Brain lukaszkaiser@google.com Illia Polosukhin ∗‡ illia.polosukhin@gmail.com Abstract The dominant sequence transduction models are based on complex recurrent or convolutional neural networks that include an encoder and a decoder. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions", "metadata": {"source": "../paper/attention_is_all_you_need.pdf", "title": "", "pid": "0", "annotations": "[{\"page\": 0, \"x\": 124.66600036621094, \"y\": 706.6775741577148, \"width\": 362.67295837402344, \"height\": 14.406021118164062, \"color\": \"#FFFF00\"}, {\"page\": 0, \"x\": 124.31300354003906, \"y\": 692.7305526733398, \"width\": 363.5814971923828, \"height\": 14.406021118164062, \"color\": \"#FFFF00\"}, {\"page\": 0, \"x\": 267.593994140625, \"y\": 678.7825546264648, \"width\": 78.90432739257812, \"height\": 14.406021118164062, \"color\": \"#FFFF00\"}, {\"page\": 0, \"x\": 211.48800659179688, \"y\": 624.0865173339844, \"width\": 188.40548706054688, \"height\": 22.397232055664062, \"color\": \"#FFFF00\"}, {\"page\": 0, \"x\": 132.9080047607422, \"y\": 545.9077453613281, \"width\": 66.89883422851562, \"height\": 12.961349487304688, \"color\": \"#FFFF00\"}, {\"page\": 0, \"x\": 199.8070068359375, \"y\": 546.2879028320312, \"width\": 4.0796661376953125, \"height\": 12.085586547851562, \"color\": \"#FFFF00\"}, {\"page\": 0, \"x\": 139.37899780273438, \"y\": 535.5964965820312, \"width\": 53.957427978515625, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 0, \"x\": 116.68099975585938, \"y\": 523.9004516601562, \"width\": 99.37687683105469, \"height\": 11.935211181640625, \"color\": \"#FFFF00\"}, {\"page\": 0, \"x\": 239.06199645996094, \"y\": 545.9077453613281, \"width\": 61.69844055175781, \"height\": 12.961349487304688, \"color\": \"#FFFF00\"}, {\"page\": 0, \"x\": 300.760009765625, \"y\": 546.2879028320312, \"width\": 4.079681396484375, \"height\": 12.085586547851562, \"color\": \"#FFFF00\"}, {\"page\": 0, \"x\": 242.9320068359375, \"y\": 535.5964965820312, \"width\": 53.9573974609375, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 0, \"x\": 230.69200134277344, \"y\": 523.9004516601562, \"width\": 78.45558166503906, \"height\": 11.935211181640625, \"color\": \"#FFFF00\"}, {\"page\": 0, \"x\": 338.6920166015625, \"y\": 545.9077453613281, \"width\": 53.857818603515625, \"height\": 12.961349487304688, \"color\": \"#FFFF00\"}, {\"page\": 0, \"x\": 392.54901123046875, \"y\": 546.2879028320312, \"width\": 4.079681396484375, \"height\": 12.085586547851562, \"color\": \"#FFFF00\"}, {\"page\": 0, \"x\": 331.4540100097656, \"y\": 535.5964965820312, \"width\": 68.33346557617188, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 0, \"x\": 323.7870178222656, \"y\": 523.9004516601562, \"width\": 83.68603515625, \"height\": 11.935211181640625, \"color\": \"#FFFF00\"}, {\"page\": 0, \"x\": 424.3000183105469, \"y\": 545.9077453613281, \"width\": 68.83160400390625, \"height\": 12.961349487304688, \"color\": \"#FFFF00\"}, {\"page\": 0, \"x\": 493.1310119628906, \"y\": 546.2879028320312, \"width\": 4.079681396484375, \"height\": 12.085586547851562, \"color\": \"#FFFF00\"}, {\"page\": 0, \"x\": 424.54901123046875, \"y\": 535.5964965820312, \"width\": 68.33346557617188, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 0, \"x\": 422.11199951171875, \"y\": 523.9004516601562, \"width\": 73.22528076171875, \"height\": 11.935211181640625, \"color\": \"#FFFF00\"}, {\"page\": 0, \"x\": 144.2919921875, \"y\": 495.9107360839844, \"width\": 48.84660339355469, \"height\": 12.961334228515625, \"color\": \"#FFFF00\"}, {\"page\": 0, \"x\": 193.13800048828125, \"y\": 496.2908935546875, \"width\": 4.0796661376953125, \"height\": 12.085601806640625, \"color\": \"#FFFF00\"}, {\"page\": 0, \"x\": 134.54800415039062, \"y\": 485.5994873046875, \"width\": 68.33348083496094, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 0, \"x\": 126.88200378417969, \"y\": 473.9024353027344, \"width\": 83.685791015625, \"height\": 11.935211181640625, \"color\": \"#FFFF00\"}, {\"page\": 0, \"x\": 248.76100158691406, \"y\": 495.9107360839844, \"width\": 70.56517028808594, \"height\": 12.961334228515625, \"color\": \"#FFFF00\"}, {\"page\": 0, \"x\": 319.32598876953125, \"y\": 496.2908935546875, \"width\": 10.95587158203125, \"height\": 12.085601806640625, \"color\": \"#FFFF00\"}, {\"page\": 0, \"x\": 244.57498168945312, \"y\": 485.5994873046875, \"width\": 86.24615478515625, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 0, \"x\": 235.406982421875, \"y\": 473.9024353027344, \"width\": 104.60748291015625, \"height\": 11.935211181640625, \"color\": \"#FFFF00\"}, {\"page\": 0, \"x\": 394.125, \"y\": 495.9107360839844, \"width\": 61.718353271484375, \"height\": 12.961334228515625, \"color\": \"#FFFF00\"}, {\"page\": 0, \"x\": 455.8420104980469, \"y\": 496.2908935546875, \"width\": 4.079681396484375, \"height\": 12.085601806640625, \"color\": \"#FFFF00\"}, {\"page\": 0, \"x\": 398.0050048828125, \"y\": 485.5994873046875, \"width\": 53.9573974609375, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 0, \"x\": 364.8489990234375, \"y\": 473.9034423828125, \"width\": 120.28872680664062, \"height\": 11.935211181640625, \"color\": \"#FFFF00\"}, {\"page\": 0, \"x\": 268.8070068359375, \"y\": 445.9127502441406, \"width\": 67.07818603515625, \"height\": 12.961334228515625, \"color\": \"#FFFF00\"}, {\"page\": 0, \"x\": 335.8840026855469, \"y\": 446.2939147949219, \"width\": 10.95587158203125, \"height\": 12.085601806640625, \"color\": \"#FFFF00\"}, {\"page\": 0, \"x\": 238.02200317382812, \"y\": 434.814453125, \"width\": 135.97979736328125, \"height\": 11.935211181640625, \"color\": \"#FFFF00\"}, {\"page\": 0, \"x\": 283.75799560546875, \"y\": 393.14227294921875, \"width\": 44.48529052734375, \"height\": 15.5537109375, \"color\": \"#FFFF00\"}, {\"page\": 0, \"x\": 143.5570068359375, \"y\": 368.2355041503906, \"width\": 324.742431640625, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 0, \"x\": 143.86599731445312, \"y\": 357.3265075683594, \"width\": 324.2649230957031, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 0, \"x\": 143.86599731445312, \"y\": 346.4175109863281, \"width\": 324.26495361328125, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 0, \"x\": 143.86599731445312, \"y\": 335.5085144042969, \"width\": 325.5147399902344, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 0, \"x\": 143.86599731445312, \"y\": 324.5994873046875, \"width\": 324.2701721191406, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}]"}, "type": "Document"}
{"page_content": "entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English- to-German translation task, improving over the existing best results, including ensembles, by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data. ∗ Equal contribution. Listing order is random. Jakob proposed replacing RNNs with self-attention and started the effort to evaluate this idea. Ashish, with Illia, designed and implemented the first Transformer models and", "metadata": {"source": "../paper/attention_is_all_you_need.pdf", "title": "", "pid": "1", "annotations": "[{\"page\": 0, \"x\": 143.86599731445312, \"y\": 313.69049072265625, \"width\": 324.2647705078125, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 0, \"x\": 143.86599731445312, \"y\": 302.781494140625, \"width\": 324.6148376464844, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 0, \"x\": 143.86599731445312, \"y\": 291.87249755859375, \"width\": 325.9211730957031, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 0, \"x\": 143.86599731445312, \"y\": 280.9624938964844, \"width\": 324.2648010253906, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 0, \"x\": 143.86599731445312, \"y\": 270.05352783203125, \"width\": 325.5101623535156, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 0, \"x\": 143.86599731445312, \"y\": 259.14447021484375, \"width\": 324.43609619140625, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 0, \"x\": 143.86599731445312, \"y\": 248.23553466796875, \"width\": 324.26495361328125, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 0, \"x\": 143.86599731445312, \"y\": 237.32647705078125, \"width\": 324.265380859375, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 0, \"x\": 143.86599731445312, \"y\": 226.41748046875, \"width\": 324.2731628417969, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 0, \"x\": 143.86599731445312, \"y\": 215.50848388671875, \"width\": 122.4005126953125, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 0, \"x\": 119.8219985961914, \"y\": 184.2872314453125, \"width\": 3.8137054443359375, \"height\": 10.3651123046875, \"color\": \"#FFFF00\"}, {\"page\": 0, \"x\": 124.13999938964844, \"y\": 183.62548828125, \"width\": 379.85707092285156, \"height\": 10.80450439453125, \"color\": \"#FFFF00\"}, {\"page\": 0, \"x\": 108.0, \"y\": 173.6634521484375, \"width\": 395.9971618652344, \"height\": 10.80450439453125, \"color\": \"#FFFF00\"}]"}, "type": "Document"}
{"page_content": "has been crucially involved in every aspect of this work. Noam proposed scaled dot-product attention, multi-head attention and the parameter-free position representation and became the other person involved in nearly every detail. Niki designed, implemented, tuned and evaluated countless model variants in our original codebase and tensor2tensor. Llion also experimented with novel model variants, was responsible for our initial codebase, and efficient inference and visualizations. Lukasz and Aidan spent countless long days designing various parts of and implementing tensor2tensor, replacing our earlier codebase, greatly improving results and massively accelerating our research. † Work performed while at Google Brain. ‡ Work performed while at Google Research. 31st Conference on Neural Information Processing Systems (NIPS 2017), Long Beach, CA, USA. arXiv:1706.03762v7  [cs.CL]  2 Aug 2023 1 Introduction Recurrent neural networks, long short-term memory [ 13 ] and gated recurrent [ 7", "metadata": {"source": "../paper/attention_is_all_you_need.pdf", "title": "", "pid": "2", "annotations": "[{\"page\": 0, \"x\": 108.0, \"y\": 163.700439453125, \"width\": 395.998046875, \"height\": 10.80450439453125, \"color\": \"#FFFF00\"}, {\"page\": 0, \"x\": 108.0, \"y\": 153.73748779296875, \"width\": 396.31378173828125, \"height\": 10.80450439453125, \"color\": \"#FFFF00\"}, {\"page\": 0, \"x\": 108.0, \"y\": 143.77545166015625, \"width\": 395.9964294433594, \"height\": 10.80450439453125, \"color\": \"#FFFF00\"}, {\"page\": 0, \"x\": 108.0, \"y\": 133.8125, \"width\": 395.9991455078125, \"height\": 10.80450439453125, \"color\": \"#FFFF00\"}, {\"page\": 0, \"x\": 108.0, \"y\": 123.8494873046875, \"width\": 395.9978942871094, \"height\": 10.80450439453125, \"color\": \"#FFFF00\"}, {\"page\": 0, \"x\": 108.0, \"y\": 113.887451171875, \"width\": 395.9980773925781, \"height\": 10.80450439453125, \"color\": \"#FFFF00\"}, {\"page\": 0, \"x\": 108.0, \"y\": 103.9244384765625, \"width\": 46.302490234375, \"height\": 10.80450439453125, \"color\": \"#FFFF00\"}, {\"page\": 0, \"x\": 120.20999908447266, \"y\": 93.63726806640625, \"width\": 3.4311447143554688, \"height\": 10.3651123046875, \"color\": \"#FFFF00\"}, {\"page\": 0, \"x\": 124.13999938964844, \"y\": 92.9754638671875, \"width\": 143.2113494873047, \"height\": 10.80450439453125, \"color\": \"#FFFF00\"}, {\"page\": 0, \"x\": 120.20999908447266, \"y\": 82.688232421875, \"width\": 3.4311447143554688, \"height\": 10.3651123046875, \"color\": \"#FFFF00\"}, {\"page\": 0, \"x\": 124.13999938964844, \"y\": 82.0264892578125, \"width\": 156.14988708496094, \"height\": 10.80450439453125, \"color\": \"#FFFF00\"}, {\"page\": 0, \"x\": 108.0, \"y\": 49.60345458984375, \"width\": 352.1375732421875, \"height\": 10.80450439453125, \"color\": \"#FFFF00\"}, {\"page\": 0, \"x\": 10.940000534057617, \"y\": 237.0, \"width\": 26.67999839782715, \"height\": 341.08001708984375, \"color\": \"#FFFF00\"}, {\"page\": 1, \"x\": 108.0, \"y\": 705.9602661132812, \"width\": 5.97760009765625, \"height\": 15.5537109375, \"color\": \"#FFFF00\"}, {\"page\": 1, \"x\": 125.93280029296875, \"y\": 705.9602661132812, \"width\": 64.88087463378906, \"height\": 15.5537109375, \"color\": \"#FFFF00\"}, {\"page\": 1, \"x\": 108.0, \"y\": 682.5545120239258, \"width\": 218.95751953125, \"height\": 12.004936218261719, \"color\": \"#FFFF00\"}, {\"page\": 1, \"x\": 326.9540100097656, \"y\": 682.5545120239258, \"width\": 9.96258544921875, \"height\": 12.004936218261719, \"color\": \"#FFFF00\"}, {\"page\": 1, \"x\": 336.9159851074219, \"y\": 682.5545120239258, \"width\": 90.80648803710938, \"height\": 12.004936218261719, \"color\": \"#FFFF00\"}, {\"page\": 1, \"x\": 427.72198486328125, \"y\": 682.5545120239258, \"width\": 4.981292724609375, \"height\": 12.004936218261719, \"color\": \"#FFFF00\"}]"}, "type": "Document"}
{"page_content": "] neural networks in particular, have been firmly established as state of the art approaches in sequence modeling and transduction problems such as language modeling and machine translation [ 35 ,  2 ,  5 ]. Numerous efforts have since continued to push the boundaries of recurrent language models and encoder-decoder architectures [38, 24, 15]. Recurrent models typically factor computation along the symbol positions of the input and output sequences. Aligning the positions to steps in computation time, they generate a sequence of hidden states  h t , as a function of the previous hidden state  h t − 1  and the input for position  t . This inherently sequential nature precludes parallelization within training examples, which becomes critical at longer sequence lengths, as memory constraints limit batching across examples. Recent work has achieved significant improvements in computational efficiency through factorization tricks [ 21 ] and conditional computation [ 32", "metadata": {"source": "../paper/attention_is_all_you_need.pdf", "title": "", "pid": "3", "annotations": "[{\"page\": 1, \"x\": 432.7030029296875, \"y\": 682.5545120239258, \"width\": 71.295654296875, \"height\": 12.004936218261719, \"color\": \"#FFFF00\"}, {\"page\": 1, \"x\": 108.0, \"y\": 671.6455154418945, \"width\": 395.9976501464844, \"height\": 12.004936218261719, \"color\": \"#FFFF00\"}, {\"page\": 1, \"x\": 108.0, \"y\": 660.7365264892578, \"width\": 312.2940979003906, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 1, \"x\": 420.2969970703125, \"y\": 660.7365264892578, \"width\": 9.96258544921875, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 1, \"x\": 430.260009765625, \"y\": 660.7365264892578, \"width\": 2.54046630859375, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 1, \"x\": 432.80047607421875, \"y\": 660.7365264892578, \"width\": 7.94482421875, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 1, \"x\": 440.7460021972656, \"y\": 660.7365264892578, \"width\": 2.54046630859375, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 1, \"x\": 443.2864685058594, \"y\": 660.7365264892578, \"width\": 7.945831298828125, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 1, \"x\": 451.23199462890625, \"y\": 660.7365264892578, \"width\": 52.77056884765625, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 1, \"x\": 108.0, \"y\": 649.8275299072266, \"width\": 396.1676330566406, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 1, \"x\": 108.0, \"y\": 638.9185333251953, \"width\": 102.36567687988281, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 1, \"x\": 108.0, \"y\": 622.5294952392578, \"width\": 395.997314453125, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 1, \"x\": 108.0, \"y\": 611.6204986572266, \"width\": 395.9969482421875, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 1, \"x\": 108.0, \"y\": 600.7115020751953, \"width\": 21.91552734375, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 1, \"x\": 129.91552734375, \"y\": 601.0203399658203, \"width\": 8.22894287109375, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 1, \"x\": 138.14601135253906, \"y\": 600.2735137939453, \"width\": 3.005706787109375, \"height\": 6.9738006591796875, \"color\": \"#FFFF00\"}, {\"page\": 1, \"x\": 141.6540069580078, \"y\": 600.7115020751953, \"width\": 166.77308654785156, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 1, \"x\": 308.4270935058594, \"y\": 601.0203399658203, \"width\": 8.23236083984375, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 1, \"x\": 316.6609802246094, \"y\": 600.2735137939453, \"width\": 3.005706787109375, \"height\": 6.9738006591796875, \"color\": \"#FFFF00\"}, {\"page\": 1, \"x\": 319.66998291015625, \"y\": 595.3848876953125, \"width\": 6.22064208984375, \"height\": 12.085586547851562, \"color\": \"#FFFF00\"}, {\"page\": 1, \"x\": 325.89697265625, \"y\": 600.2735137939453, \"width\": 3.96807861328125, \"height\": 6.9738006591796875, \"color\": \"#FFFF00\"}, {\"page\": 1, \"x\": 329.86505126953125, \"y\": 599.2174835205078, \"width\": 102.81512451171875, \"height\": 13.498947143554688, \"color\": \"#FFFF00\"}, {\"page\": 1, \"x\": 432.68017578125, \"y\": 601.0203399658203, \"width\": 6.09033203125, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 1, \"x\": 438.7720031738281, \"y\": 600.7115020751953, \"width\": 65.57888793945312, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 1, \"x\": 108.0, \"y\": 589.8025054931641, \"width\": 396.1674499511719, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 1, \"x\": 108.0, \"y\": 578.8935089111328, \"width\": 395.9975891113281, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 1, \"x\": 108.0, \"y\": 567.9845123291016, \"width\": 320.2769775390625, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 1, \"x\": 428.27801513671875, \"y\": 567.9845123291016, \"width\": 9.96258544921875, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 1, \"x\": 438.2409973144531, \"y\": 567.9845123291016, \"width\": 65.75619506835938, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 1, \"x\": 108.0, \"y\": 557.0755157470703, \"width\": 56.571685791015625, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 1, \"x\": 164.5760040283203, \"y\": 557.0755157470703, \"width\": 9.96258544921875, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}]"}, "type": "Document"}
{"page_content": "], while also improving model performance in case of the latter. The fundamental constraint of sequential computation, however, remains. Attention mechanisms have become an integral part of compelling sequence modeling and transduc- tion models in various tasks, allowing modeling of dependencies without regard to their distance in the input or output sequences [ 2 ,  19 ]. In all but a few cases [ 27 ], however, such attention mechanisms are used in conjunction with a recurrent network. In this work we propose the Transformer, a model architecture eschewing recurrence and instead relying entirely on an attention mechanism to draw global dependencies between input and output. The Transformer allows for significantly more parallelization and can reach a new state of the art in translation quality after being trained for as little as twelve hours on eight P100 GPUs. 2 Background The goal of reducing sequential computation also forms the foundation of the Extended Neural GPU [ 16", "metadata": {"source": "../paper/attention_is_all_you_need.pdf", "title": "", "pid": "4", "annotations": "[{\"page\": 1, \"x\": 174.53900146484375, \"y\": 557.0755157470703, \"width\": 329.46044921875, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 1, \"x\": 108.0, \"y\": 546.1665191650391, \"width\": 222.52468872070312, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 1, \"x\": 107.64099884033203, \"y\": 529.7775268554688, \"width\": 398.0144577026367, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 1, \"x\": 108.0, \"y\": 518.8685302734375, \"width\": 395.9970703125, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 1, \"x\": 108.0, \"y\": 507.9595031738281, \"width\": 119.84507751464844, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 1, \"x\": 227.8470001220703, \"y\": 507.9595031738281, \"width\": 4.981292724609375, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 1, \"x\": 232.8280029296875, \"y\": 507.9595031738281, \"width\": 2.4408416748046875, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 1, \"x\": 235.2688446044922, \"y\": 507.9595031738281, \"width\": 12.347747802734375, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 1, \"x\": 247.61700439453125, \"y\": 507.9595031738281, \"width\": 95.79800415039062, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 1, \"x\": 343.4169921875, \"y\": 507.9595031738281, \"width\": 9.96258544921875, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 1, \"x\": 353.3800048828125, \"y\": 507.9595031738281, \"width\": 150.6192626953125, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 1, \"x\": 108.0, \"y\": 497.0505065917969, \"width\": 195.78494262695312, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 1, \"x\": 108.0, \"y\": 480.6614990234375, \"width\": 395.9975280761719, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 1, \"x\": 108.0, \"y\": 469.75250244140625, \"width\": 397.73870849609375, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 1, \"x\": 107.69100189208984, \"y\": 458.843505859375, \"width\": 396.3121109008789, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 1, \"x\": 108.0, \"y\": 447.93450927734375, \"width\": 344.35723876953125, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 1, \"x\": 108.0, \"y\": 415.64727783203125, \"width\": 5.97760009765625, \"height\": 15.5537109375, \"color\": \"#FFFF00\"}, {\"page\": 1, \"x\": 125.93280029296875, \"y\": 415.64727783203125, \"width\": 62.89631652832031, \"height\": 15.5537109375, \"color\": \"#FFFF00\"}, {\"page\": 1, \"x\": 107.69100189208984, \"y\": 392.2414855957031, \"width\": 396.31043243408203, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 1, \"x\": 108.0, \"y\": 381.3324890136719, \"width\": 3.2511978149414062, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 1, \"x\": 111.2509994506836, \"y\": 381.3324890136719, \"width\": 9.962600708007812, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}]"}, "type": "Document"}
{"page_content": "], ByteNet [ 18 ] and ConvS2S [ 9 ], all of which use convolutional neural networks as basic building block, computing hidden representations in parallel for all input and output positions. In these models, the number of operations required to relate signals from two arbitrary input or output positions grows in the distance between positions, linearly for ConvS2S and logarithmically for ByteNet. This makes it more difficult to learn dependencies between distant positions [ 12 ]. In the Transformer this is reduced to a constant number of operations, albeit at the cost of reduced effective resolution due to averaging attention-weighted positions, an effect we counteract with Multi-Head Attention as described in section 3.2. Self-attention, sometimes called intra-attention is an attention mechanism relating different positions of a single sequence in order to compute a representation of the sequence. Self-attention has been", "metadata": {"source": "../paper/attention_is_all_you_need.pdf", "title": "", "pid": "5", "annotations": "[{\"page\": 1, \"x\": 121.21399688720703, \"y\": 381.3324890136719, \"width\": 46.180641174316406, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 1, \"x\": 167.39500427246094, \"y\": 381.3324890136719, \"width\": 9.96258544921875, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 1, \"x\": 177.35800170898438, \"y\": 381.3324890136719, \"width\": 64.0963134765625, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 1, \"x\": 241.4550018310547, \"y\": 381.3324890136719, \"width\": 4.981292724609375, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 1, \"x\": 246.43600463867188, \"y\": 381.3324890136719, \"width\": 257.5669250488281, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 1, \"x\": 108.0, \"y\": 370.4234924316406, \"width\": 397.2414245605469, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 1, \"x\": 108.0, \"y\": 359.51348876953125, \"width\": 396.00146484375, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 1, \"x\": 108.0, \"y\": 348.6044921875, \"width\": 395.999267578125, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 1, \"x\": 108.0, \"y\": 337.69549560546875, \"width\": 270.1732482910156, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 1, \"x\": 378.16900634765625, \"y\": 337.69549560546875, \"width\": 9.96258544921875, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 1, \"x\": 388.1319885253906, \"y\": 337.69549560546875, \"width\": 115.86557006835938, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 1, \"x\": 108.0, \"y\": 326.7864990234375, \"width\": 395.99737548828125, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 1, \"x\": 108.0, \"y\": 315.87750244140625, \"width\": 395.9972839355469, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 1, \"x\": 108.0, \"y\": 304.968505859375, \"width\": 96.56745910644531, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 1, \"x\": 108.0, \"y\": 288.5794982910156, \"width\": 395.99993896484375, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 1, \"x\": 108.0, \"y\": 277.6705322265625, \"width\": 395.99749755859375, \"height\": 12.004913330078125, \"color\": \"#FFFF00\"}]"}, "type": "Document"}
{"page_content": "used successfully in a variety of tasks including reading comprehension, abstractive summarization, textual entailment and learning task-independent sentence representations [4, 27, 28, 22]. End-to-end memory networks are based on a recurrent attention mechanism instead of sequence- aligned recurrence and have been shown to perform well on simple-language question answering and language modeling tasks [34]. To the best of our knowledge, however, the Transformer is the first transduction model relying entirely on self-attention to compute representations of its input and output without using sequence- aligned RNNs or convolution. In the following sections, we will describe the Transformer, motivate self-attention and discuss its advantages over models such as [17, 18] and [9]. 3 Model Architecture Most competitive neural sequence transduction models have an encoder-decoder structure [ 5 ,  2 ,  35 ]. Here, the encoder maps an input sequence of symbol representations  ( x 1 , ..., x n )", "metadata": {"source": "../paper/attention_is_all_you_need.pdf", "title": "", "pid": "6", "annotations": "[{\"page\": 1, \"x\": 108.0, \"y\": 266.76153564453125, \"width\": 397.2498779296875, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 1, \"x\": 108.0, \"y\": 255.85247802734375, \"width\": 355.11688232421875, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 1, \"x\": 108.0, \"y\": 239.46453857421875, \"width\": 397.6537780761719, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 1, \"x\": 108.0, \"y\": 228.55548095703125, \"width\": 395.99517822265625, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 1, \"x\": 108.0, \"y\": 217.6455078125, \"width\": 120.08915710449219, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 1, \"x\": 107.69100189208984, \"y\": 201.25750732421875, \"width\": 396.3124465942383, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 1, \"x\": 108.0, \"y\": 190.3485107421875, \"width\": 397.656982421875, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 1, \"x\": 108.0, \"y\": 179.43951416015625, \"width\": 395.9974670410156, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 1, \"x\": 108.0, \"y\": 168.530517578125, \"width\": 309.3487243652344, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 1, \"x\": 108.0, \"y\": 136.2432861328125, \"width\": 5.97760009765625, \"height\": 15.5537109375, \"color\": \"#FFFF00\"}, {\"page\": 1, \"x\": 125.93280029296875, \"y\": 136.2432861328125, \"width\": 100.16064453125, \"height\": 15.5537109375, \"color\": \"#FFFF00\"}, {\"page\": 1, \"x\": 108.0, \"y\": 112.83648681640625, \"width\": 362.0843505859375, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 1, \"x\": 470.0849914550781, \"y\": 112.83648681640625, \"width\": 4.981292724609375, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 1, \"x\": 475.0660095214844, \"y\": 112.83648681640625, \"width\": 2.47821044921875, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 1, \"x\": 477.5442199707031, \"y\": 112.83648681640625, \"width\": 7.480072021484375, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 1, \"x\": 485.0249938964844, \"y\": 112.83648681640625, \"width\": 2.47821044921875, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 1, \"x\": 487.5032043457031, \"y\": 112.83648681640625, \"width\": 12.461395263671875, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 1, \"x\": 499.9639892578125, \"y\": 112.83648681640625, \"width\": 5.7791748046875, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 1, \"x\": 108.0, \"y\": 101.927490234375, \"width\": 286.6253967285156, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 1, \"x\": 394.6253967285156, \"y\": 102.236328125, \"width\": 7.245086669921875, \"height\": 9.96258544921875, \"color\": \"#FFFF00\"}, {\"page\": 1, \"x\": 401.8789978027344, \"y\": 102.236328125, \"width\": 5.688629150390625, \"height\": 9.96258544921875, \"color\": \"#FFFF00\"}, {\"page\": 1, \"x\": 407.572998046875, \"y\": 101.489501953125, \"width\": 3.96807861328125, \"height\": 6.97381591796875, \"color\": \"#FFFF00\"}, {\"page\": 1, \"x\": 412.0419921875, \"y\": 102.236328125, \"width\": 22.8541259765625, \"height\": 9.96258544921875, \"color\": \"#FFFF00\"}, {\"page\": 1, \"x\": 434.89398193359375, \"y\": 101.489501953125, \"width\": 4.923492431640625, \"height\": 6.97381591796875, \"color\": \"#FFFF00\"}, {\"page\": 1, \"x\": 440.3169860839844, \"y\": 102.236328125, \"width\": 3.865478515625, \"height\": 9.96258544921875, \"color\": \"#FFFF00\"}]"}, "type": "Document"}
{"page_content": "to a sequence of continuous representations  z  = ( z 1 , ..., z n ) . Given  z , the decoder then generates an output sequence  ( y 1 , ..., y m )  of symbols one element at a time. At each step the model is auto-regressive [10], consuming the previously generated symbols as additional input when generating the next. 2 Figure 1: The Transformer - model architecture. The Transformer follows this overall architecture using stacked self-attention and point-wise, fully connected layers for both the encoder and decoder, shown in the left and right halves of Figure 1, respectively. 3.1 Encoder and Decoder Stacks Encoder: The encoder is composed of a stack of  N  = 6  identical layers. Each layer has two sub-layers. The first is a multi-head self-attention mechanism, and the second is a simple, position- wise fully connected feed-forward network. We employ a residual connection [ 11 ] around each of the two sub-layers, followed by layer normalization [ 1", "metadata": {"source": "../paper/attention_is_all_you_need.pdf", "title": "", "pid": "7", "annotations": "[{\"page\": 1, \"x\": 444.1824645996094, \"y\": 101.927490234375, \"width\": 59.820404052734375, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 1, \"x\": 108.0, \"y\": 91.01849365234375, \"width\": 121.96258544921875, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 1, \"x\": 229.96258544921875, \"y\": 91.32733154296875, \"width\": 8.786300659179688, \"height\": 9.96258544921875, \"color\": \"#FFFF00\"}, {\"page\": 1, \"x\": 238.74888610839844, \"y\": 91.32733154296875, \"width\": 21.599746704101562, \"height\": 9.96258544921875, \"color\": \"#FFFF00\"}, {\"page\": 1, \"x\": 260.35400390625, \"y\": 91.32733154296875, \"width\": 4.632598876953125, \"height\": 9.96258544921875, \"color\": \"#FFFF00\"}, {\"page\": 1, \"x\": 264.9880065917969, \"y\": 90.58050537109375, \"width\": 3.96807861328125, \"height\": 6.97381591796875, \"color\": \"#FFFF00\"}, {\"page\": 1, \"x\": 269.4570007324219, \"y\": 91.32733154296875, \"width\": 21.798095703125, \"height\": 9.96258544921875, \"color\": \"#FFFF00\"}, {\"page\": 1, \"x\": 291.24798583984375, \"y\": 90.58050537109375, \"width\": 4.923492431640625, \"height\": 6.97381591796875, \"color\": \"#FFFF00\"}, {\"page\": 1, \"x\": 296.6709899902344, \"y\": 91.32733154296875, \"width\": 3.865478515625, \"height\": 9.96258544921875, \"color\": \"#FFFF00\"}, {\"page\": 1, \"x\": 300.5450134277344, \"y\": 91.01849365234375, \"width\": 33.66619873046875, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 1, \"x\": 334.2112121582031, \"y\": 91.32733154296875, \"width\": 8.783660888671875, \"height\": 9.96258544921875, \"color\": \"#FFFF00\"}, {\"page\": 1, \"x\": 342.9960021972656, \"y\": 91.01849365234375, \"width\": 161.00454711914062, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 1, \"x\": 108.0, \"y\": 80.1094970703125, \"width\": 37.24317932128906, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 1, \"x\": 145.24317932128906, \"y\": 80.4183349609375, \"width\": 6.42431640625, \"height\": 9.96258544921875, \"color\": \"#FFFF00\"}, {\"page\": 1, \"x\": 151.67599487304688, \"y\": 80.4183349609375, \"width\": 4.8816680908203125, \"height\": 9.96258544921875, \"color\": \"#FFFF00\"}, {\"page\": 1, \"x\": 156.5609893798828, \"y\": 79.6715087890625, \"width\": 3.9680938720703125, \"height\": 6.97381591796875, \"color\": \"#FFFF00\"}, {\"page\": 1, \"x\": 161.0299835205078, \"y\": 80.4183349609375, \"width\": 22.047256469726562, \"height\": 9.96258544921875, \"color\": \"#FFFF00\"}, {\"page\": 1, \"x\": 183.07298278808594, \"y\": 79.6715087890625, \"width\": 7.064453125, \"height\": 6.97381591796875, \"color\": \"#FFFF00\"}, {\"page\": 1, \"x\": 190.63998413085938, \"y\": 80.4183349609375, \"width\": 3.8654937744140625, \"height\": 9.96258544921875, \"color\": \"#FFFF00\"}, {\"page\": 1, \"x\": 194.50547790527344, \"y\": 80.1094970703125, \"width\": 309.49729919433594, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 1, \"x\": 108.0, \"y\": 69.20050048828125, \"width\": 382.5636901855469, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 1, \"x\": 303.5090026855469, \"y\": 39.3125, \"width\": 4.981292724609375, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 2, \"x\": 210.01100158691406, \"y\": 376.8995056152344, \"width\": 191.9792938232422, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 2, \"x\": 107.69100189208984, \"y\": 344.8475036621094, \"width\": 396.66190338134766, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 2, \"x\": 108.0, \"y\": 333.9385070800781, \"width\": 397.2474670410156, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 2, \"x\": 108.0, \"y\": 323.0295104980469, \"width\": 49.5838623046875, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 2, \"x\": 108.0, \"y\": 297.9647521972656, \"width\": 12.4532470703125, \"height\": 12.961334228515625, \"color\": \"#FFFF00\"}, {\"page\": 2, \"x\": 130.4158477783203, \"y\": 297.9647521972656, \"width\": 122.58976745605469, \"height\": 12.961334228515625, \"color\": \"#FFFF00\"}, {\"page\": 2, \"x\": 108.0, \"y\": 277.98675537109375, \"width\": 40.078338623046875, \"height\": 12.961334228515625, \"color\": \"#FFFF00\"}, {\"page\": 2, \"x\": 158.04100036621094, \"y\": 278.58453369140625, \"width\": 160.58787536621094, \"height\": 12.004913330078125, \"color\": \"#FFFF00\"}, {\"page\": 2, \"x\": 318.6288757324219, \"y\": 278.89337158203125, \"width\": 11.190093994140625, \"height\": 9.96258544921875, \"color\": \"#FFFF00\"}, {\"page\": 2, \"x\": 329.8189697265625, \"y\": 278.89337158203125, \"width\": 21.93701171875, \"height\": 9.96258544921875, \"color\": \"#FFFF00\"}, {\"page\": 2, \"x\": 351.7559814453125, \"y\": 278.58453369140625, \"width\": 152.24420166015625, \"height\": 12.004913330078125, \"color\": \"#FFFF00\"}, {\"page\": 2, \"x\": 108.0, \"y\": 267.67547607421875, \"width\": 397.6571960449219, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 2, \"x\": 107.64099884033203, \"y\": 256.76654052734375, \"width\": 320.4524459838867, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 2, \"x\": 428.093994140625, \"y\": 256.76654052734375, \"width\": 9.96258544921875, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 2, \"x\": 438.0570068359375, \"y\": 256.76654052734375, \"width\": 65.94488525390625, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 2, \"x\": 108.0, \"y\": 245.85748291015625, \"width\": 220.0753173828125, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 2, \"x\": 328.07501220703125, \"y\": 245.85748291015625, \"width\": 4.981292724609375, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}]"}, "type": "Document"}
{"page_content": "]. That is, the output of each sub-layer is LayerNorm( x  + Sublayer( x )) , where  Sublayer( x )  is the function implemented by the sub-layer itself. To facilitate these residual connections, all sub-layers in the model, as well as the embedding layers, produce outputs of dimension  d model  = 512 . Decoder: The decoder is also composed of a stack of  N  = 6  identical layers. In addition to the two sub-layers in each encoder layer, the decoder inserts a third sub-layer, which performs multi-head attention over the output of the encoder stack. Similar to the encoder, we employ residual connections around each of the sub-layers, followed by layer normalization. We also modify the self-attention sub-layer in the decoder stack to prevent positions from attending to subsequent positions. This masking, combined with fact that the output embeddings are offset by one position, ensures that the predictions for position  i  can depend only on the known outputs at positions less than  i . 3.2", "metadata": {"source": "../paper/attention_is_all_you_need.pdf", "title": "", "pid": "8", "annotations": "[{\"page\": 2, \"x\": 333.0559997558594, \"y\": 245.85748291015625, \"width\": 170.94284057617188, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 2, \"x\": 108.0, \"y\": 235.25732421875, \"width\": 52.76191711425781, \"height\": 9.96258544921875, \"color\": \"#FFFF00\"}, {\"page\": 2, \"x\": 160.7740020751953, \"y\": 235.25732421875, \"width\": 5.6886444091796875, \"height\": 9.96258544921875, \"color\": \"#FFFF00\"}, {\"page\": 2, \"x\": 166.462646484375, \"y\": 235.25732421875, \"width\": 53.9610595703125, \"height\": 9.96258544921875, \"color\": \"#FFFF00\"}, {\"page\": 2, \"x\": 220.41600036621094, \"y\": 235.25732421875, \"width\": 5.6886444091796875, \"height\": 9.96258544921875, \"color\": \"#FFFF00\"}, {\"page\": 2, \"x\": 226.11000061035156, \"y\": 235.25732421875, \"width\": 7.7409515380859375, \"height\": 9.96258544921875, \"color\": \"#FFFF00\"}, {\"page\": 2, \"x\": 233.85800170898438, \"y\": 234.948486328125, \"width\": 30.2823486328125, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 2, \"x\": 264.1403503417969, \"y\": 235.25732421875, \"width\": 44.103729248046875, \"height\": 9.96258544921875, \"color\": \"#FFFF00\"}, {\"page\": 2, \"x\": 308.2409973144531, \"y\": 235.25732421875, \"width\": 5.688629150390625, \"height\": 9.96258544921875, \"color\": \"#FFFF00\"}, {\"page\": 2, \"x\": 313.93499755859375, \"y\": 235.25732421875, \"width\": 3.865478515625, \"height\": 9.96258544921875, \"color\": \"#FFFF00\"}, {\"page\": 2, \"x\": 317.80047607421875, \"y\": 234.948486328125, \"width\": 186.3656005859375, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 2, \"x\": 108.0, \"y\": 224.03948974609375, \"width\": 396.0033874511719, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 2, \"x\": 108.0, \"y\": 213.1295166015625, \"width\": 147.48626708984375, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 2, \"x\": 255.48626708984375, \"y\": 213.4383544921875, \"width\": 7.6702880859375, \"height\": 9.96258544921875, \"color\": \"#FFFF00\"}, {\"page\": 2, \"x\": 263.1620178222656, \"y\": 212.475341796875, \"width\": 17.434539794921875, \"height\": 8.4034423828125, \"color\": \"#FFFF00\"}, {\"page\": 2, \"x\": 280.5965576171875, \"y\": 211.9443359375, \"width\": 28.728851318359375, \"height\": 11.45660400390625, \"color\": \"#FFFF00\"}, {\"page\": 2, \"x\": 309.322021484375, \"y\": 213.1295166015625, \"width\": 2.49066162109375, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 2, \"x\": 108.0, \"y\": 189.4107666015625, \"width\": 37.95014953613281, \"height\": 12.9613037109375, \"color\": \"#FFFF00\"}, {\"page\": 2, \"x\": 155.91299438476562, \"y\": 190.00848388671875, \"width\": 167.51959228515625, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 2, \"x\": 323.4325866699219, \"y\": 190.31732177734375, \"width\": 10.368377685546875, \"height\": 9.96258544921875, \"color\": \"#FFFF00\"}, {\"page\": 2, \"x\": 333.80096435546875, \"y\": 190.31732177734375, \"width\": 19.359832763671875, \"height\": 9.96258544921875, \"color\": \"#FFFF00\"}, {\"page\": 2, \"x\": 353.1607971191406, \"y\": 190.00848388671875, \"width\": 150.83547973632812, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 2, \"x\": 108.0, \"y\": 179.0994873046875, \"width\": 395.9974670410156, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 2, \"x\": 108.0, \"y\": 168.19049072265625, \"width\": 396.00146484375, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 2, \"x\": 108.0, \"y\": 157.281494140625, \"width\": 395.9974060058594, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 2, \"x\": 108.0, \"y\": 146.37249755859375, \"width\": 395.9973449707031, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 2, \"x\": 108.0, \"y\": 135.4635009765625, \"width\": 395.9971618652344, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 2, \"x\": 108.0, \"y\": 124.55450439453125, \"width\": 92.98094177246094, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 2, \"x\": 200.98094177246094, \"y\": 124.86334228515625, \"width\": 5.917205810546875, \"height\": 9.96258544921875, \"color\": \"#FFFF00\"}, {\"page\": 2, \"x\": 206.8981475830078, \"y\": 124.55450439453125, \"width\": 241.33912658691406, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 2, \"x\": 448.2372741699219, \"y\": 124.86334228515625, \"width\": 5.916839599609375, \"height\": 9.96258544921875, \"color\": \"#FFFF00\"}, {\"page\": 2, \"x\": 454.15899658203125, \"y\": 124.55450439453125, \"width\": 2.49066162109375, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 2, \"x\": 108.0, \"y\": 99.48974609375, \"width\": 12.4532470703125, \"height\": 12.9613037109375, \"color\": \"#FFFF00\"}]"}, "type": "Document"}
{"page_content": "Attention An attention function can be described as mapping a query and a set of key-value pairs to an output, where the query, keys, values, and output are all vectors. The output is computed as a weighted sum 3 Scaled Dot-Product Attention Multi-Head Attention Figure 2: (left) Scaled Dot-Product Attention. (right) Multi-Head Attention consists of several attention layers running in parallel. of the values, where the weight assigned to each value is computed by a compatibility function of the query with the corresponding key. 3.2.1 Scaled Dot-Product Attention We call our particular attention \"Scaled Dot-Product Attention\" (Figure 2). The input consists of queries and keys of dimension  d k , and values of dimension  d v . We compute the dot products of the query with all keys, divide each by √ d k , and apply a softmax function to obtain the weights on the values. In practice, we compute the attention function on a set of queries simultaneously, packed together into a matrix  Q", "metadata": {"source": "../paper/attention_is_all_you_need.pdf", "title": "", "pid": "9", "annotations": "[{\"page\": 2, \"x\": 130.4158477783203, \"y\": 99.48974609375, \"width\": 40.398345947265625, \"height\": 12.9613037109375, \"color\": \"#FFFF00\"}, {\"page\": 2, \"x\": 107.64099884033203, \"y\": 80.1094970703125, \"width\": 397.60787200927734, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 2, \"x\": 107.64099884033203, \"y\": 69.20050048828125, \"width\": 396.36278533935547, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 2, \"x\": 303.5090026855469, \"y\": 39.3125, \"width\": 4.981292724609375, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 3, \"x\": 147.7830047607422, \"y\": 710.4455032348633, \"width\": 118.43537902832031, \"height\": 12.004936218261719, \"color\": \"#FFFF00\"}, {\"page\": 3, \"x\": 363.58599853515625, \"y\": 710.4455032348633, \"width\": 86.61474609375, \"height\": 12.004936218261719, \"color\": \"#FFFF00\"}, {\"page\": 3, \"x\": 108.0, \"y\": 507.1814880371094, \"width\": 395.9972229003906, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 3, \"x\": 108.0, \"y\": 496.2724914550781, \"width\": 139.73541259765625, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 3, \"x\": 108.0, \"y\": 464.46649169921875, \"width\": 395.9951477050781, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 3, \"x\": 108.0, \"y\": 453.5574951171875, \"width\": 135.51123046875, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 3, \"x\": 108.0, \"y\": 429.8997497558594, \"width\": 19.925193786621094, \"height\": 12.961334228515625, \"color\": \"#FFFF00\"}, {\"page\": 3, \"x\": 137.88778686523438, \"y\": 429.8997497558594, \"width\": 125.99700927734375, \"height\": 12.961334228515625, \"color\": \"#FFFF00\"}, {\"page\": 3, \"x\": 107.53199768066406, \"y\": 411.86749267578125, \"width\": 396.46473693847656, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 3, \"x\": 108.0, \"y\": 400.95849609375, \"width\": 121.1678466796875, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 3, \"x\": 229.1678466796875, \"y\": 401.267333984375, \"width\": 7.6677093505859375, \"height\": 9.962615966796875, \"color\": \"#FFFF00\"}, {\"page\": 3, \"x\": 236.83999633789062, \"y\": 400.52056884765625, \"width\": 4.23309326171875, \"height\": 6.973785400390625, \"color\": \"#FFFF00\"}, {\"page\": 3, \"x\": 241.74200439453125, \"y\": 400.95849609375, \"width\": 102.04153442382812, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 3, \"x\": 343.7835388183594, \"y\": 401.267333984375, \"width\": 7.6669921875, \"height\": 9.962615966796875, \"color\": \"#FFFF00\"}, {\"page\": 3, \"x\": 351.4549865722656, \"y\": 400.52056884765625, \"width\": 3.982025146484375, \"height\": 6.973785400390625, \"color\": \"#FFFF00\"}, {\"page\": 3, \"x\": 356.1889953613281, \"y\": 400.95849609375, \"width\": 147.8115234375, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 3, \"x\": 108.0, \"y\": 390.04949951171875, \"width\": 139.55987548828125, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 3, \"x\": 250.0489959716797, \"y\": 391.0279235839844, \"width\": 8.298843383789062, \"height\": 17.28509521484375, \"color\": \"#FFFF00\"}, {\"page\": 3, \"x\": 258.35101318359375, \"y\": 390.35833740234375, \"width\": 5.1805419921875, \"height\": 9.962615966796875, \"color\": \"#FFFF00\"}, {\"page\": 3, \"x\": 263.5360107421875, \"y\": 389.611572265625, \"width\": 4.23309326171875, \"height\": 6.973785400390625, \"color\": \"#FFFF00\"}, {\"page\": 3, \"x\": 268.43798828125, \"y\": 390.04949951171875, \"width\": 235.55929565429688, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 3, \"x\": 107.7509994506836, \"y\": 379.1405029296875, \"width\": 27.69603729248047, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 3, \"x\": 108.0, \"y\": 362.7514953613281, \"width\": 396.170166015625, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 3, \"x\": 108.0, \"y\": 351.8424987792969, \"width\": 51.051605224609375, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 3, \"x\": 159.05160522460938, \"y\": 352.1513366699219, \"width\": 10.356842041015625, \"height\": 9.962615966796875, \"color\": \"#FFFF00\"}]"}, "type": "Document"}
{"page_content": ". The keys and values are also packed together into matrices  K  and  V  . We compute the matrix of outputs as: Attention( Q, K, V  ) = softmax( QK T √ d k ) V (1) The two most commonly used attention functions are additive attention [ 2 ], and dot-product (multi- plicative) attention. Dot-product attention is identical to our algorithm, except for the scaling factor of 1 √ d k  . Additive attention computes the compatibility function using a feed-forward network with a single hidden layer. While the two are similar in theoretical complexity, dot-product attention is much faster and more space-efficient in practice, since it can be implemented using highly optimized matrix multiplication code. While for small values of  d k  the two mechanisms perform similarly, additive attention outperforms dot product attention without scaling for larger values of  d k  [ 3 ]. We suspect that for large values of d k", "metadata": {"source": "../paper/attention_is_all_you_need.pdf", "title": "", "pid": "10", "annotations": "[{\"page\": 3, \"x\": 169.41400146484375, \"y\": 351.8424987792969, \"width\": 239.92987060546875, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 3, \"x\": 409.3438720703125, \"y\": 352.1513366699219, \"width\": 10.951385498046875, \"height\": 9.962615966796875, \"color\": \"#FFFF00\"}, {\"page\": 3, \"x\": 420.2952575683594, \"y\": 351.8424987792969, \"width\": 17.63189697265625, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 3, \"x\": 437.9271545410156, \"y\": 352.1513366699219, \"width\": 8.296051025390625, \"height\": 9.962615966796875, \"color\": \"#FFFF00\"}, {\"page\": 3, \"x\": 446.22320556640625, \"y\": 351.8424987792969, \"width\": 57.77508544921875, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 3, \"x\": 108.0, \"y\": 340.9335021972656, \"width\": 96.85639953613281, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 3, \"x\": 219.97000122070312, \"y\": 308.7373352050781, \"width\": 45.65863037109375, \"height\": 9.962615966796875, \"color\": \"#FFFF00\"}, {\"page\": 3, \"x\": 265.6319885253906, \"y\": 308.7373352050781, \"width\": 31.1629638671875, \"height\": 9.962615966796875, \"color\": \"#FFFF00\"}, {\"page\": 3, \"x\": 296.7949523925781, \"y\": 308.7373352050781, \"width\": 57.617034912109375, \"height\": 9.962615966796875, \"color\": \"#FFFF00\"}, {\"page\": 3, \"x\": 355.6089782714844, \"y\": 315.4763488769531, \"width\": 16.338653564453125, \"height\": 9.962615966796875, \"color\": \"#FFFF00\"}, {\"page\": 3, \"x\": 372.6589660644531, \"y\": 319.8395690917969, \"width\": 4.700347900390625, \"height\": 6.973785400390625, \"color\": \"#FFFF00\"}, {\"page\": 3, \"x\": 358.0769958496094, \"y\": 301.9629211425781, \"width\": 8.298858642578125, \"height\": 17.28509521484375, \"color\": \"#FFFF00\"}, {\"page\": 3, \"x\": 366.3789978027344, \"y\": 301.2923278808594, \"width\": 5.1805419921875, \"height\": 9.962615966796875, \"color\": \"#FFFF00\"}, {\"page\": 3, \"x\": 371.56500244140625, \"y\": 300.5455627441406, \"width\": 4.23309326171875, \"height\": 6.973785400390625, \"color\": \"#FFFF00\"}, {\"page\": 3, \"x\": 380.1300048828125, \"y\": 308.7373352050781, \"width\": 3.865478515625, \"height\": 9.962615966796875, \"color\": \"#FFFF00\"}, {\"page\": 3, \"x\": 384.0050048828125, \"y\": 308.7373352050781, \"width\": 5.808197021484375, \"height\": 9.962615966796875, \"color\": \"#FFFF00\"}, {\"page\": 3, \"x\": 493.0509948730469, \"y\": 308.4284973144531, \"width\": 11.616363525390625, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 3, \"x\": 107.69100189208984, \"y\": 282.1264953613281, \"width\": 290.7103958129883, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 3, \"x\": 398.4049987792969, \"y\": 282.1264953613281, \"width\": 4.981292724609375, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 3, \"x\": 403.385986328125, \"y\": 282.1264953613281, \"width\": 102.2667236328125, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 3, \"x\": 108.0, \"y\": 271.21746826171875, \"width\": 396.16693115234375, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 3, \"x\": 108.0, \"y\": 260.30853271484375, \"width\": 8.37353515625, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 3, \"x\": 125.59500122070312, \"y\": 265.28753662109375, \"width\": 3.9680938720703125, \"height\": 6.97381591796875, \"color\": \"#FFFF00\"}, {\"page\": 3, \"x\": 120.05599975585938, \"y\": 257.69189453125, \"width\": 6.5414276123046875, \"height\": 12.0855712890625, \"color\": \"#FFFF00\"}, {\"page\": 3, \"x\": 126.60099792480469, \"y\": 257.15850830078125, \"width\": 4.1424407958984375, \"height\": 6.97381591796875, \"color\": \"#FFFF00\"}, {\"page\": 3, \"x\": 130.74899291992188, \"y\": 256.59869384765625, \"width\": 3.77581787109375, \"height\": 4.98126220703125, \"color\": \"#FFFF00\"}, {\"page\": 3, \"x\": 134.52481079101562, \"y\": 255.04449462890625, \"width\": 369.47564697265625, \"height\": 17.26898193359375, \"color\": \"#FFFF00\"}, {\"page\": 3, \"x\": 108.0, \"y\": 247.13848876953125, \"width\": 395.9973449707031, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 3, \"x\": 108.0, \"y\": 236.2294921875, \"width\": 396.0005187988281, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 3, \"x\": 108.0, \"y\": 225.32049560546875, \"width\": 108.20378112792969, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 3, \"x\": 107.53199768066406, \"y\": 208.9315185546875, \"width\": 101.54672241210938, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 3, \"x\": 209.07872009277344, \"y\": 209.2403564453125, \"width\": 7.6638336181640625, \"height\": 9.96258544921875, \"color\": \"#FFFF00\"}, {\"page\": 3, \"x\": 216.7469940185547, \"y\": 208.4935302734375, \"width\": 4.23309326171875, \"height\": 6.97381591796875, \"color\": \"#FFFF00\"}, {\"page\": 3, \"x\": 220.98008728027344, \"y\": 207.4375, \"width\": 283.01890563964844, \"height\": 13.49896240234375, \"color\": \"#FFFF00\"}, {\"page\": 3, \"x\": 108.0, \"y\": 198.02252197265625, \"width\": 225.89010620117188, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 3, \"x\": 333.8901062011719, \"y\": 198.33135986328125, \"width\": 7.67742919921875, \"height\": 9.96258544921875, \"color\": \"#FFFF00\"}, {\"page\": 3, \"x\": 341.572998046875, \"y\": 197.58453369140625, \"width\": 4.23309326171875, \"height\": 6.97381591796875, \"color\": \"#FFFF00\"}, {\"page\": 3, \"x\": 345.80609130859375, \"y\": 196.52850341796875, \"width\": 6.500030517578125, \"height\": 13.49896240234375, \"color\": \"#FFFF00\"}, {\"page\": 3, \"x\": 352.3059997558594, \"y\": 198.02252197265625, \"width\": 4.981292724609375, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 3, \"x\": 357.2879943847656, \"y\": 198.02252197265625, \"width\": 146.71200561523438, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 3, \"x\": 108.0, \"y\": 187.42230224609375, \"width\": 5.180549621582031, \"height\": 9.96258544921875, \"color\": \"#FFFF00\"}, {\"page\": 3, \"x\": 113.18499755859375, \"y\": 186.67449951171875, \"width\": 4.23309326171875, \"height\": 6.97381591796875, \"color\": \"#FFFF00\"}]"}, "type": "Document"}
{"page_content": ", the dot products grow large in magnitude, pushing the softmax function into regions where it has extremely small gradients 4 . To counteract this effect, we scale the dot products by 1 √ d k  . 3.2.2 Multi-Head Attention Instead of performing a single attention function with  d model -dimensional keys, values and queries, we found it beneficial to linearly project the queries, keys and values  h  times with different, learned linear projections to  d k ,  d k  and  d v  dimensions, respectively. On each of these projected versions of queries, keys and values we then perform the attention function in parallel, yielding  d v -dimensional 4 To illustrate why the dot products get large, assume that the components of  q  and  k  are independent random variables with mean  0  and variance  1 . Then their dot product,  q  ·  k  = P d k i =1 q i k i , has mean  0  and variance  d k . 4 output values. These are concatenated and once again projected, resulting in the final values, as", "metadata": {"source": "../paper/attention_is_all_you_need.pdf", "title": "", "pid": "11", "annotations": "[{\"page\": 3, \"x\": 118.08699798583984, \"y\": 187.11346435546875, \"width\": 385.91138458251953, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 3, \"x\": 108.0, \"y\": 176.20452880859375, \"width\": 102.78416442871094, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 3, \"x\": 213.2740020751953, \"y\": 180.65936279296875, \"width\": 3.4868927001953125, \"height\": 8.4034423828125, \"color\": \"#FFFF00\"}, {\"page\": 3, \"x\": 217.25900268554688, \"y\": 176.20452880859375, \"width\": 219.78488159179688, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 3, \"x\": 446.2669982910156, \"y\": 181.18255615234375, \"width\": 3.96807861328125, \"height\": 6.97381591796875, \"color\": \"#FFFF00\"}, {\"page\": 3, \"x\": 440.72900390625, \"y\": 173.5869140625, \"width\": 6.541412353515625, \"height\": 12.0855712890625, \"color\": \"#FFFF00\"}, {\"page\": 3, \"x\": 447.27398681640625, \"y\": 173.05352783203125, \"width\": 4.142425537109375, \"height\": 6.97381591796875, \"color\": \"#FFFF00\"}, {\"page\": 3, \"x\": 451.4209899902344, \"y\": 172.49468994140625, \"width\": 3.77581787109375, \"height\": 4.98126220703125, \"color\": \"#FFFF00\"}, {\"page\": 3, \"x\": 455.1968078613281, \"y\": 170.94049072265625, \"width\": 4.265838623046875, \"height\": 17.26898193359375, \"color\": \"#FFFF00\"}, {\"page\": 3, \"x\": 108.0, \"y\": 150.17578125, \"width\": 19.925193786621094, \"height\": 12.9613037109375, \"color\": \"#FFFF00\"}, {\"page\": 3, \"x\": 137.88778686523438, \"y\": 150.17578125, \"width\": 92.70199584960938, \"height\": 12.9613037109375, \"color\": \"#FFFF00\"}, {\"page\": 3, \"x\": 108.0, \"y\": 132.14349365234375, \"width\": 216.1954345703125, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 3, \"x\": 324.1954345703125, \"y\": 132.45233154296875, \"width\": 7.656097412109375, \"height\": 9.96258544921875, \"color\": \"#FFFF00\"}, {\"page\": 3, \"x\": 331.85699462890625, \"y\": 131.48931884765625, \"width\": 17.434539794921875, \"height\": 8.4034423828125, \"color\": \"#FFFF00\"}, {\"page\": 3, \"x\": 349.78900146484375, \"y\": 132.14349365234375, \"width\": 155.45257568359375, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 3, \"x\": 107.64099884033203, \"y\": 121.2344970703125, \"width\": 273.13033294677734, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 3, \"x\": 380.7713317871094, \"y\": 121.5433349609375, \"width\": 8.222137451171875, \"height\": 9.96258544921875, \"color\": \"#FFFF00\"}, {\"page\": 3, \"x\": 388.99346923828125, \"y\": 121.2344970703125, \"width\": 115.00225830078125, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 3, \"x\": 108.0, \"y\": 110.32550048828125, \"width\": 79.97958374023438, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 3, \"x\": 187.97958374023438, \"y\": 110.63433837890625, \"width\": 7.6729736328125, \"height\": 9.96258544921875, \"color\": \"#FFFF00\"}, {\"page\": 3, \"x\": 195.6580047607422, \"y\": 109.88751220703125, \"width\": 4.23309326171875, \"height\": 6.97381591796875, \"color\": \"#FFFF00\"}, {\"page\": 3, \"x\": 200.55999755859375, \"y\": 110.32550048828125, \"width\": 2.5006103515625, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 3, \"x\": 203.06060791015625, \"y\": 110.63433837890625, \"width\": 7.6689453125, \"height\": 9.96258544921875, \"color\": \"#FFFF00\"}, {\"page\": 3, \"x\": 210.73399353027344, \"y\": 109.88751220703125, \"width\": 4.23309326171875, \"height\": 6.97381591796875, \"color\": \"#FFFF00\"}, {\"page\": 3, \"x\": 214.9670867919922, \"y\": 108.83148193359375, \"width\": 17.600433349609375, \"height\": 13.49896240234375, \"color\": \"#FFFF00\"}, {\"page\": 3, \"x\": 232.56752014160156, \"y\": 110.63433837890625, \"width\": 7.669036865234375, \"height\": 9.96258544921875, \"color\": \"#FFFF00\"}, {\"page\": 3, \"x\": 240.24099731445312, \"y\": 109.88751220703125, \"width\": 3.9820404052734375, \"height\": 6.97381591796875, \"color\": \"#FFFF00\"}, {\"page\": 3, \"x\": 244.22303771972656, \"y\": 108.83148193359375, \"width\": 259.77284240722656, \"height\": 13.49896240234375, \"color\": \"#FFFF00\"}, {\"page\": 3, \"x\": 108.0, \"y\": 99.41650390625, \"width\": 331.7229919433594, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 3, \"x\": 439.7229919433594, \"y\": 99.725341796875, \"width\": 7.670562744140625, \"height\": 9.96258544921875, \"color\": \"#FFFF00\"}, {\"page\": 3, \"x\": 447.39801025390625, \"y\": 98.9775390625, \"width\": 3.982025146484375, \"height\": 6.97381591796875, \"color\": \"#FFFF00\"}, {\"page\": 3, \"x\": 452.1319885253906, \"y\": 99.41650390625, \"width\": 51.868682861328125, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 3, \"x\": 120.65299987792969, \"y\": 85.47930908203125, \"width\": 2.988800048828125, \"height\": 7.2030029296875, \"color\": \"#FFFF00\"}, {\"page\": 3, \"x\": 123.86199951171875, \"y\": 80.8304443359375, \"width\": 263.9635925292969, \"height\": 10.80450439453125, \"color\": \"#FFFF00\"}, {\"page\": 3, \"x\": 387.8255920410156, \"y\": 81.1083984375, \"width\": 6.355987548828125, \"height\": 8.96636962890625, \"color\": \"#FFFF00\"}, {\"page\": 3, \"x\": 394.18157958984375, \"y\": 80.8304443359375, \"width\": 15.25592041015625, \"height\": 10.80450439453125, \"color\": \"#FFFF00\"}, {\"page\": 3, \"x\": 409.4375, \"y\": 81.1083984375, \"width\": 7.041534423828125, \"height\": 8.96636962890625, \"color\": \"#FFFF00\"}, {\"page\": 3, \"x\": 416.4790344238281, \"y\": 80.8304443359375, \"width\": 87.52273559570312, \"height\": 10.80450439453125, \"color\": \"#FFFF00\"}, {\"page\": 3, \"x\": 107.7760009765625, \"y\": 69.48046875, \"width\": 71.78419494628906, \"height\": 10.80450439453125, \"color\": \"#FFFF00\"}, {\"page\": 3, \"x\": 179.56019592285156, \"y\": 69.7584228515625, \"width\": 6.84356689453125, \"height\": 8.96636962890625, \"color\": \"#FFFF00\"}, {\"page\": 3, \"x\": 186.4037628173828, \"y\": 69.48046875, \"width\": 47.457305908203125, \"height\": 10.80450439453125, \"color\": \"#FFFF00\"}, {\"page\": 3, \"x\": 233.86106872558594, \"y\": 69.7584228515625, \"width\": 6.8376922607421875, \"height\": 8.96636962890625, \"color\": \"#FFFF00\"}, {\"page\": 3, \"x\": 240.70599365234375, \"y\": 69.48046875, \"width\": 87.46408081054688, \"height\": 10.80450439453125, \"color\": \"#FFFF00\"}, {\"page\": 3, \"x\": 328.1700744628906, \"y\": 69.7584228515625, \"width\": 6.358489990234375, \"height\": 8.96636962890625, \"color\": \"#FFFF00\"}, {\"page\": 3, \"x\": 334.528564453125, \"y\": 63.41021728515625, \"width\": 4.926849365234375, \"height\": 15.55670166015625, \"color\": \"#FFFF00\"}, {\"page\": 3, \"x\": 339.4554138183594, \"y\": 69.7584228515625, \"width\": 6.849609375, \"height\": 8.96636962890625, \"color\": \"#FFFF00\"}, {\"page\": 3, \"x\": 346.3050231933594, \"y\": 69.7584228515625, \"width\": 9.98712158203125, \"height\": 8.96636962890625, \"color\": \"#FFFF00\"}, {\"page\": 3, \"x\": 358.8559875488281, \"y\": 52.202392578125, \"width\": 9.719573974609375, \"height\": 33.44464111328125, \"color\": \"#FFFF00\"}, {\"page\": 3, \"x\": 368.5829772949219, \"y\": 74.76763916015625, \"width\": 3.837615966796875, \"height\": 5.97760009765625, \"color\": \"#FFFF00\"}, {\"page\": 3, \"x\": 372.4229736328125, \"y\": 73.61669921875, \"width\": 3.77581787109375, \"height\": 4.98126220703125, \"color\": \"#FFFF00\"}, {\"page\": 3, \"x\": 368.5829772949219, \"y\": 67.765625, \"width\": 2.6600341796875, \"height\": 5.97760009765625, \"color\": \"#FFFF00\"}, {\"page\": 3, \"x\": 371.2469787597656, \"y\": 67.765625, \"width\": 9.241363525390625, \"height\": 5.97760009765625, \"color\": \"#FFFF00\"}, {\"page\": 3, \"x\": 382.52398681640625, \"y\": 69.7584228515625, \"width\": 4.115570068359375, \"height\": 8.96636962890625, \"color\": \"#FFFF00\"}, {\"page\": 3, \"x\": 386.6409912109375, \"y\": 69.5096435546875, \"width\": 2.6600341796875, \"height\": 5.97760009765625, \"color\": \"#FFFF00\"}, {\"page\": 3, \"x\": 389.802978515625, \"y\": 69.7584228515625, \"width\": 4.797027587890625, \"height\": 8.96636962890625, \"color\": \"#FFFF00\"}, {\"page\": 3, \"x\": 394.6009826660156, \"y\": 69.5096435546875, \"width\": 2.6600341796875, \"height\": 5.97760009765625, \"color\": \"#FFFF00\"}, {\"page\": 3, \"x\": 397.76300048828125, \"y\": 69.48046875, \"width\": 37.992889404296875, \"height\": 10.80450439453125, \"color\": \"#FFFF00\"}, {\"page\": 3, \"x\": 435.7558898925781, \"y\": 69.7584228515625, \"width\": 6.844879150390625, \"height\": 8.96636962890625, \"color\": \"#FFFF00\"}, {\"page\": 3, \"x\": 442.60076904296875, \"y\": 69.48046875, \"width\": 47.45635986328125, \"height\": 10.80450439453125, \"color\": \"#FFFF00\"}, {\"page\": 3, \"x\": 490.05712890625, \"y\": 69.7584228515625, \"width\": 7.00897216796875, \"height\": 8.96636962890625, \"color\": \"#FFFF00\"}, {\"page\": 3, \"x\": 497.0699768066406, \"y\": 69.442626953125, \"width\": 3.945220947265625, \"height\": 5.97760009765625, \"color\": \"#FFFF00\"}, {\"page\": 3, \"x\": 501.64300537109375, \"y\": 69.48046875, \"width\": 2.23486328125, \"height\": 10.80450439453125, \"color\": \"#FFFF00\"}, {\"page\": 3, \"x\": 303.5090026855469, \"y\": 39.3125, \"width\": 4.981292724609375, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 4, \"x\": 108.0, \"y\": 707.2374954223633, \"width\": 395.99737548828125, \"height\": 12.004936218261719, \"color\": \"#FFFF00\"}]"}, "type": "Document"}
{"page_content": "depicted in Figure 2. Multi-head attention allows the model to jointly attend to information from different representation subspaces at different positions. With a single attention head, averaging inhibits this. MultiHead( Q, K, V  ) = Concat(head 1 , ...,  head h ) W O where  head i  = Attention( QW Q i , KW  K i , V W  V i ) Where the projections are parameter matrices  W Q i ∈ R d model × d k ,  W K i ∈ R d model × d k ,  W V i ∈ R d model × d v and  W O ∈ R hd v × d model . In this work we employ  h  = 8  parallel attention layers, or heads. For each of these we use d k  =  d v  =  d model /h  = 64 . Due to the reduced dimension of each head, the total computational cost is similar to that of single-head attention with full dimensionality. 3.2.3 Applications of Attention in our Model The Transformer uses multi-head attention in three different ways: •  In \"encoder-decoder attention\" layers, the queries come from the previous decoder layer,", "metadata": {"source": "../paper/attention_is_all_you_need.pdf", "title": "", "pid": "12", "annotations": "[{\"page\": 4, \"x\": 108.0, \"y\": 696.328498840332, \"width\": 82.46041870117188, \"height\": 12.004936218261719, \"color\": \"#FFFF00\"}, {\"page\": 4, \"x\": 108.0, \"y\": 679.9404983520508, \"width\": 395.996826171875, \"height\": 12.004936218261719, \"color\": \"#FFFF00\"}, {\"page\": 4, \"x\": 108.0, \"y\": 669.0315017700195, \"width\": 337.1941223144531, \"height\": 12.004936218261719, \"color\": \"#FFFF00\"}, {\"page\": 4, \"x\": 186.94000244140625, \"y\": 634.1273345947266, \"width\": 50.37092590332031, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 4, \"x\": 237.3070068359375, \"y\": 634.1273345947266, \"width\": 31.162994384765625, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 4, \"x\": 268.4700012207031, \"y\": 634.1273345947266, \"width\": 74.72183227539062, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 4, \"x\": 343.19000244140625, \"y\": 633.3795318603516, \"width\": 3.96807861328125, \"height\": 6.9738006591796875, \"color\": \"#FFFF00\"}, {\"page\": 4, \"x\": 347.6600036621094, \"y\": 634.1273345947266, \"width\": 15.50177001953125, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 4, \"x\": 363.1617736816406, \"y\": 634.1273345947266, \"width\": 22.128387451171875, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 4, \"x\": 385.2960205078125, \"y\": 633.3795318603516, \"width\": 4.39349365234375, \"height\": 6.9738006591796875, \"color\": \"#FFFF00\"}, {\"page\": 4, \"x\": 390.19403076171875, \"y\": 634.1273345947266, \"width\": 3.865478515625, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 4, \"x\": 394.06903076171875, \"y\": 634.1273345947266, \"width\": 9.404693603515625, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 4, \"x\": 404.8620300292969, \"y\": 638.9875030517578, \"width\": 6.053253173828125, \"height\": 6.9738006591796875, \"color\": \"#FFFF00\"}, {\"page\": 4, \"x\": 224.4970245361328, \"y\": 617.0074615478516, \"width\": 24.338638305664062, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 4, \"x\": 248.83566284179688, \"y\": 617.3162994384766, \"width\": 22.9635009765625, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 4, \"x\": 271.8050231933594, \"y\": 616.5684967041016, \"width\": 2.252532958984375, \"height\": 6.9738006591796875, \"color\": \"#FFFF00\"}, {\"page\": 4, \"x\": 274.05755615234375, \"y\": 615.8213043212891, \"width\": 59.44757080078125, \"height\": 11.457595825195312, \"color\": \"#FFFF00\"}, {\"page\": 4, \"x\": 333.5040283203125, \"y\": 617.3162994384766, \"width\": 17.28509521484375, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 4, \"x\": 352.17303466796875, \"y\": 622.8504791259766, \"width\": 6.269439697265625, \"height\": 6.9738006591796875, \"color\": \"#FFFF00\"}, {\"page\": 4, \"x\": 350.7890319824219, \"y\": 615.2864532470703, \"width\": 2.817413330078125, \"height\": 6.9738006591796875, \"color\": \"#FFFF00\"}, {\"page\": 4, \"x\": 358.9450378417969, \"y\": 617.3162384033203, \"width\": 23.003631591796875, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 4, \"x\": 381.94866943359375, \"y\": 618.0634307861328, \"width\": 8.0792236328125, \"height\": 11.086776733398438, \"color\": \"#FFFF00\"}, {\"page\": 4, \"x\": 381.9560241699219, \"y\": 615.6004180908203, \"width\": 2.817413330078125, \"height\": 6.9738006591796875, \"color\": \"#FFFF00\"}, {\"page\": 4, \"x\": 391.0210266113281, \"y\": 617.3162384033203, \"width\": 21.857940673828125, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 4, \"x\": 412.87896728515625, \"y\": 618.0634307861328, \"width\": 6.088409423828125, \"height\": 11.086776733398438, \"color\": \"#FFFF00\"}, {\"page\": 4, \"x\": 412.8830261230469, \"y\": 615.6004180908203, \"width\": 2.817413330078125, \"height\": 6.9738006591796875, \"color\": \"#FFFF00\"}, {\"page\": 4, \"x\": 421.18603515625, \"y\": 617.3162384033203, \"width\": 3.865478515625, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 4, \"x\": 107.53199768066406, \"y\": 575.8925323486328, \"width\": 176.1991729736328, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 4, \"x\": 283.7311706542969, \"y\": 576.2013702392578, \"width\": 11.568511962890625, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 4, \"x\": 296.6869812011719, \"y\": 581.7355499267578, \"width\": 6.269439697265625, \"height\": 6.9738006591796875, \"color\": \"#FFFF00\"}, {\"page\": 4, \"x\": 295.3039855957031, \"y\": 574.1715240478516, \"width\": 2.817413330078125, \"height\": 6.9738006591796875, \"color\": \"#FFFF00\"}, {\"page\": 4, \"x\": 306.22698974609375, \"y\": 569.1278533935547, \"width\": 6.635101318359375, \"height\": 17.285110473632812, \"color\": \"#FFFF00\"}, {\"page\": 4, \"x\": 315.635986328125, \"y\": 574.5076599121094, \"width\": 7.1929931640625, \"height\": 13.349884033203125, \"color\": \"#FFFF00\"}, {\"page\": 4, \"x\": 322.83099365234375, \"y\": 580.5634918212891, \"width\": 4.142425537109375, \"height\": 6.9738006591796875, \"color\": \"#FFFF00\"}, {\"page\": 4, \"x\": 326.97900390625, \"y\": 579.9112243652344, \"width\": 12.453277587890625, \"height\": 6.002471923828125, \"color\": \"#FFFF00\"}, {\"page\": 4, \"x\": 339.92999267578125, \"y\": 575.6748657226562, \"width\": 6.22064208984375, \"height\": 12.085586547851562, \"color\": \"#FFFF00\"}, {\"page\": 4, \"x\": 346.156982421875, \"y\": 580.5634918212891, \"width\": 4.142425537109375, \"height\": 6.9738006591796875, \"color\": \"#FFFF00\"}, {\"page\": 4, \"x\": 350.3039855957031, \"y\": 580.0046081542969, \"width\": 3.77581787109375, \"height\": 4.9813079833984375, \"color\": \"#FFFF00\"}, {\"page\": 4, \"x\": 355.1570129394531, \"y\": 575.8925323486328, \"width\": 2.440826416015625, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 4, \"x\": 357.59783935546875, \"y\": 576.2013702392578, \"width\": 11.6358642578125, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 4, \"x\": 370.62200927734375, \"y\": 580.5635528564453, \"width\": 6.6878662109375, \"height\": 6.9738006591796875, \"color\": \"#FFFF00\"}, {\"page\": 4, \"x\": 369.2380065917969, \"y\": 574.3555450439453, \"width\": 2.817413330078125, \"height\": 6.9738006591796875, \"color\": \"#FFFF00\"}, {\"page\": 4, \"x\": 381.07000732421875, \"y\": 569.1279144287109, \"width\": 6.635101318359375, \"height\": 17.285110473632812, \"color\": \"#FFFF00\"}, {\"page\": 4, \"x\": 390.47900390625, \"y\": 574.5077209472656, \"width\": 7.1929931640625, \"height\": 13.349884033203125, \"color\": \"#FFFF00\"}, {\"page\": 4, \"x\": 397.67401123046875, \"y\": 580.5635528564453, \"width\": 4.142425537109375, \"height\": 6.9738006591796875, \"color\": \"#FFFF00\"}, {\"page\": 4, \"x\": 401.822021484375, \"y\": 579.9112854003906, \"width\": 12.453277587890625, \"height\": 6.002471923828125, \"color\": \"#FFFF00\"}, {\"page\": 4, \"x\": 414.77301025390625, \"y\": 575.6749267578125, \"width\": 6.22064208984375, \"height\": 12.085586547851562, \"color\": \"#FFFF00\"}, {\"page\": 4, \"x\": 421.0, \"y\": 580.5635528564453, \"width\": 4.142425537109375, \"height\": 6.9738006591796875, \"color\": \"#FFFF00\"}, {\"page\": 4, \"x\": 425.1470031738281, \"y\": 580.0046691894531, \"width\": 3.77581787109375, \"height\": 4.9813079833984375, \"color\": \"#FFFF00\"}, {\"page\": 4, \"x\": 430.0, \"y\": 575.8925323486328, \"width\": 2.440826416015625, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 4, \"x\": 432.4408264160156, \"y\": 576.2013702392578, \"width\": 11.6358642578125, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 4, \"x\": 445.4649963378906, \"y\": 580.5635528564453, \"width\": 4.700347900390625, \"height\": 6.9738006591796875, \"color\": \"#FFFF00\"}, {\"page\": 4, \"x\": 444.08099365234375, \"y\": 574.3555450439453, \"width\": 2.817413330078125, \"height\": 6.9738006591796875, \"color\": \"#FFFF00\"}, {\"page\": 4, \"x\": 455.1499938964844, \"y\": 569.1279144287109, \"width\": 6.635101318359375, \"height\": 17.285110473632812, \"color\": \"#FFFF00\"}, {\"page\": 4, \"x\": 464.55999755859375, \"y\": 574.5077209472656, \"width\": 7.1929931640625, \"height\": 13.349884033203125, \"color\": \"#FFFF00\"}, {\"page\": 4, \"x\": 471.7550048828125, \"y\": 580.5635528564453, \"width\": 4.142425537109375, \"height\": 6.9738006591796875, \"color\": \"#FFFF00\"}, {\"page\": 4, \"x\": 475.9020080566406, \"y\": 579.9112854003906, \"width\": 12.453277587890625, \"height\": 6.002471923828125, \"color\": \"#FFFF00\"}, {\"page\": 4, \"x\": 488.8529968261719, \"y\": 575.6749267578125, \"width\": 6.22064208984375, \"height\": 12.085586547851562, \"color\": \"#FFFF00\"}, {\"page\": 4, \"x\": 495.0799865722656, \"y\": 580.5635528564453, \"width\": 4.142425537109375, \"height\": 6.9738006591796875, \"color\": \"#FFFF00\"}, {\"page\": 4, \"x\": 499.22698974609375, \"y\": 580.0657043457031, \"width\": 3.59649658203125, \"height\": 4.9813079833984375, \"color\": \"#FFFF00\"}, {\"page\": 4, \"x\": 108.0, \"y\": 563.6605377197266, \"width\": 14.385993957519531, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 4, \"x\": 122.38599395751953, \"y\": 563.9693756103516, \"width\": 11.895698547363281, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 4, \"x\": 135.6699981689453, \"y\": 568.3325958251953, \"width\": 6.053253173828125, \"height\": 6.9738006591796875, \"color\": \"#FFFF00\"}, {\"page\": 4, \"x\": 145.20899963378906, \"y\": 556.8959197998047, \"width\": 6.6350860595703125, \"height\": 17.285110473632812, \"color\": \"#FFFF00\"}, {\"page\": 4, \"x\": 154.6179962158203, \"y\": 562.2757263183594, \"width\": 7.1929931640625, \"height\": 13.349884033203125, \"color\": \"#FFFF00\"}, {\"page\": 4, \"x\": 161.81399536132812, \"y\": 568.3325958251953, \"width\": 8.807907104492188, \"height\": 6.9738006591796875, \"color\": \"#FFFF00\"}, {\"page\": 4, \"x\": 170.625, \"y\": 567.8337097167969, \"width\": 3.59649658203125, \"height\": 4.9813079833984375, \"color\": \"#FFFF00\"}, {\"page\": 4, \"x\": 174.89999389648438, \"y\": 563.4439697265625, \"width\": 6.2206268310546875, \"height\": 12.085586547851562, \"color\": \"#FFFF00\"}, {\"page\": 4, \"x\": 181.12599182128906, \"y\": 568.3325958251953, \"width\": 4.1424407958984375, \"height\": 6.9738006591796875, \"color\": \"#FFFF00\"}, {\"page\": 4, \"x\": 185.27398681640625, \"y\": 567.6792907714844, \"width\": 12.4532470703125, \"height\": 6.002471923828125, \"color\": \"#FFFF00\"}, {\"page\": 4, \"x\": 198.72299194335938, \"y\": 563.6605377197266, \"width\": 2.4906463623046875, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 4, \"x\": 108.0, \"y\": 547.2725372314453, \"width\": 101.791259765625, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 4, \"x\": 209.791259765625, \"y\": 547.5813751220703, \"width\": 9.6422119140625, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 4, \"x\": 219.4334716796875, \"y\": 547.5813751220703, \"width\": 23.510498046875, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 4, \"x\": 242.9439697265625, \"y\": 547.2725372314453, \"width\": 261.0581359863281, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 4, \"x\": 108.0, \"y\": 536.6723785400391, \"width\": 5.180549621582031, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 4, \"x\": 113.18499755859375, \"y\": 535.9245910644531, \"width\": 4.23309326171875, \"height\": 6.973785400390625, \"color\": \"#FFFF00\"}, {\"page\": 4, \"x\": 117.4180908203125, \"y\": 535.1773681640625, \"width\": 11.181838989257812, \"height\": 11.457611083984375, \"color\": \"#FFFF00\"}, {\"page\": 4, \"x\": 128.5999298095703, \"y\": 536.6723785400391, \"width\": 7.959625244140625, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 4, \"x\": 136.56399536132812, \"y\": 535.9245910644531, \"width\": 3.9820404052734375, \"height\": 6.973785400390625, \"color\": \"#FFFF00\"}, {\"page\": 4, \"x\": 140.54603576660156, \"y\": 535.1773681640625, \"width\": 11.263900756835938, \"height\": 11.457611083984375, \"color\": \"#FFFF00\"}, {\"page\": 4, \"x\": 151.8099365234375, \"y\": 536.6723785400391, \"width\": 7.959625244140625, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 4, \"x\": 159.77500915527344, \"y\": 535.7084045410156, \"width\": 17.434494018554688, \"height\": 8.403411865234375, \"color\": \"#FFFF00\"}, {\"page\": 4, \"x\": 177.70700073242188, \"y\": 536.6723785400391, \"width\": 10.719757080078125, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 4, \"x\": 188.4267578125, \"y\": 536.6723785400391, \"width\": 23.256332397460938, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 4, \"x\": 211.68299865722656, \"y\": 536.3635406494141, \"width\": 292.31394958496094, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 4, \"x\": 108.0, \"y\": 525.4534912109375, \"width\": 261.1495361328125, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 4, \"x\": 108.0, \"y\": 500.6837463378906, \"width\": 19.925193786621094, \"height\": 12.961334228515625, \"color\": \"#FFFF00\"}, {\"page\": 4, \"x\": 137.88778686523438, \"y\": 500.6837463378906, \"width\": 164.970703125, \"height\": 12.961334228515625, \"color\": \"#FFFF00\"}, {\"page\": 4, \"x\": 107.69100189208984, \"y\": 482.22747802734375, \"width\": 264.91544342041016, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 4, \"x\": 135.39700317382812, \"y\": 461.38348388671875, \"width\": 3.486907958984375, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 4, \"x\": 138.8839111328125, \"y\": 461.38348388671875, \"width\": 366.3582458496094, \"height\": 12.004974365234375, \"color\": \"#FFFF00\"}]"}, "type": "Document"}
{"page_content": "and the memory keys and values come from the output of the encoder. This allows every position in the decoder to attend over all positions in the input sequence. This mimics the typical encoder-decoder attention mechanisms in sequence-to-sequence models such as [38, 2, 9]. •  The encoder contains self-attention layers. In a self-attention layer all of the keys, values and queries come from the same place, in this case, the output of the previous layer in the encoder. Each position in the encoder can attend to all positions in the previous layer of the encoder. •  Similarly, self-attention layers in the decoder allow each position in the decoder to attend to all positions in the decoder up to and including that position. We need to prevent leftward information flow in the decoder to preserve the auto-regressive property. We implement this inside of scaled dot-product attention by masking out (setting to  −∞ ) all values in the input", "metadata": {"source": "../paper/attention_is_all_you_need.pdf", "title": "", "pid": "13", "annotations": "[{\"page\": 4, \"x\": 143.86599731445312, \"y\": 450.4735107421875, \"width\": 360.4817810058594, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 4, \"x\": 143.86599731445312, \"y\": 439.56451416015625, \"width\": 360.1287536621094, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 4, \"x\": 143.86599731445312, \"y\": 428.6554870605469, \"width\": 360.1363525390625, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 4, \"x\": 143.86599731445312, \"y\": 417.7464904785156, \"width\": 39.01350402832031, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 4, \"x\": 135.39700317382812, \"y\": 401.9104919433594, \"width\": 3.486907958984375, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 4, \"x\": 138.8839111328125, \"y\": 401.9104919433594, \"width\": 365.1141662597656, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 4, \"x\": 143.86599731445312, \"y\": 391.0014953613281, \"width\": 360.1343078613281, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 4, \"x\": 143.86599731445312, \"y\": 380.0924987792969, \"width\": 360.1372375488281, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 4, \"x\": 143.86599731445312, \"y\": 369.1835021972656, \"width\": 33.474334716796875, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 4, \"x\": 135.39700317382812, \"y\": 353.3475036621094, \"width\": 3.486907958984375, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 4, \"x\": 138.8839111328125, \"y\": 353.3475036621094, \"width\": 365.1155700683594, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 4, \"x\": 143.86599731445312, \"y\": 342.4385070800781, \"width\": 360.1371154785156, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 4, \"x\": 143.86599731445312, \"y\": 331.5295104980469, \"width\": 360.13653564453125, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 4, \"x\": 143.86599731445312, \"y\": 320.6205139160156, \"width\": 250.18582153320312, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 4, \"x\": 394.05181884765625, \"y\": 313.8559265136719, \"width\": 20.201690673828125, \"height\": 17.28509521484375, \"color\": \"#FFFF00\"}, {\"page\": 4, \"x\": 414.2510070800781, \"y\": 320.6205139160156, \"width\": 89.74472045898438, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}]"}, "type": "Document"}
{"page_content": "of the softmax which correspond to illegal connections. See Figure 2. 3.3 Position-wise Feed-Forward Networks In addition to attention sub-layers, each of the layers in our encoder and decoder contains a fully connected feed-forward network, which is applied to each position separately and identically. This consists of two linear transformations with a ReLU activation in between. FFN( x ) = max(0 , xW 1  +  b 1 ) W 2  +  b 2 (2) While the linear transformations are the same across different positions, they use different parameters from layer to layer. Another way of describing this is as two convolutions with kernel size 1. The dimensionality of input and output is  d model  = 512 , and the inner-layer has dimensionality d ff  = 2048 . 3.4 Embeddings and Softmax Similarly to other sequence transduction models, we use learned embeddings to convert the input tokens and output tokens to vectors of dimension  d model . We also use the usual learned linear transfor-", "metadata": {"source": "../paper/attention_is_all_you_need.pdf", "title": "", "pid": "14", "annotations": "[{\"page\": 4, \"x\": 143.86599731445312, \"y\": 309.71148681640625, \"width\": 277.0997314453125, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 4, \"x\": 108.0, \"y\": 283.5957336425781, \"width\": 12.4532470703125, \"height\": 12.961334228515625, \"color\": \"#FFFF00\"}, {\"page\": 4, \"x\": 130.4158477783203, \"y\": 283.5957336425781, \"width\": 162.4501495361328, \"height\": 12.961334228515625, \"color\": \"#FFFF00\"}, {\"page\": 4, \"x\": 108.0, \"y\": 263.79449462890625, \"width\": 396.3429260253906, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 4, \"x\": 108.0, \"y\": 252.885498046875, \"width\": 395.9985656738281, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 4, \"x\": 108.0, \"y\": 241.97650146484375, \"width\": 293.5380859375, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 4, \"x\": 226.9010009765625, \"y\": 213.57537841796875, \"width\": 24.348617553710938, \"height\": 9.96258544921875, \"color\": \"#FFFF00\"}, {\"page\": 4, \"x\": 251.25399780273438, \"y\": 213.57537841796875, \"width\": 5.688629150390625, \"height\": 9.96258544921875, \"color\": \"#FFFF00\"}, {\"page\": 4, \"x\": 256.947998046875, \"y\": 213.57537841796875, \"width\": 44.562713623046875, \"height\": 9.96258544921875, \"color\": \"#FFFF00\"}, {\"page\": 4, \"x\": 301.50299072265625, \"y\": 213.57537841796875, \"width\": 19.536651611328125, \"height\": 9.96258544921875, \"color\": \"#FFFF00\"}, {\"page\": 4, \"x\": 321.03399658203125, \"y\": 212.82855224609375, \"width\": 3.96807861328125, \"height\": 6.97381591796875, \"color\": \"#FFFF00\"}, {\"page\": 4, \"x\": 325.0020751953125, \"y\": 212.08135986328125, \"width\": 10.45587158203125, \"height\": 11.45660400390625, \"color\": \"#FFFF00\"}, {\"page\": 4, \"x\": 335.45794677734375, \"y\": 213.57537841796875, \"width\": 6.49603271484375, \"height\": 9.96258544921875, \"color\": \"#FFFF00\"}, {\"page\": 4, \"x\": 341.95501708984375, \"y\": 212.82855224609375, \"width\": 3.96807861328125, \"height\": 6.97381591796875, \"color\": \"#FFFF00\"}, {\"page\": 4, \"x\": 346.4250183105469, \"y\": 213.57537841796875, \"width\": 3.865478515625, \"height\": 9.96258544921875, \"color\": \"#FFFF00\"}, {\"page\": 4, \"x\": 350.29901123046875, \"y\": 213.57537841796875, \"width\": 9.404693603515625, \"height\": 9.96258544921875, \"color\": \"#FFFF00\"}, {\"page\": 4, \"x\": 359.7080078125, \"y\": 212.82855224609375, \"width\": 3.96807861328125, \"height\": 6.97381591796875, \"color\": \"#FFFF00\"}, {\"page\": 4, \"x\": 363.67608642578125, \"y\": 212.08135986328125, \"width\": 10.45684814453125, \"height\": 11.45660400390625, \"color\": \"#FFFF00\"}, {\"page\": 4, \"x\": 374.1329345703125, \"y\": 213.57537841796875, \"width\": 6.495025634765625, \"height\": 9.96258544921875, \"color\": \"#FFFF00\"}, {\"page\": 4, \"x\": 380.6300048828125, \"y\": 212.82855224609375, \"width\": 3.96807861328125, \"height\": 6.97381591796875, \"color\": \"#FFFF00\"}, {\"page\": 4, \"x\": 493.0509948730469, \"y\": 213.26654052734375, \"width\": 11.616363525390625, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 4, \"x\": 107.53199768066406, \"y\": 191.48052978515625, \"width\": 396.47007751464844, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 4, \"x\": 108.0, \"y\": 180.57147216796875, \"width\": 397.74517822265625, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 4, \"x\": 107.69100189208984, \"y\": 169.66253662109375, \"width\": 173.3815689086914, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 4, \"x\": 281.07257080078125, \"y\": 169.97137451171875, \"width\": 8.573974609375, \"height\": 9.96258544921875, \"color\": \"#FFFF00\"}, {\"page\": 4, \"x\": 289.6510009765625, \"y\": 169.00836181640625, \"width\": 17.434539794921875, \"height\": 8.4034423828125, \"color\": \"#FFFF00\"}, {\"page\": 4, \"x\": 307.0855407714844, \"y\": 168.47735595703125, \"width\": 32.081573486328125, \"height\": 11.45660400390625, \"color\": \"#FFFF00\"}, {\"page\": 4, \"x\": 339.1679992675781, \"y\": 169.66253662109375, \"width\": 165.1810302734375, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 4, \"x\": 108.0, \"y\": 159.06231689453125, \"width\": 5.180549621582031, \"height\": 9.96258544921875, \"color\": \"#FFFF00\"}, {\"page\": 4, \"x\": 113.18499755859375, \"y\": 158.31451416015625, \"width\": 8.549880981445312, \"height\": 6.97381591796875, \"color\": \"#FFFF00\"}, {\"page\": 4, \"x\": 121.73487854003906, \"y\": 157.56732177734375, \"width\": 34.49479675292969, \"height\": 11.45758056640625, \"color\": \"#FFFF00\"}, {\"page\": 4, \"x\": 156.22499084472656, \"y\": 158.75347900390625, \"width\": 2.4906463623046875, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 4, \"x\": 107.99999237060547, \"y\": 132.63775634765625, \"width\": 12.4532470703125, \"height\": 12.9613037109375, \"color\": \"#FFFF00\"}, {\"page\": 4, \"x\": 130.41583251953125, \"y\": 132.63775634765625, \"width\": 109.60845947265625, \"height\": 12.9613037109375, \"color\": \"#FFFF00\"}, {\"page\": 4, \"x\": 108.0, \"y\": 112.83648681640625, \"width\": 395.9974365234375, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 4, \"x\": 108.0, \"y\": 101.927490234375, \"width\": 191.24447631835938, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 4, \"x\": 299.2444763183594, \"y\": 102.236328125, \"width\": 7.60107421875, \"height\": 9.96258544921875, \"color\": \"#FFFF00\"}, {\"page\": 4, \"x\": 306.8500061035156, \"y\": 101.2733154296875, \"width\": 17.434539794921875, \"height\": 8.4034423828125, \"color\": \"#FFFF00\"}, {\"page\": 4, \"x\": 324.7829895019531, \"y\": 101.927490234375, \"width\": 180.8662109375, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}]"}, "type": "Document"}
{"page_content": "mation and softmax function to convert the decoder output to predicted next-token probabilities. In our model, we share the same weight matrix between the two embedding layers and the pre-softmax linear transformation, similar to [ 30 ]. In the embedding layers, we multiply those weights by √ d model . 5 Table 1: Maximum path lengths, per-layer complexity and minimum number of sequential operations for different layer types.  n  is the sequence length,  d  is the representation dimension,  k  is the kernel size of convolutions and  r  the size of the neighborhood in restricted self-attention. Layer Type Complexity per Layer Sequential Maximum Path Length Operations Self-Attention O ( n 2 ·  d ) O (1) O (1) Recurrent O ( n  ·  d 2 ) O ( n ) O ( n ) Convolutional O ( k  ·  n  ·  d 2 ) O (1) O ( log k ( n )) Self-Attention (restricted) O ( r  ·  n  ·  d ) O (1) O ( n/r ) 3.5 Positional Encoding", "metadata": {"source": "../paper/attention_is_all_you_need.pdf", "title": "", "pid": "15", "annotations": "[{\"page\": 4, \"x\": 108.0, \"y\": 91.01849365234375, \"width\": 395.9967956542969, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 4, \"x\": 108.0, \"y\": 80.1094970703125, \"width\": 396.2503662109375, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 4, \"x\": 108.0, \"y\": 69.20050048828125, \"width\": 129.55966186523438, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 4, \"x\": 237.55999755859375, \"y\": 69.20050048828125, \"width\": 9.96258544921875, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 4, \"x\": 247.5229949951172, \"y\": 69.20050048828125, \"width\": 222.0088653564453, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 4, \"x\": 471.8819885253906, \"y\": 70.1439208984375, \"width\": 8.298858642578125, \"height\": 17.28509521484375, \"color\": \"#FFFF00\"}, {\"page\": 4, \"x\": 480.18499755859375, \"y\": 69.50933837890625, \"width\": 5.1805419921875, \"height\": 9.96258544921875, \"color\": \"#FFFF00\"}, {\"page\": 4, \"x\": 485.3699951171875, \"y\": 68.54632568359375, \"width\": 17.434539794921875, \"height\": 8.4034423828125, \"color\": \"#FFFF00\"}, {\"page\": 4, \"x\": 503.3030090332031, \"y\": 69.20050048828125, \"width\": 2.440826416015625, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 4, \"x\": 303.5090026855469, \"y\": 39.3125, \"width\": 4.981292724609375, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 107.69100189208984, \"y\": 710.4455032348633, \"width\": 396.30411529541016, \"height\": 12.004936218261719, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 108.0, \"y\": 699.536506652832, \"width\": 97.02030944824219, \"height\": 12.004936218261719, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 205.0203094482422, \"y\": 699.8453521728516, \"width\": 9.071243286132812, \"height\": 9.962593078613281, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 214.091552734375, \"y\": 699.536506652832, \"width\": 93.10580444335938, \"height\": 12.004936218261719, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 307.1973571777344, \"y\": 699.8453521728516, \"width\": 7.676177978515625, \"height\": 9.962593078613281, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 314.87353515625, \"y\": 699.536506652832, \"width\": 129.8233642578125, \"height\": 12.004936218261719, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 444.6968994140625, \"y\": 699.8453521728516, \"width\": 7.675628662109375, \"height\": 9.962593078613281, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 452.3725280761719, \"y\": 699.536506652832, \"width\": 51.63104248046875, \"height\": 12.004936218261719, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 108.0, \"y\": 688.6275100708008, \"width\": 96.527587890625, \"height\": 12.004936218261719, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 204.527587890625, \"y\": 688.9363555908203, \"width\": 6.983551025390625, \"height\": 9.962593078613281, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 211.51113891601562, \"y\": 688.6275100708008, \"width\": 223.56982421875, \"height\": 12.004936218261719, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 124.5469970703125, \"y\": 665.0065383911133, \"width\": 45.39955139160156, \"height\": 12.004936218261719, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 239.70468139648438, \"y\": 665.0065383911133, \"width\": 87.8402099609375, \"height\": 12.004936218261719, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 340.326904296875, \"y\": 665.0065383911133, \"width\": 42.06207275390625, \"height\": 12.004936218261719, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 395.1709899902344, \"y\": 665.0065383911133, \"width\": 92.2835693359375, \"height\": 12.004936218261719, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 339.4989929199219, \"y\": 654.0975494384766, \"width\": 43.715850830078125, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 124.5469970703125, \"y\": 641.4605255126953, \"width\": 57.006011962890625, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 264.39599609375, \"y\": 641.7693634033203, \"width\": 7.59149169921875, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 272.2720031738281, \"y\": 641.7693634033203, \"width\": 3.865478515625, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 276.1470031738281, \"y\": 641.7693634033203, \"width\": 5.977569580078125, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 282.12701416015625, \"y\": 646.1315460205078, \"width\": 3.96807861328125, \"height\": 6.9738006591796875, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 288.8100280761719, \"y\": 634.6959075927734, \"width\": 2.7596435546875, \"height\": 17.285110473632812, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 291.5696716308594, \"y\": 641.7693634033203, \"width\": 7.401885986328125, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 298.9770202636719, \"y\": 641.7693634033203, \"width\": 3.865478515625, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 351.05401611328125, \"y\": 641.7693634033203, \"width\": 7.59149169921875, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 358.9300231933594, \"y\": 641.7693634033203, \"width\": 12.72222900390625, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 431.0080261230469, \"y\": 641.7693634033203, \"width\": 7.59149169921875, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 438.884033203125, \"y\": 641.7693634033203, \"width\": 12.72222900390625, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 124.54702758789062, \"y\": 630.0775299072266, \"width\": 39.28254699707031, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 264.3960266113281, \"y\": 630.3863677978516, \"width\": 7.59149169921875, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 272.27203369140625, \"y\": 630.3863677978516, \"width\": 3.865478515625, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 276.14703369140625, \"y\": 630.3863677978516, \"width\": 5.977569580078125, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 282.1246032714844, \"y\": 623.3129119873047, \"width\": 4.97607421875, \"height\": 17.285110473632812, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 287.1006774902344, \"y\": 630.3863677978516, \"width\": 7.401885986328125, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 294.50701904296875, \"y\": 634.7495880126953, \"width\": 3.96807861328125, \"height\": 6.9738006591796875, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 298.9770202636719, \"y\": 630.3863677978516, \"width\": 3.865478515625, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 350.55401611328125, \"y\": 630.3863677978516, \"width\": 7.59149169921875, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 358.4300231933594, \"y\": 630.3863677978516, \"width\": 3.865478515625, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 362.3050231933594, \"y\": 630.3863677978516, \"width\": 5.977569580078125, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 368.2850341796875, \"y\": 630.3863677978516, \"width\": 3.865478515625, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 430.509033203125, \"y\": 630.3863677978516, \"width\": 7.59149169921875, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 438.3850402832031, \"y\": 630.3863677978516, \"width\": 3.865478515625, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 442.259033203125, \"y\": 630.3863677978516, \"width\": 5.977569580078125, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 448.2390441894531, \"y\": 630.3863677978516, \"width\": 3.865478515625, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 124.54705810546875, \"y\": 618.6955108642578, \"width\": 56.418182373046875, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 258.049072265625, \"y\": 619.0043487548828, \"width\": 7.59149169921875, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 265.9250793457031, \"y\": 619.0043487548828, \"width\": 3.865478515625, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 269.799072265625, \"y\": 619.0043487548828, \"width\": 5.1805419921875, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 274.9796142578125, \"y\": 611.9308929443359, \"width\": 5.2930908203125, \"height\": 17.285110473632812, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 280.272705078125, \"y\": 619.0043487548828, \"width\": 8.199920654296875, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 288.4726257324219, \"y\": 611.9308929443359, \"width\": 4.975067138671875, \"height\": 17.285110473632812, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 293.44769287109375, \"y\": 619.0043487548828, \"width\": 7.40289306640625, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 300.85504150390625, \"y\": 623.3665313720703, \"width\": 3.96807861328125, \"height\": 6.9738006591796875, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 305.32403564453125, \"y\": 619.0043487548828, \"width\": 3.865478515625, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 351.0540466308594, \"y\": 619.0043487548828, \"width\": 7.59149169921875, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 358.9300537109375, \"y\": 619.0043487548828, \"width\": 12.72222900390625, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 417.8090515136719, \"y\": 619.0043487548828, \"width\": 7.59149169921875, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 425.68505859375, \"y\": 619.0043487548828, \"width\": 3.865478515625, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 429.5590515136719, \"y\": 619.0043487548828, \"width\": 12.74212646484375, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 442.3090515136719, \"y\": 618.2565460205078, \"width\": 4.23309326171875, \"height\": 6.9738006591796875, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 447.2110595703125, \"y\": 619.0043487548828, \"width\": 3.865478515625, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 451.0850524902344, \"y\": 619.0043487548828, \"width\": 5.977569580078125, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 457.0650634765625, \"y\": 619.0043487548828, \"width\": 7.740936279296875, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 124.54705810546875, \"y\": 607.7865142822266, \"width\": 103.20263671875, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 260.6480712890625, \"y\": 608.0953521728516, \"width\": 7.59149169921875, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 268.5240783691406, \"y\": 608.0953521728516, \"width\": 3.865478515625, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 272.3980712890625, \"y\": 608.0953521728516, \"width\": 4.493133544921875, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 276.8912048339844, \"y\": 601.0218963623047, \"width\": 5.25250244140625, \"height\": 17.285110473632812, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 282.1437072753906, \"y\": 608.0953521728516, \"width\": 8.19891357421875, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 290.3426208496094, \"y\": 601.0218963623047, \"width\": 4.97607421875, \"height\": 17.285110473632812, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 295.3186950683594, \"y\": 608.0953521728516, \"width\": 7.401885986328125, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 302.72503662109375, \"y\": 608.0953521728516, \"width\": 3.865478515625, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 351.0540466308594, \"y\": 608.0953521728516, \"width\": 7.59149169921875, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 358.9300537109375, \"y\": 608.0953521728516, \"width\": 12.72222900390625, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 425.633056640625, \"y\": 608.0953521728516, \"width\": 7.59149169921875, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 433.5090637207031, \"y\": 608.0953521728516, \"width\": 3.865478515625, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 437.383056640625, \"y\": 608.0953521728516, \"width\": 15.451995849609375, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 453.1160583496094, \"y\": 608.0953521728516, \"width\": 3.865478515625, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 108.0, \"y\": 567.1657409667969, \"width\": 12.4532470703125, \"height\": 12.961349487304688, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 130.4158477783203, \"y\": 567.1657409667969, \"width\": 84.78169250488281, \"height\": 12.961349487304688, \"color\": \"#FFFF00\"}]"}, "type": "Document"}
{"page_content": "Since our model contains no recurrence and no convolution, in order for the model to make use of the order of the sequence, we must inject some information about the relative or absolute position of the tokens in the sequence. To this end, we add \"positional encodings\" to the input embeddings at the bottoms of the encoder and decoder stacks. The positional encodings have the same dimension  d model as the embeddings, so that the two can be summed. There are many choices of positional encodings, learned and fixed [9]. In this work, we use sine and cosine functions of different frequencies: PE ( pos, 2 i )  =  sin ( pos/ 10000 2 i/d model ) PE ( pos, 2 i +1)  =  cos ( pos/ 10000 2 i/d model ) where  pos  is the position and  i  is the dimension. That is, each dimension of the positional encoding corresponds to a sinusoid. The wavelengths form a geometric progression from  2 π  to  10000  ·  2 π . We", "metadata": {"source": "../paper/attention_is_all_you_need.pdf", "title": "", "pid": "16", "annotations": "[{\"page\": 5, \"x\": 108.0, \"y\": 547.7885284423828, \"width\": 396.0016784667969, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 108.0, \"y\": 536.8795318603516, \"width\": 395.9983825683594, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 108.0, \"y\": 525.9705200195312, \"width\": 395.99737548828125, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 108.0, \"y\": 515.0615234375, \"width\": 370.42144775390625, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 478.42144775390625, \"y\": 515.370361328125, \"width\": 7.641082763671875, \"height\": 9.962615966796875, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 486.0669860839844, \"y\": 514.4064025878906, \"width\": 17.434539794921875, \"height\": 8.403411865234375, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 108.0, \"y\": 504.1524963378906, \"width\": 397.2479248046875, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 108.0, \"y\": 493.2434997558594, \"width\": 85.06062316894531, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 108.0, \"y\": 476.8544921875, \"width\": 281.86175537109375, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 235.50900268554688, \"y\": 443.7793273925781, \"width\": 15.133193969726562, \"height\": 9.962615966796875, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 250.64300537109375, \"y\": 442.7275390625, \"width\": 3.110321044921875, \"height\": 6.973785400390625, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 253.7570037841797, \"y\": 442.7275390625, \"width\": 14.163772583007812, \"height\": 6.973785400390625, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 267.9219970703125, \"y\": 442.7275390625, \"width\": 3.96807861328125, \"height\": 6.973785400390625, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 271.89398193359375, \"y\": 442.7275390625, \"width\": 2.817413330078125, \"height\": 6.973785400390625, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 274.71197509765625, \"y\": 442.7275390625, \"width\": 3.110321044921875, \"height\": 6.973785400390625, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 277.8222961425781, \"y\": 441.9803161621094, \"width\": 11.009613037109375, \"height\": 11.761627197265625, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 288.8319091796875, \"y\": 443.7793273925781, \"width\": 16.8621826171875, \"height\": 9.962615966796875, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 305.68896484375, \"y\": 443.7793273925781, \"width\": 3.865478515625, \"height\": 9.962615966796875, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 309.56396484375, \"y\": 443.7793273925781, \"width\": 19.496795654296875, \"height\": 9.962615966796875, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 329.0569763183594, \"y\": 443.7793273925781, \"width\": 24.906463623046875, \"height\": 9.962615966796875, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 353.9629821777344, \"y\": 448.6395568847656, \"width\": 3.96807861328125, \"height\": 6.973785400390625, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 357.9349670410156, \"y\": 448.6395568847656, \"width\": 11.039520263671875, \"height\": 6.973785400390625, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 368.98297119140625, \"y\": 447.98724365234375, \"width\": 12.453277587890625, \"height\": 6.002471923828125, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 382.4319763183594, \"y\": 443.7793273925781, \"width\": 3.865478515625, \"height\": 9.962615966796875, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 225.6939697265625, \"y\": 426.9083251953125, \"width\": 15.133193969726562, \"height\": 9.962615966796875, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 240.82797241210938, \"y\": 425.8565368652344, \"width\": 3.110321044921875, \"height\": 6.973785400390625, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 243.94097900390625, \"y\": 425.8565368652344, \"width\": 14.163787841796875, \"height\": 6.973785400390625, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 258.10699462890625, \"y\": 425.8565368652344, \"width\": 3.96807861328125, \"height\": 6.973785400390625, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 262.0780029296875, \"y\": 425.8565368652344, \"width\": 2.817413330078125, \"height\": 6.973785400390625, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 264.8970031738281, \"y\": 425.8565368652344, \"width\": 13.201416015625, \"height\": 6.973785400390625, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 278.0984191894531, \"y\": 425.10931396484375, \"width\": 11.005523681640625, \"height\": 11.761627197265625, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 289.10394287109375, \"y\": 426.9083251953125, \"width\": 16.583221435546875, \"height\": 9.962615966796875, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 305.69000244140625, \"y\": 426.9083251953125, \"width\": 3.865478515625, \"height\": 9.962615966796875, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 309.5639953613281, \"y\": 426.9083251953125, \"width\": 19.496795654296875, \"height\": 9.962615966796875, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 329.0570068359375, \"y\": 426.9083251953125, \"width\": 24.906463623046875, \"height\": 9.962615966796875, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 353.9630126953125, \"y\": 431.7685546875, \"width\": 3.96807861328125, \"height\": 6.973785400390625, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 357.93499755859375, \"y\": 431.7685546875, \"width\": 11.039520263671875, \"height\": 6.973785400390625, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 368.9830017089844, \"y\": 431.1162414550781, \"width\": 12.453277587890625, \"height\": 6.002471923828125, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 382.4320068359375, \"y\": 426.9083251953125, \"width\": 3.865478515625, \"height\": 9.962615966796875, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 107.64099884033203, \"y\": 404.1235046386719, \"width\": 24.314292907714844, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 131.95529174804688, \"y\": 404.4323425292969, \"width\": 16.988250732421875, \"height\": 9.962615966796875, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 148.94354248046875, \"y\": 404.1235046386719, \"width\": 75.18353271484375, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 224.1270751953125, \"y\": 404.4323425292969, \"width\": 5.9140625, \"height\": 9.962615966796875, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 230.0411376953125, \"y\": 404.1235046386719, \"width\": 273.956298828125, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 108.0, \"y\": 393.2145080566406, \"width\": 309.332275390625, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 417.332275390625, \"y\": 393.5233459472656, \"width\": 7.391021728515625, \"height\": 9.962615966796875, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 424.7229919433594, \"y\": 393.5233459472656, \"width\": 5.678680419921875, \"height\": 9.962615966796875, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 430.40167236328125, \"y\": 393.2145080566406, \"width\": 10.36822509765625, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 440.7698974609375, \"y\": 393.5233459472656, \"width\": 27.321563720703125, \"height\": 9.962615966796875, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 468.0914611816406, \"y\": 386.4499206542969, \"width\": 4.692169189453125, \"height\": 17.28509521484375, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 472.78363037109375, \"y\": 393.5233459472656, \"width\": 6.921661376953125, \"height\": 9.962615966796875, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 479.7049865722656, \"y\": 393.5233459472656, \"width\": 5.678680419921875, \"height\": 9.962615966796875, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 485.74200439453125, \"y\": 393.2145080566406, \"width\": 18.257476806640625, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}]"}, "type": "Document"}
{"page_content": "chose this function because we hypothesized it would allow the model to easily learn to attend by relative positions, since for any fixed offset  k ,  PE pos + k  can be represented as a linear function of PE pos . We also experimented with using learned positional embeddings [ 9 ] instead, and found that the two versions produced nearly identical results (see Table 3 row (E)). We chose the sinusoidal version because it may allow the model to extrapolate to sequence lengths longer than the ones encountered during training. 4 Why Self-Attention In this section we compare various aspects of self-attention layers to the recurrent and convolu- tional layers commonly used for mapping one variable-length sequence of symbol representations ( x 1 , ..., x n )  to another sequence of equal length  ( z 1 , ..., z n ) , with  x i , z i  ∈ R d , such as a hidden layer in a typical sequence transduction encoder or decoder. Motivating our use of self-attention we consider three desiderata.", "metadata": {"source": "../paper/attention_is_all_you_need.pdf", "title": "", "pid": "17", "annotations": "[{\"page\": 5, \"x\": 108.0, \"y\": 382.3055114746094, \"width\": 396.34283447265625, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 108.0, \"y\": 371.3965148925781, \"width\": 175.15994262695312, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 283.1599426269531, \"y\": 371.7053527832031, \"width\": 7.767608642578125, \"height\": 9.962615966796875, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 291.24700927734375, \"y\": 371.3965148925781, \"width\": 2.54046630859375, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 293.7874755859375, \"y\": 371.7053527832031, \"width\": 17.740692138671875, \"height\": 9.962615966796875, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 311.52899169921875, \"y\": 370.9585876464844, \"width\": 11.7996826171875, \"height\": 6.973785400390625, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 323.3280029296875, \"y\": 370.9585876464844, \"width\": 6.11602783203125, \"height\": 6.973785400390625, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 329.4440002441406, \"y\": 370.9585876464844, \"width\": 4.23309326171875, \"height\": 6.973785400390625, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 333.6770935058594, \"y\": 369.90252685546875, \"width\": 170.32415771484375, \"height\": 13.498931884765625, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 108.0, \"y\": 360.79632568359375, \"width\": 15.133193969726562, \"height\": 9.962615966796875, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 123.13400268554688, \"y\": 360.049560546875, \"width\": 11.799667358398438, \"height\": 6.973785400390625, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 135.4320068359375, \"y\": 360.48748779296875, \"width\": 2.4906463623046875, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 107.53199768066406, \"y\": 344.0985107421875, \"width\": 262.7668914794922, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 370.29901123046875, \"y\": 344.0985107421875, \"width\": 4.981292724609375, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 375.2799987792969, \"y\": 344.0985107421875, \"width\": 128.7156982421875, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 107.7509994506836, \"y\": 333.18951416015625, \"width\": 396.25138092041016, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 108.0, \"y\": 322.2804870605469, \"width\": 395.99774169921875, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 108.0, \"y\": 311.3714904785156, \"width\": 61.987274169921875, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 108.0, \"y\": 281.8602600097656, \"width\": 5.97760009765625, \"height\": 15.5537109375, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 125.93280029296875, \"y\": 281.8602600097656, \"width\": 99.10861206054688, \"height\": 15.5537109375, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 108.0, \"y\": 260.18450927734375, \"width\": 397.6539001464844, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 108.0, \"y\": 249.2755126953125, \"width\": 396.003173828125, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 106.83399963378906, \"y\": 238.67535400390625, \"width\": 3.8654861450195312, \"height\": 9.96258544921875, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 110.70899963378906, \"y\": 238.67535400390625, \"width\": 5.6886444091796875, \"height\": 9.96258544921875, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 116.40299987792969, \"y\": 237.92755126953125, \"width\": 3.9680938720703125, \"height\": 6.97381591796875, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 120.87200164794922, \"y\": 238.67535400390625, \"width\": 22.854225158691406, \"height\": 9.96258544921875, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 143.7239990234375, \"y\": 237.92755126953125, \"width\": 4.9235076904296875, \"height\": 6.97381591796875, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 149.14700317382812, \"y\": 238.67535400390625, \"width\": 3.8654937744140625, \"height\": 9.96258544921875, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 153.0124969482422, \"y\": 238.36651611328125, \"width\": 151.7668914794922, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 304.7793884277344, \"y\": 238.67535400390625, \"width\": 7.236083984375, \"height\": 9.96258544921875, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 312.02398681640625, \"y\": 238.67535400390625, \"width\": 4.632598876953125, \"height\": 9.96258544921875, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 316.656982421875, \"y\": 237.92755126953125, \"width\": 3.96807861328125, \"height\": 6.97381591796875, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 321.1269836425781, \"y\": 238.67535400390625, \"width\": 21.798095703125, \"height\": 9.96258544921875, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 342.91796875, \"y\": 237.92755126953125, \"width\": 4.923492431640625, \"height\": 6.97381591796875, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 348.3409729003906, \"y\": 238.67535400390625, \"width\": 3.865478515625, \"height\": 9.96258544921875, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 352.2149963378906, \"y\": 238.36651611328125, \"width\": 24.20550537109375, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 376.4205017089844, \"y\": 238.67535400390625, \"width\": 9.062164306640625, \"height\": 9.96258544921875, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 385.4880065917969, \"y\": 237.92755126953125, \"width\": 2.817413330078125, \"height\": 6.97381591796875, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 388.80499267578125, \"y\": 238.67535400390625, \"width\": 9.065948486328125, \"height\": 9.96258544921875, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 397.8659973144531, \"y\": 237.92755126953125, \"width\": 2.817413330078125, \"height\": 6.97381591796875, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 400.68341064453125, \"y\": 230.10693359375, \"width\": 11.539703369140625, \"height\": 18.78009033203125, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 416.6340026855469, \"y\": 236.98175048828125, \"width\": 7.1929931640625, \"height\": 13.349853515625, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 423.8290100097656, \"y\": 243.03753662109375, \"width\": 4.142425537109375, \"height\": 6.97381591796875, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 428.4750061035156, \"y\": 238.36651611328125, \"width\": 75.52301025390625, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 108.0, \"y\": 227.45751953125, \"width\": 395.9971923828125, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 108.0, \"y\": 216.5474853515625, \"width\": 101.52890014648438, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}]"}, "type": "Document"}
{"page_content": "One is the total computational complexity per layer. Another is the amount of computation that can be parallelized, as measured by the minimum number of sequential operations required. The third is the path length between long-range dependencies in the network. Learning long-range dependencies is a key challenge in many sequence transduction tasks. One key factor affecting the ability to learn such dependencies is the length of the paths forward and backward signals have to traverse in the network. The shorter these paths between any combination of positions in the input and output sequences, the easier it is to learn long-range dependencies [ 12 ]. Hence we also compare the maximum path length between any two input and output positions in networks composed of the different layer types. As noted in Table 1, a self-attention layer connects all positions with a constant number of sequentially executed operations, whereas a recurrent layer requires  O ( n )", "metadata": {"source": "../paper/attention_is_all_you_need.pdf", "title": "", "pid": "18", "annotations": "[{\"page\": 5, \"x\": 108.0, \"y\": 200.15948486328125, \"width\": 396.0002136230469, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 108.0, \"y\": 189.25048828125, \"width\": 349.45806884765625, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 107.69100189208984, \"y\": 172.86151123046875, \"width\": 396.31043243408203, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 108.0, \"y\": 161.9525146484375, \"width\": 395.99658203125, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 108.0, \"y\": 151.04351806640625, \"width\": 395.9974670410156, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 108.0, \"y\": 140.134521484375, \"width\": 395.99786376953125, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 108.0, \"y\": 129.22552490234375, \"width\": 283.1261291503906, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 391.12200927734375, \"y\": 129.22552490234375, \"width\": 9.96258544921875, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 401.0840148925781, \"y\": 129.22552490234375, \"width\": 102.91546630859375, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 108.0, \"y\": 118.31646728515625, \"width\": 396.00006103515625, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 108.0, \"y\": 107.40753173828125, \"width\": 82.47041320800781, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 107.64099884033203, \"y\": 91.01849365234375, \"width\": 396.70458221435547, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 108.0, \"y\": 80.1094970703125, \"width\": 227.5849609375, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 335.5849609375, \"y\": 80.4183349609375, \"width\": 10.7955322265625, \"height\": 9.96258544921875, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 346.6650085449219, \"y\": 80.4183349609375, \"width\": 3.865478515625, \"height\": 9.96258544921875, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 350.53900146484375, \"y\": 80.4183349609375, \"width\": 5.977569580078125, \"height\": 9.96258544921875, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 356.5190124511719, \"y\": 80.4183349609375, \"width\": 3.865478515625, \"height\": 9.96258544921875, \"color\": \"#FFFF00\"}]"}, "type": "Document"}
{"page_content": "sequential operations. In terms of computational complexity, self-attention layers are faster than recurrent layers when the sequence 6 length  n  is smaller than the representation dimensionality  d , which is most often the case with sentence representations used by state-of-the-art models in machine translations, such as word-piece [ 38 ] and byte-pair [ 31 ] representations. To improve computational performance for tasks involving very long sequences, self-attention could be restricted to considering only a neighborhood of size  r  in the input sequence centered around the respective output position. This would increase the maximum path length to  O ( n/r ) . We plan to investigate this approach further in future work. A single convolutional layer with kernel width  k < n  does not connect all pairs of input and output positions. Doing so requires a stack of  O ( n/k )  convolutional layers in the case of contiguous kernels, or  O ( log k ( n ))", "metadata": {"source": "../paper/attention_is_all_you_need.pdf", "title": "", "pid": "19", "annotations": "[{\"page\": 5, \"x\": 360.3844909667969, \"y\": 80.1094970703125, \"width\": 143.615966796875, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 108.0, \"y\": 69.20050048828125, \"width\": 395.9975280761719, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 5, \"x\": 303.5090026855469, \"y\": 39.3125, \"width\": 4.981292724609375, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 108.0, \"y\": 707.2374954223633, \"width\": 25.404632568359375, \"height\": 12.004936218261719, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 133.40463256835938, \"y\": 707.5463409423828, \"width\": 9.43292236328125, \"height\": 9.962593078613281, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 142.83755493164062, \"y\": 707.2374954223633, \"width\": 205.32260131835938, \"height\": 12.004936218261719, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 348.16015625, \"y\": 707.5463409423828, \"width\": 8.633392333984375, \"height\": 9.962593078613281, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 356.79901123046875, \"y\": 707.2374954223633, \"width\": 147.20455932617188, \"height\": 12.004936218261719, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 108.0, \"y\": 696.328498840332, \"width\": 396.00347900390625, \"height\": 12.004936218261719, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 108.0, \"y\": 685.4195022583008, \"width\": 3.3374481201171875, \"height\": 12.004936218261719, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 111.33699798583984, \"y\": 685.4195022583008, \"width\": 9.962600708007812, \"height\": 12.004936218261719, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 121.30000305175781, \"y\": 685.4195022583008, \"width\": 64.77459716796875, \"height\": 12.004936218261719, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 186.07200622558594, \"y\": 685.4195022583008, \"width\": 9.96258544921875, \"height\": 12.004936218261719, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 196.03500366210938, \"y\": 685.4195022583008, \"width\": 307.96771240234375, \"height\": 12.004936218261719, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 107.7509994506836, \"y\": 674.5105056762695, \"width\": 379.06226348876953, \"height\": 12.004936218261719, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 486.8132629394531, \"y\": 674.8193511962891, \"width\": 6.90386962890625, \"height\": 9.962593078613281, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 493.7171325683594, \"y\": 674.5105056762695, \"width\": 10.282745361328125, \"height\": 12.004936218261719, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 108.0, \"y\": 663.6015167236328, \"width\": 396.0014343261719, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 108.0, \"y\": 652.6925201416016, \"width\": 54.794281005859375, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 162.79428100585938, \"y\": 653.0013580322266, \"width\": 10.082229614257812, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 173.1610107421875, \"y\": 653.0013580322266, \"width\": 3.8654937744140625, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 177.03500366210938, \"y\": 653.0013580322266, \"width\": 15.451980590820312, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 192.76800537109375, \"y\": 653.0013580322266, \"width\": 3.8654937744140625, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 196.64199829101562, \"y\": 652.6925201416016, \"width\": 240.9254150390625, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 107.64099884033203, \"y\": 636.3035430908203, \"width\": 186.0506820678711, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 293.6916809082031, \"y\": 636.6123809814453, \"width\": 27.246337890625, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 320.9380187988281, \"y\": 636.3035430908203, \"width\": 183.06179809570312, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 108.0, \"y\": 625.3944854736328, \"width\": 149.633056640625, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 257.633056640625, \"y\": 625.7033233642578, \"width\": 9.951446533203125, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 267.8690185546875, \"y\": 625.7033233642578, \"width\": 3.865478515625, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 271.7440185546875, \"y\": 625.7033233642578, \"width\": 16.139404296875, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 288.20501708984375, \"y\": 625.7033233642578, \"width\": 3.865478515625, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 292.07049560546875, \"y\": 625.3944854736328, \"width\": 213.17205810546875, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 108.0, \"y\": 614.4854888916016, \"width\": 8.464820861816406, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 116.4648208618164, \"y\": 614.7943267822266, \"width\": 10.526679992675781, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 127.2760009765625, \"y\": 614.7943267822266, \"width\": 3.8654937744140625, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 131.14999389648438, \"y\": 614.7943267822266, \"width\": 12.742172241210938, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 143.89999389648438, \"y\": 614.0475006103516, \"width\": 4.23309326171875, \"height\": 6.9738006591796875, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 148.80198669433594, \"y\": 614.7943267822266, \"width\": 3.8654937744140625, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 152.6759796142578, \"y\": 614.7943267822266, \"width\": 5.9775543212890625, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 158.65597534179688, \"y\": 614.7943267822266, \"width\": 7.7409515380859375, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}]"}, "type": "Document"}
{"page_content": "in the case of dilated convolutions [ 18 ], increasing the length of the longest paths between any two positions in the network. Convolutional layers are generally more expensive than recurrent layers, by a factor of  k . Separable convolutions [ 6 ], however, decrease the complexity considerably, to  O ( k  ·  n  ·  d  +  n  ·  d 2 ) . Even with  k  =  n , however, the complexity of a separable convolution is equal to the combination of a self-attention layer and a point-wise feed-forward layer, the approach we take in our model. As side benefit, self-attention could yield more interpretable models. We inspect attention distributions from our models and present and discuss examples in the appendix. Not only do individual attention heads clearly learn to perform different tasks, many appear to exhibit behavior related to the syntactic and semantic structure of the sentences. 5 Training This section describes the training regime for our models. 5.1 Training Data and Batching", "metadata": {"source": "../paper/attention_is_all_you_need.pdf", "title": "", "pid": "20", "annotations": "[{\"page\": 6, \"x\": 166.3969268798828, \"y\": 614.4854888916016, \"width\": 149.7819061279297, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 316.1789855957031, \"y\": 614.4854888916016, \"width\": 9.96258544921875, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 326.1409912109375, \"y\": 614.4854888916016, \"width\": 177.86297607421875, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 108.0, \"y\": 603.5764923095703, \"width\": 395.9989013671875, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 108.0, \"y\": 592.6674957275391, \"width\": 125.80374145507812, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 233.80374145507812, \"y\": 592.9763336181641, \"width\": 8.265823364257812, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 242.38900756835938, \"y\": 592.6674957275391, \"width\": 108.95547485351562, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 351.34100341796875, \"y\": 592.6674957275391, \"width\": 4.981292724609375, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 356.322998046875, \"y\": 592.6674957275391, \"width\": 148.02783203125, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 108.0, \"y\": 581.7584991455078, \"width\": 64.76148986816406, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 172.76148986816406, \"y\": 582.0673370361328, \"width\": 10.511016845703125, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 183.5570068359375, \"y\": 582.0673370361328, \"width\": 3.8654937744140625, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 187.43099975585938, \"y\": 582.0673370361328, \"width\": 5.1805572509765625, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 192.61155700683594, \"y\": 574.9938812255859, \"width\": 5.6140899658203125, \"height\": 17.285110473632812, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 198.22564697265625, \"y\": 582.0673370361328, \"width\": 8.519912719726562, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 206.7455596923828, \"y\": 574.9938812255859, \"width\": 5.297088623046875, \"height\": 17.285110473632812, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 212.0426483154297, \"y\": 582.0673370361328, \"width\": 7.7219085693359375, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 219.76455688476562, \"y\": 582.0673370361328, \"width\": 10.280380249023438, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 230.04493713378906, \"y\": 582.0673370361328, \"width\": 8.520614624023438, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 238.5655517578125, \"y\": 574.9938812255859, \"width\": 5.29608154296875, \"height\": 17.285110473632812, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 243.86163330078125, \"y\": 582.0673370361328, \"width\": 7.7229156494140625, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 251.58999633789062, \"y\": 586.4295196533203, \"width\": 3.9680938720703125, \"height\": 6.9738006591796875, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 256.0589904785156, \"y\": 582.0673370361328, \"width\": 3.865478515625, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 259.9330139160156, \"y\": 581.7584991455078, \"width\": 48.654937744140625, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 308.58795166015625, \"y\": 582.0673370361328, \"width\": 8.101593017578125, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 316.6895446777344, \"y\": 582.0673370361328, \"width\": 11.62939453125, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 328.3189392089844, \"y\": 582.0673370361328, \"width\": 9.55462646484375, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 337.8760070800781, \"y\": 581.7584991455078, \"width\": 166.12603759765625, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 108.0, \"y\": 570.8495025634766, \"width\": 397.2477111816406, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 108.0, \"y\": 559.9405059814453, \"width\": 140.17373657226562, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 107.64099884033203, \"y\": 543.5515289306641, \"width\": 396.36275482177734, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 108.0, \"y\": 532.6425170898438, \"width\": 395.99853515625, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 108.0, \"y\": 521.7335205078125, \"width\": 396.00152587890625, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 108.0, \"y\": 510.82452392578125, \"width\": 158.25595092773438, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 108.0, \"y\": 478.83331298828125, \"width\": 5.97760009765625, \"height\": 15.5537109375, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 125.93280029296875, \"y\": 478.83331298828125, \"width\": 44.29402160644531, \"height\": 15.5537109375, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 107.69100189208984, \"y\": 455.60552978515625, \"width\": 229.78739166259766, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 108.0, \"y\": 428.2287902832031, \"width\": 12.4532470703125, \"height\": 12.961334228515625, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 130.4158477783203, \"y\": 428.2287902832031, \"width\": 119.11277770996094, \"height\": 12.961334228515625, \"color\": \"#FFFF00\"}]"}, "type": "Document"}
{"page_content": "We trained on the standard WMT 2014 English-German dataset consisting of about 4.5 million sentence pairs. Sentences were encoded using byte-pair encoding [ 3 ], which has a shared source- target vocabulary of about 37000 tokens. For English-French, we used the significantly larger WMT 2014 English-French dataset consisting of 36M sentences and split tokens into a 32000 word-piece vocabulary [ 38 ]. Sentence pairs were batched together by approximate sequence length. Each training batch contained a set of sentence pairs containing approximately 25000 source tokens and 25000 target tokens. 5.2 Hardware and Schedule We trained our models on one machine with 8 NVIDIA P100 GPUs. For our base models using the hyperparameters described throughout the paper, each training step took about 0.4 seconds. We trained the base models for a total of 100,000 steps or 12 hours. For our big models,(described on the", "metadata": {"source": "../paper/attention_is_all_you_need.pdf", "title": "", "pid": "21", "annotations": "[{\"page\": 6, \"x\": 107.53199768066406, \"y\": 407.9234924316406, \"width\": 396.46485900878906, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 108.0, \"y\": 397.0144958496094, \"width\": 273.7401123046875, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 381.739013671875, \"y\": 397.0144958496094, \"width\": 4.981292724609375, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 386.7200012207031, \"y\": 397.0144958496094, \"width\": 118.93453979492188, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 108.0, \"y\": 386.1054992675781, \"width\": 396.30413818359375, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 108.0, \"y\": 375.19549560546875, \"width\": 396.0009765625, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 107.7509994506836, \"y\": 364.2864990234375, \"width\": 48.40668487548828, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 156.15699768066406, \"y\": 364.2864990234375, \"width\": 9.96258544921875, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 166.1199951171875, \"y\": 364.2864990234375, \"width\": 337.8802795410156, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 108.0, \"y\": 353.37750244140625, \"width\": 395.99749755859375, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 108.0, \"y\": 342.468505859375, \"width\": 53.39952087402344, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 108.0, \"y\": 315.0927429199219, \"width\": 12.4532470703125, \"height\": 12.961334228515625, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 130.4158477783203, \"y\": 315.0927429199219, \"width\": 102.62471008300781, \"height\": 12.961334228515625, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 107.53199768066406, \"y\": 294.7864990234375, \"width\": 396.46473693847656, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 108.0, \"y\": 283.87750244140625, \"width\": 395.99688720703125, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 108.0, \"y\": 272.968505859375, \"width\": 396.0014953613281, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}]"}, "type": "Document"}
{"page_content": "bottom line of table 3), step time was 1.0 seconds. The big models were trained for 300,000 steps (3.5 days). 5.3 Optimizer We used the Adam optimizer [ 20 ] with  β 1  = 0 . 9 ,  β 2  = 0 . 98  and  ϵ  = 10 − 9 . We varied the learning rate over the course of training, according to the formula: lrate  =  d − 0 . 5 model ·  min( step _ num − 0 . 5 , step _ num  ·  warmup _ steps − 1 . 5 ) (3) This corresponds to increasing the learning rate linearly for the first  warmup _ steps  training steps, and decreasing it thereafter proportionally to the inverse square root of the step number. We used warmup _ steps  = 4000 . 5.4 Regularization We employ three types of regularization during training: 7 Table 2: The Transformer achieves better BLEU scores than previous state-of-the-art models on the English-to-German and English-to-French newstest2014 tests at a fraction of the training cost. Model BLEU Training Cost (FLOPs) EN-DE EN-FR EN-DE EN-FR ByteNet [18] 23.75 Deep-Att + PosUnk [39] 39.2", "metadata": {"source": "../paper/attention_is_all_you_need.pdf", "title": "", "pid": "22", "annotations": "[{\"page\": 6, \"x\": 108.0, \"y\": 262.05950927734375, \"width\": 395.9975280761719, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 107.6709976196289, \"y\": 251.1505126953125, \"width\": 42.331077575683594, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 108.0, \"y\": 223.7738037109375, \"width\": 12.4532470703125, \"height\": 12.9613037109375, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 130.4158477783203, \"y\": 223.7738037109375, \"width\": 43.715911865234375, \"height\": 12.9613037109375, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 107.53199768066406, \"y\": 203.468505859375, \"width\": 123.48844909667969, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 231.01800537109375, \"y\": 203.468505859375, \"width\": 9.96258544921875, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 240.97999572753906, \"y\": 203.468505859375, \"width\": 23.847427368164062, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 264.8274230957031, \"y\": 203.77734375, \"width\": 8.1114501953125, \"height\": 9.96258544921875, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 272.94500732421875, \"y\": 203.030517578125, \"width\": 3.96807861328125, \"height\": 6.97381591796875, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 276.9130859375, \"y\": 202.2833251953125, \"width\": 18.770721435546875, \"height\": 11.45660400390625, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 295.67901611328125, \"y\": 203.77734375, \"width\": 2.7596435546875, \"height\": 9.96258544921875, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 298.4460144042969, \"y\": 203.77734375, \"width\": 4.981292724609375, \"height\": 9.96258544921875, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 303.4280090332031, \"y\": 203.468505859375, \"width\": 2.530487060546875, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 305.95849609375, \"y\": 203.77734375, \"width\": 8.11138916015625, \"height\": 9.96258544921875, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 314.0760192871094, \"y\": 203.030517578125, \"width\": 3.96807861328125, \"height\": 6.97381591796875, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 318.0440979003906, \"y\": 202.2833251953125, \"width\": 18.770721435546875, \"height\": 11.45660400390625, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 336.8100280761719, \"y\": 203.77734375, \"width\": 2.7596435546875, \"height\": 9.96258544921875, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 339.5780334472656, \"y\": 203.77734375, \"width\": 9.96258544921875, \"height\": 9.96258544921875, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 349.5406188964844, \"y\": 203.468505859375, \"width\": 17.0965576171875, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 366.6371765136719, \"y\": 203.77734375, \"width\": 6.51666259765625, \"height\": 9.96258544921875, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 373.1538391113281, \"y\": 203.77734375, \"width\": 23.259246826171875, \"height\": 9.96258544921875, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 396.40899658203125, \"y\": 203.25091552734375, \"width\": 6.22064208984375, \"height\": 12.0855712890625, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 402.635009765625, \"y\": 208.1395263671875, \"width\": 3.96807861328125, \"height\": 6.97381591796875, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 407.1050109863281, \"y\": 203.468505859375, \"width\": 96.89791870117188, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 108.0, \"y\": 192.55950927734375, \"width\": 228.23312377929688, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 162.89199829101562, \"y\": 162.47735595703125, \"width\": 21.4295654296875, \"height\": 9.96258544921875, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 184.32156372070312, \"y\": 162.47735595703125, \"width\": 10.522369384765625, \"height\": 9.96258544921875, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 194.84393310546875, \"y\": 162.47735595703125, \"width\": 7.95562744140625, \"height\": 9.96258544921875, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 202.8040008544922, \"y\": 162.596923828125, \"width\": 6.2206268310546875, \"height\": 12.0855712890625, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 209.031005859375, \"y\": 167.48553466796875, \"width\": 3.9680938720703125, \"height\": 6.97381591796875, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 213.0019989013672, \"y\": 167.48553466796875, \"width\": 2.3641204833984375, \"height\": 6.97381591796875, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 215.3679962158203, \"y\": 167.48553466796875, \"width\": 3.9680938720703125, \"height\": 6.97381591796875, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 202.8040008544922, \"y\": 160.11737060546875, \"width\": 17.434494018554688, \"height\": 8.4034423828125, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 222.9510040283203, \"y\": 155.4039306640625, \"width\": 2.7596435546875, \"height\": 17.28509521484375, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 225.7106475830078, \"y\": 162.47735595703125, \"width\": 22.694503784179688, \"height\": 9.96258544921875, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 248.4110107421875, \"y\": 162.47735595703125, \"width\": 17.9227294921875, \"height\": 9.96258544921875, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 266.33001708984375, \"y\": 162.16851806640625, \"width\": 4.981292724609375, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 271.3110046386719, \"y\": 162.47735595703125, \"width\": 20.43328857421875, \"height\": 9.96258544921875, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 291.7409973144531, \"y\": 162.44891357421875, \"width\": 6.22064208984375, \"height\": 12.0855712890625, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 297.9679870605469, \"y\": 167.3375244140625, \"width\": 3.96807861328125, \"height\": 6.97381591796875, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 301.9389953613281, \"y\": 167.3375244140625, \"width\": 2.364105224609375, \"height\": 6.97381591796875, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 304.30499267578125, \"y\": 167.3375244140625, \"width\": 3.96807861328125, \"height\": 6.97381591796875, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 308.7749938964844, \"y\": 162.47735595703125, \"width\": 22.3560791015625, \"height\": 9.96258544921875, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 331.1210021972656, \"y\": 162.16851806640625, \"width\": 4.981292724609375, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 336.1029968261719, \"y\": 162.47735595703125, \"width\": 20.43328857421875, \"height\": 9.96258544921875, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 356.5362854003906, \"y\": 155.4039306640625, \"width\": 4.970367431640625, \"height\": 17.28509521484375, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 361.50665283203125, \"y\": 162.47735595703125, \"width\": 39.13275146484375, \"height\": 9.96258544921875, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 400.6289978027344, \"y\": 162.16851806640625, \"width\": 4.981292724609375, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 405.6109924316406, \"y\": 162.47735595703125, \"width\": 22.585235595703125, \"height\": 9.96258544921875, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 428.1999816894531, \"y\": 162.44891357421875, \"width\": 6.22064208984375, \"height\": 12.0855712890625, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 434.4259948730469, \"y\": 167.3375244140625, \"width\": 3.96807861328125, \"height\": 6.97381591796875, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 438.3979797363281, \"y\": 167.3375244140625, \"width\": 2.364105224609375, \"height\": 6.97381591796875, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 440.76397705078125, \"y\": 167.3375244140625, \"width\": 3.96807861328125, \"height\": 6.97381591796875, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 445.23297119140625, \"y\": 162.47735595703125, \"width\": 3.865478515625, \"height\": 9.96258544921875, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 493.05096435546875, \"y\": 162.16851806640625, \"width\": 11.616363525390625, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 107.69100189208984, \"y\": 138.70050048828125, \"width\": 271.61658477783203, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 379.3075866699219, \"y\": 139.00933837890625, \"width\": 39.401824951171875, \"height\": 9.96258544921875, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 418.6990051269531, \"y\": 138.70050048828125, \"width\": 4.981292724609375, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 423.67999267578125, \"y\": 139.00933837890625, \"width\": 22.585235595703125, \"height\": 9.96258544921875, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 446.2652282714844, \"y\": 138.70050048828125, \"width\": 58.978668212890625, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 108.0, \"y\": 127.79150390625, \"width\": 395.99749755859375, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 108.0, \"y\": 117.19134521484375, \"width\": 36.91143798828125, \"height\": 9.96258544921875, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 144.9010009765625, \"y\": 116.88250732421875, \"width\": 4.981292724609375, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 149.8820037841797, \"y\": 117.19134521484375, \"width\": 22.585205078125, \"height\": 9.96258544921875, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 172.4672088623047, \"y\": 117.19134521484375, \"width\": 33.21746826171875, \"height\": 9.96258544921875, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 205.67999267578125, \"y\": 116.88250732421875, \"width\": 2.4906463623046875, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 107.99999237060547, \"y\": 89.50579833984375, \"width\": 12.4532470703125, \"height\": 12.9613037109375, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 130.41583251953125, \"y\": 89.50579833984375, \"width\": 63.0931396484375, \"height\": 12.9613037109375, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 107.53199005126953, \"y\": 69.20050048828125, \"width\": 224.45726776123047, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 6, \"x\": 303.5090026855469, \"y\": 39.3125, \"width\": 4.981292724609375, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 107.69100189208984, \"y\": 710.4455032348633, \"width\": 396.3121109008789, \"height\": 12.004936218261719, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 108.0, \"y\": 699.536506652832, \"width\": 375.51025390625, \"height\": 12.004936218261719, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 136.67100524902344, \"y\": 675.442512512207, \"width\": 26.012344360351562, \"height\": 12.004936218261719, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 311.02099609375, \"y\": 683.7315139770508, \"width\": 26.012359619140625, \"height\": 12.004936218261719, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 383.2498474121094, \"y\": 683.7315139770508, \"width\": 92.0743408203125, \"height\": 12.004936218261719, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 288.7200012207031, \"y\": 667.816535949707, \"width\": 29.877838134765625, \"height\": 12.004936218261719, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 330.5529479980469, \"y\": 667.816535949707, \"width\": 28.781951904296875, \"height\": 12.004936218261719, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 387.4692687988281, \"y\": 667.816535949707, \"width\": 29.877838134765625, \"height\": 12.004936218261719, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 440.0419006347656, \"y\": 667.816535949707, \"width\": 28.781951904296875, \"height\": 12.004936218261719, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 136.67100524902344, \"y\": 656.5095367431641, \"width\": 52.29368591308594, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 292.44622802734375, \"y\": 656.5095367431641, \"width\": 22.41583251953125, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 136.67100524902344, \"y\": 645.1265411376953, \"width\": 98.3109130859375, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 336.22186279296875, \"y\": 645.1265411376953, \"width\": 17.434539794921875, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}]"}, "type": "Document"}
{"page_content": "1 . 0  ·  10 20 GNMT + RL [38] 24.6 39.92 2 . 3  ·  10 19 1 . 4  ·  10 20 ConvS2S [9] 25.16 40.46 9 . 6  ·  10 18 1 . 5  ·  10 20 MoE [32] 26.03 40.56 2 . 0  ·  10 19 1 . 2  ·  10 20 Deep-Att + PosUnk Ensemble [39] 40.4 8 . 0  ·  10 20 GNMT + RL Ensemble [38] 26.30 41.16 1 . 8  ·  10 20 1 . 1  ·  10 21 ConvS2S Ensemble [9] 26.36 41.29 7 . 7  ·  10 19 1 . 2  ·  10 21 Transformer (base model) 27.3 38.1 3 . 3  ·  10 18 Transformer (big) 28.4 41.8 2 . 3  ·  10 19 Residual Dropout We apply dropout [ 33 ] to the output of each sub-layer, before it is added to the sub-layer input and normalized. In addition, we apply dropout to the sums of the embeddings and the positional encodings in both the encoder and decoder stacks. For the base model, we use a rate of P drop  = 0 . 1 . Label Smoothing During training, we employed label smoothing of value  ϵ ls  = 0 . 1  [ 36 ]. This hurts perplexity, as the model learns to be more unsure, but improves accuracy and BLEU score. 6 Results 6.1", "metadata": {"source": "../paper/attention_is_all_you_need.pdf", "title": "", "pid": "23", "annotations": "[{\"page\": 7, \"x\": 435.26397705078125, \"y\": 645.4353790283203, \"width\": 4.981292724609375, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 440.2459716796875, \"y\": 645.4353790283203, \"width\": 2.7596435546875, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 443.0129699707031, \"y\": 645.4353790283203, \"width\": 4.981292724609375, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 447.9942626953125, \"y\": 638.3619232177734, \"width\": 4.973358154296875, \"height\": 17.285110473632812, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 452.9676208496094, \"y\": 645.4353790283203, \"width\": 12.1849365234375, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 465.1519775390625, \"y\": 649.7985992431641, \"width\": 7.943145751953125, \"height\": 6.9738006591796875, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 136.67098999023438, \"y\": 633.7445831298828, \"width\": 71.7506103515625, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 294.93682861328125, \"y\": 633.7445831298828, \"width\": 17.434539794921875, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 333.7311706542969, \"y\": 633.7445831298828, \"width\": 22.41583251953125, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 383.2449951171875, \"y\": 634.0534210205078, \"width\": 4.981292724609375, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 388.2259826660156, \"y\": 634.0534210205078, \"width\": 2.7596435546875, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 390.9939880371094, \"y\": 634.0534210205078, \"width\": 4.981292724609375, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 395.97528076171875, \"y\": 626.9799652099609, \"width\": 4.973358154296875, \"height\": 17.285110473632812, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 400.9486389160156, \"y\": 634.0534210205078, \"width\": 12.183929443359375, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 413.13299560546875, \"y\": 638.4156036376953, \"width\": 7.943145751953125, \"height\": 6.9738006591796875, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 435.2640075683594, \"y\": 634.0534210205078, \"width\": 4.981292724609375, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 440.2460021972656, \"y\": 634.0534210205078, \"width\": 2.7596435546875, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 443.01300048828125, \"y\": 634.0534210205078, \"width\": 4.981292724609375, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 447.9942932128906, \"y\": 626.9799652099609, \"width\": 4.973358154296875, \"height\": 17.285110473632812, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 452.9676513671875, \"y\": 634.0534210205078, \"width\": 12.1849365234375, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 465.1520080566406, \"y\": 638.4156036376953, \"width\": 7.943145751953125, \"height\": 6.9738006591796875, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 136.6710205078125, \"y\": 622.3615875244141, \"width\": 51.35716247558594, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 292.4461975097656, \"y\": 622.3615875244141, \"width\": 22.41583251953125, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 333.731201171875, \"y\": 622.3615875244141, \"width\": 22.41583251953125, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 383.2450256347656, \"y\": 622.6704254150391, \"width\": 4.981292724609375, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 388.22601318359375, \"y\": 622.6704254150391, \"width\": 2.7596435546875, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 390.9940185546875, \"y\": 622.6704254150391, \"width\": 4.981292724609375, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 395.9753112792969, \"y\": 615.5969696044922, \"width\": 4.973358154296875, \"height\": 17.285110473632812, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 400.94866943359375, \"y\": 622.6704254150391, \"width\": 12.183929443359375, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 413.1330261230469, \"y\": 627.0336456298828, \"width\": 7.943145751953125, \"height\": 6.9738006591796875, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 435.2640380859375, \"y\": 622.6704254150391, \"width\": 4.981292724609375, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 440.24603271484375, \"y\": 622.6704254150391, \"width\": 2.7596435546875, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 443.0130310058594, \"y\": 622.6704254150391, \"width\": 4.981292724609375, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 447.99432373046875, \"y\": 615.5969696044922, \"width\": 4.973358154296875, \"height\": 17.285110473632812, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 452.9676818847656, \"y\": 622.6704254150391, \"width\": 12.1849365234375, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 465.15203857421875, \"y\": 627.0336456298828, \"width\": 7.943145751953125, \"height\": 6.9738006591796875, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 136.67105102539062, \"y\": 610.9796295166016, \"width\": 39.013519287109375, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 292.4462585449219, \"y\": 610.9796295166016, \"width\": 22.41583251953125, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 333.73126220703125, \"y\": 610.9796295166016, \"width\": 22.41583251953125, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 383.24505615234375, \"y\": 611.2884674072266, \"width\": 4.981292724609375, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 388.2260437011719, \"y\": 611.2884674072266, \"width\": 2.7596435546875, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 390.9940490722656, \"y\": 611.2884674072266, \"width\": 4.981292724609375, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 395.975341796875, \"y\": 604.2150115966797, \"width\": 4.973358154296875, \"height\": 17.285110473632812, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 400.9486999511719, \"y\": 611.2884674072266, \"width\": 12.183929443359375, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 413.133056640625, \"y\": 615.6506500244141, \"width\": 7.943145751953125, \"height\": 6.9738006591796875, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 435.2650451660156, \"y\": 611.2884674072266, \"width\": 4.981292724609375, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 440.24603271484375, \"y\": 611.2884674072266, \"width\": 2.7596435546875, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 443.0130310058594, \"y\": 611.2884674072266, \"width\": 4.981292724609375, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 447.99432373046875, \"y\": 604.2150115966797, \"width\": 4.973358154296875, \"height\": 17.285110473632812, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 452.9676818847656, \"y\": 611.2884674072266, \"width\": 12.1849365234375, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 465.15203857421875, \"y\": 615.6506500244141, \"width\": 7.943145751953125, \"height\": 6.9738006591796875, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 136.67100524902344, \"y\": 598.3415069580078, \"width\": 140.0940399169922, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 336.2218322753906, \"y\": 598.3415069580078, \"width\": 17.434539794921875, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 435.26397705078125, \"y\": 598.6503448486328, \"width\": 4.981292724609375, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 440.2459716796875, \"y\": 598.6503448486328, \"width\": 2.7596435546875, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 443.0129699707031, \"y\": 598.6503448486328, \"width\": 4.981292724609375, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 447.9942626953125, \"y\": 591.5768890380859, \"width\": 4.973358154296875, \"height\": 17.285110473632812, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 452.9676208496094, \"y\": 598.6503448486328, \"width\": 12.1849365234375, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 465.1519775390625, \"y\": 603.0135650634766, \"width\": 7.943145751953125, \"height\": 6.9738006591796875, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 136.67098999023438, \"y\": 586.9595489501953, \"width\": 113.53375244140625, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 292.4461669921875, \"y\": 586.9595489501953, \"width\": 22.41583251953125, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 333.7311706542969, \"y\": 586.9595489501953, \"width\": 22.41583251953125, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 383.2449951171875, \"y\": 587.2683868408203, \"width\": 4.981292724609375, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 388.2259826660156, \"y\": 587.2683868408203, \"width\": 2.7596435546875, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 390.9939880371094, \"y\": 587.2683868408203, \"width\": 4.981292724609375, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 395.97528076171875, \"y\": 580.1949310302734, \"width\": 4.973358154296875, \"height\": 17.285110473632812, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 400.9486389160156, \"y\": 587.2683868408203, \"width\": 12.183929443359375, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 413.13299560546875, \"y\": 591.6305694580078, \"width\": 7.943145751953125, \"height\": 6.9738006591796875, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 435.2640075683594, \"y\": 587.2683868408203, \"width\": 4.981292724609375, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 440.2460021972656, \"y\": 587.2683868408203, \"width\": 2.7596435546875, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 443.01300048828125, \"y\": 587.2683868408203, \"width\": 4.981292724609375, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 447.9942932128906, \"y\": 580.1949310302734, \"width\": 4.973358154296875, \"height\": 17.285110473632812, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 452.9676513671875, \"y\": 587.2683868408203, \"width\": 12.1849365234375, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 465.1520080566406, \"y\": 591.6305694580078, \"width\": 7.943145751953125, \"height\": 6.9738006591796875, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 136.6710205078125, \"y\": 575.5775299072266, \"width\": 93.14030456542969, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 292.4461975097656, \"y\": 575.5775299072266, \"width\": 22.41583251953125, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 333.73602294921875, \"y\": 574.9797668457031, \"width\": 22.41583251953125, \"height\": 12.961349487304688, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 383.2450256347656, \"y\": 575.8863677978516, \"width\": 4.981292724609375, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 388.22601318359375, \"y\": 575.8863677978516, \"width\": 2.7596435546875, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 390.9940185546875, \"y\": 575.8863677978516, \"width\": 4.981292724609375, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 395.9753112792969, \"y\": 568.8129119873047, \"width\": 4.973358154296875, \"height\": 17.285110473632812, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 400.94866943359375, \"y\": 575.8863677978516, \"width\": 12.183929443359375, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 413.1330261230469, \"y\": 580.2485504150391, \"width\": 7.943145751953125, \"height\": 6.9738006591796875, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 435.2640380859375, \"y\": 575.8863677978516, \"width\": 4.981292724609375, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 440.24603271484375, \"y\": 575.8863677978516, \"width\": 2.7596435546875, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 443.0130310058594, \"y\": 575.8863677978516, \"width\": 4.981292724609375, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 447.99432373046875, \"y\": 568.8129119873047, \"width\": 4.973358154296875, \"height\": 17.285110473632812, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 452.9676818847656, \"y\": 575.8863677978516, \"width\": 12.1849365234375, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 465.15203857421875, \"y\": 580.2485504150391, \"width\": 7.943145751953125, \"height\": 6.9738006591796875, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 136.67100524902344, \"y\": 562.4415435791016, \"width\": 103.67083740234375, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 294.9368896484375, \"y\": 562.4415435791016, \"width\": 17.434539794921875, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 336.2218933105469, \"y\": 562.4415435791016, \"width\": 17.434539794921875, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 407.3389892578125, \"y\": 562.7503814697266, \"width\": 5.728485107421875, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 413.0669860839844, \"y\": 562.7503814697266, \"width\": 3.178070068359375, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 416.25, \"y\": 562.7503814697266, \"width\": 5.728485107421875, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 421.9784851074219, \"y\": 555.8761901855469, \"width\": 5.72357177734375, \"height\": 17.583984375, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 427.7020568847656, \"y\": 562.7503814697266, \"width\": 14.007904052734375, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 441.7099914550781, \"y\": 567.1125640869141, \"width\": 9.02410888671875, \"height\": 6.98077392578125, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 136.67098999023438, \"y\": 551.0595245361328, \"width\": 71.30233764648438, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 294.94097900390625, \"y\": 550.4617614746094, \"width\": 17.434539794921875, \"height\": 12.961349487304688, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 336.2259826660156, \"y\": 550.4617614746094, \"width\": 17.434539794921875, \"height\": 12.961349487304688, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 410.12298583984375, \"y\": 551.3683624267578, \"width\": 4.981292724609375, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 415.1039733886719, \"y\": 551.3683624267578, \"width\": 2.7596435546875, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 417.8709716796875, \"y\": 551.3683624267578, \"width\": 4.981292724609375, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 422.8522644042969, \"y\": 544.2949066162109, \"width\": 4.974365234375, \"height\": 17.285110473632812, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 427.8266296386719, \"y\": 551.3683624267578, \"width\": 12.183929443359375, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 440.010986328125, \"y\": 555.7305450439453, \"width\": 7.943145751953125, \"height\": 6.9738006591796875, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 108.0, \"y\": 507.7457580566406, \"width\": 74.94456481933594, \"height\": 12.961334228515625, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 192.90899658203125, \"y\": 508.343505859375, \"width\": 76.54885864257812, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 269.4630126953125, \"y\": 508.343505859375, \"width\": 9.96258544921875, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 279.42498779296875, \"y\": 508.343505859375, \"width\": 224.5762939453125, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 108.0, \"y\": 497.43450927734375, \"width\": 396.0014953613281, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 108.0, \"y\": 486.5255126953125, \"width\": 395.99761962890625, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 108.0, \"y\": 475.9253234863281, \"width\": 6.395988464355469, \"height\": 9.962615966796875, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 114.39599609375, \"y\": 475.1785583496094, \"width\": 16.095535278320312, \"height\": 6.973785400390625, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 130.4915313720703, \"y\": 474.43133544921875, \"width\": 18.772262573242188, \"height\": 11.45660400390625, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 149.2589874267578, \"y\": 475.9253234863281, \"width\": 2.7596435546875, \"height\": 9.962615966796875, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 152.02699279785156, \"y\": 475.9253234863281, \"width\": 4.981292724609375, \"height\": 9.962615966796875, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 157.00799560546875, \"y\": 475.6164855957031, \"width\": 2.4906463623046875, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 108.0, \"y\": 449.67474365234375, \"width\": 74.46607971191406, \"height\": 12.961334228515625, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 192.42799377441406, \"y\": 450.2724914550781, \"width\": 227.00575256347656, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 419.4337463378906, \"y\": 450.5813293457031, \"width\": 6.78411865234375, \"height\": 9.962615966796875, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 426.2270202636719, \"y\": 449.83355712890625, \"width\": 6.318267822265625, \"height\": 6.973785400390625, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 432.5452880859375, \"y\": 449.0863342285156, \"width\": 19.74371337890625, \"height\": 11.457611083984375, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 452.28302001953125, \"y\": 450.5813293457031, \"width\": 2.7596435546875, \"height\": 9.962615966796875, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 455.0500183105469, \"y\": 450.5813293457031, \"width\": 4.981292724609375, \"height\": 9.962615966796875, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 460.03131103515625, \"y\": 450.2724914550781, \"width\": 6.137603759765625, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 466.16900634765625, \"y\": 450.2724914550781, \"width\": 9.96258544921875, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 476.1319885253906, \"y\": 450.2724914550781, \"width\": 27.86383056640625, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 108.0, \"y\": 439.3634948730469, \"width\": 383.69964599609375, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 108.0, \"y\": 407.4612731933594, \"width\": 5.97760009765625, \"height\": 15.5537109375, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 125.93280029296875, \"y\": 407.4612731933594, \"width\": 37.192626953125, \"height\": 15.5537109375, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 108.0, \"y\": 383.6887512207031, \"width\": 12.4532470703125, \"height\": 12.961334228515625, \"color\": \"#FFFF00\"}]"}, "type": "Document"}
{"page_content": "Machine Translation On the WMT 2014 English-to-German translation task, the big transformer model (Transformer (big) in Table 2) outperforms the best previously reported models (including ensembles) by more than  2 . 0 BLEU, establishing a new state-of-the-art BLEU score of  28 . 4 . The configuration of this model is listed in the bottom line of Table 3. Training took  3 . 5  days on  8  P100 GPUs. Even our base model surpasses all previously published models and ensembles, at a fraction of the training cost of any of the competitive models. On the WMT 2014 English-to-French translation task, our big model achieves a BLEU score of  41 . 0 , outperforming all of the previously published single models, at less than  1 / 4  the training cost of the previous state-of-the-art model. The Transformer (big) model trained for English-to-French used dropout rate  P drop  = 0 . 1 , instead of  0 . 3 .", "metadata": {"source": "../paper/attention_is_all_you_need.pdf", "title": "", "pid": "24", "annotations": "[{\"page\": 7, \"x\": 130.4158477783203, \"y\": 383.6887512207031, \"width\": 88.65716552734375, \"height\": 12.961334228515625, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 108.0, \"y\": 363.41949462890625, \"width\": 396.6652526855469, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 108.0, \"y\": 352.510498046875, \"width\": 381.0164794921875, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 489.0164794921875, \"y\": 352.8193359375, \"width\": 7.48382568359375, \"height\": 9.962615966796875, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 496.5, \"y\": 352.8193359375, \"width\": 2.7596435546875, \"height\": 9.962615966796875, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 499.26800537109375, \"y\": 352.8193359375, \"width\": 4.981292724609375, \"height\": 9.962615966796875, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 108.0, \"y\": 341.60150146484375, \"width\": 232.64569091796875, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 340.64569091796875, \"y\": 341.91033935546875, \"width\": 12.451904296875, \"height\": 9.962615966796875, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 353.0980224609375, \"y\": 341.91033935546875, \"width\": 2.7596435546875, \"height\": 9.962615966796875, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 355.8650207519531, \"y\": 341.91033935546875, \"width\": 4.981292724609375, \"height\": 9.962615966796875, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 360.84600830078125, \"y\": 341.60150146484375, \"width\": 143.15322875976562, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 108.0, \"y\": 330.6925048828125, \"width\": 199.47552490234375, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 307.47552490234375, \"y\": 331.0013427734375, \"width\": 7.4677734375, \"height\": 9.962615966796875, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 314.9429931640625, \"y\": 331.0013427734375, \"width\": 2.7596435546875, \"height\": 9.962615966796875, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 317.71099853515625, \"y\": 331.0013427734375, \"width\": 4.981292724609375, \"height\": 9.962615966796875, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 322.6922912597656, \"y\": 330.6925048828125, \"width\": 33.59295654296875, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 356.2852478027344, \"y\": 331.0013427734375, \"width\": 7.473052978515625, \"height\": 9.962615966796875, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 363.75830078125, \"y\": 330.6925048828125, \"width\": 140.239501953125, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 108.0, \"y\": 319.78350830078125, \"width\": 396.0032653808594, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 108.0, \"y\": 308.8735046386719, \"width\": 95.07307434082031, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 108.0, \"y\": 292.4855041503906, \"width\": 374.601318359375, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 482.601318359375, \"y\": 292.7943420410156, \"width\": 12.4522705078125, \"height\": 9.962615966796875, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 495.0530090332031, \"y\": 292.7943420410156, \"width\": 2.7596435546875, \"height\": 9.962615966796875, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 497.8210144042969, \"y\": 292.7943420410156, \"width\": 4.981292724609375, \"height\": 9.962615966796875, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 502.802001953125, \"y\": 292.4855041503906, \"width\": 2.443328857421875, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 108.0, \"y\": 281.5765075683594, \"width\": 286.7475280761719, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 394.7475280761719, \"y\": 281.8853454589844, \"width\": 7.4727783203125, \"height\": 9.962615966796875, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 402.2200012207031, \"y\": 281.8853454589844, \"width\": 4.981292724609375, \"height\": 9.962615966796875, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 407.2019958496094, \"y\": 281.8853454589844, \"width\": 4.981292724609375, \"height\": 9.962615966796875, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 412.18328857421875, \"y\": 281.5765075683594, \"width\": 91.81314086914062, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 108.0, \"y\": 270.66754150390625, \"width\": 395.99761962890625, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 108.0, \"y\": 259.75848388671875, \"width\": 48.418243408203125, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 156.41824340820312, \"y\": 260.06732177734375, \"width\": 8.886749267578125, \"height\": 9.96258544921875, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 165.30499267578125, \"y\": 259.31951904296875, \"width\": 16.095550537109375, \"height\": 6.97381591796875, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 181.40054321289062, \"y\": 258.57232666015625, \"width\": 18.772247314453125, \"height\": 11.45758056640625, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 200.16798400878906, \"y\": 260.06732177734375, \"width\": 2.7596435546875, \"height\": 9.96258544921875, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 202.9349822998047, \"y\": 260.06732177734375, \"width\": 4.981292724609375, \"height\": 9.96258544921875, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 207.91697692871094, \"y\": 259.75848388671875, \"width\": 43.994842529296875, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 251.9118194580078, \"y\": 260.06732177734375, \"width\": 7.4714508056640625, \"height\": 9.96258544921875, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 259.3829650878906, \"y\": 260.06732177734375, \"width\": 2.7596435546875, \"height\": 9.96258544921875, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 262.1509704589844, \"y\": 260.06732177734375, \"width\": 4.981292724609375, \"height\": 9.96258544921875, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 267.1319580078125, \"y\": 259.75848388671875, \"width\": 2.49066162109375, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}]"}, "type": "Document"}
{"page_content": "For the base models, we used a single model obtained by averaging the last 5 checkpoints, which were written at 10-minute intervals. For the big models, we averaged the last 20 checkpoints. We used beam search with a beam size of  4  and length penalty  α  = 0 . 6  [ 38 ]. These hyperparameters were chosen after experimentation on the development set. We set the maximum output length during inference to input length +  50 , but terminate early when possible [38]. Table 2 summarizes our results and compares our translation quality and training costs to other model architectures from the literature. We estimate the number of floating point operations used to train a model by multiplying the training time, the number of GPUs used, and an estimate of the sustained single-precision floating-point capacity of each GPU 5 . 6.2 Model Variations To evaluate the importance of different components of the Transformer, we varied our base model", "metadata": {"source": "../paper/attention_is_all_you_need.pdf", "title": "", "pid": "25", "annotations": "[{\"page\": 7, \"x\": 108.0, \"y\": 243.3695068359375, \"width\": 395.99737548828125, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 107.64099884033203, \"y\": 232.46051025390625, \"width\": 396.36327362060547, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 108.0, \"y\": 221.551513671875, \"width\": 154.22634887695312, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 262.2263488769531, \"y\": 221.8603515625, \"width\": 7.6689453125, \"height\": 9.96258544921875, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 269.8952941894531, \"y\": 221.551513671875, \"width\": 78.0440673828125, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 347.9393615722656, \"y\": 221.8603515625, \"width\": 9.049713134765625, \"height\": 9.96258544921875, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 356.98907470703125, \"y\": 221.8603515625, \"width\": 19.029388427734375, \"height\": 9.96258544921875, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 376.0119934082031, \"y\": 221.8603515625, \"width\": 2.7596435546875, \"height\": 9.96258544921875, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 378.77899169921875, \"y\": 221.8603515625, \"width\": 4.981292724609375, \"height\": 9.96258544921875, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 383.7602844238281, \"y\": 221.551513671875, \"width\": 6.067626953125, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 389.8280029296875, \"y\": 221.551513671875, \"width\": 9.96258544921875, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 399.7909851074219, \"y\": 221.551513671875, \"width\": 104.2099609375, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 107.64099884033203, \"y\": 210.64251708984375, \"width\": 396.3628463745117, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 108.0, \"y\": 199.7335205078125, \"width\": 105.78285217285156, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 213.78285217285156, \"y\": 200.0423583984375, \"width\": 12.452743530273438, \"height\": 9.96258544921875, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 226.2360076904297, \"y\": 199.7335205078125, \"width\": 160.83616638183594, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 107.69100189208984, \"y\": 183.344482421875, \"width\": 396.30420684814453, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 108.0, \"y\": 172.43548583984375, \"width\": 395.99761962890625, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 108.0, \"y\": 161.5264892578125, \"width\": 395.9969787597656, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 108.0, \"y\": 150.61749267578125, \"width\": 210.01162719726562, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 320.5010070800781, \"y\": 155.07232666015625, \"width\": 3.486907958984375, \"height\": 8.4034423828125, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 324.4859924316406, \"y\": 150.61749267578125, \"width\": 2.49066162109375, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 108.0, \"y\": 123.330810546875, \"width\": 12.4532470703125, \"height\": 12.9613037109375, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 130.4158477783203, \"y\": 123.330810546875, \"width\": 73.52397155761719, \"height\": 12.9613037109375, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 107.69100189208984, \"y\": 103.06048583984375, \"width\": 396.30994415283203, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}]"}, "type": "Document"}
{"page_content": "in different ways, measuring the change in performance on English-to-German translation on the 5 We used values of 2.8, 3.7, 6.0 and 9.5 TFLOPS for K80, K40, M40 and P100, respectively. 8 Table 3: Variations on the Transformer architecture. Unlisted values are identical to those of the base model. All metrics are on the English-to-German translation development set, newstest2013. Listed perplexities are per-wordpiece, according to our byte-pair encoding, and should not be compared to per-word perplexities. N d model d ff h d k d v P drop ϵ ls train PPL BLEU params steps (dev) (dev) × 10 6 base 6 512 2048 8 64 64 0.1 0.1 100K 4.92 25.8 65 (A) 1 512 512 5.29 24.9 4 128 128 5.00 25.5 16 32 32 4.91 25.8 32 16 16 5.01 25.4 (B) 16 5.16 25.1 58 32 5.01 25.4 60 (C) 2 6.11 23.7 36 4 5.19 25.3 50 8 4.88 25.5 80 256 32 32 5.75 24.5 28 1024 128 128 4.66 26.0 168 1024 5.12 25.4 53 4096 4.75 26.2 90 (D) 0.0 5.77 24.6 0.2 4.95 25.5 0.0 4.67 25.3 0.2 5.47 25.7 (E)", "metadata": {"source": "../paper/attention_is_all_you_need.pdf", "title": "", "pid": "26", "annotations": "[{\"page\": 7, \"x\": 108.0, \"y\": 92.1514892578125, \"width\": 395.99749755859375, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 120.65299987792969, \"y\": 74.12933349609375, \"width\": 2.988800048828125, \"height\": 7.2030029296875, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 123.71800231933594, \"y\": 69.48046875, \"width\": 329.83824157714844, \"height\": 10.80450439453125, \"color\": \"#FFFF00\"}, {\"page\": 7, \"x\": 303.5090026855469, \"y\": 39.3125, \"width\": 4.981292724609375, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 107.69100189208984, \"y\": 710.4455032348633, \"width\": 396.3043899536133, \"height\": 12.004936218261719, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 108.0, \"y\": 699.536506652832, \"width\": 395.9969177246094, \"height\": 12.004936218261719, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 108.0, \"y\": 688.6275100708008, \"width\": 396.0033264160156, \"height\": 12.004936218261719, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 108.0, \"y\": 677.7185134887695, \"width\": 87.53140258789062, \"height\": 12.004936218261719, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 146.1269989013672, \"y\": 645.0173492431641, \"width\": 7.999969482421875, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 167.177978515625, \"y\": 645.0173492431641, \"width\": 5.1805572509765625, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 172.35800170898438, \"y\": 644.0533599853516, \"width\": 17.434494018554688, \"height\": 8.403427124023438, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 207.1320037841797, \"y\": 645.0173492431641, \"width\": 5.1805572509765625, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 212.31700134277344, \"y\": 644.0533599853516, \"width\": 4.47021484375, \"height\": 8.403427124023438, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 236.23800659179688, \"y\": 645.0173492431641, \"width\": 5.73846435546875, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 258.47454833984375, \"y\": 645.0173492431641, \"width\": 5.1805419921875, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 263.65802001953125, \"y\": 644.2695465087891, \"width\": 4.23309326171875, \"height\": 6.9738006591796875, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 285.4560241699219, \"y\": 645.0173492431641, \"width\": 5.1805419921875, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 290.6410217285156, \"y\": 644.2695465087891, \"width\": 3.982025146484375, \"height\": 6.9738006591796875, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 309.843017578125, \"y\": 645.0173492431641, \"width\": 6.39599609375, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 316.239013671875, \"y\": 644.2695465087891, \"width\": 16.09552001953125, \"height\": 6.9738006591796875, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 345.5880126953125, \"y\": 645.0173492431641, \"width\": 4.03485107421875, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 349.63201904296875, \"y\": 644.2695465087891, \"width\": 6.318267822265625, \"height\": 6.9738006591796875, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 371.1390075683594, \"y\": 650.1624908447266, \"width\": 18.26141357421875, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 405.09600830078125, \"y\": 650.1624908447266, \"width\": 17.16558837890625, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 436.01995849609375, \"y\": 650.1624908447266, \"width\": 26.012359619140625, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 473.9874267578125, \"y\": 650.1624908447266, \"width\": 28.772003173828125, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 370.3070068359375, \"y\": 638.7805328369141, \"width\": 19.925201416015625, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 403.2929992675781, \"y\": 638.7805328369141, \"width\": 20.772003173828125, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 438.6402893066406, \"y\": 638.7805328369141, \"width\": 20.772003173828125, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 477.2829895019531, \"y\": 632.0159149169922, \"width\": 7.740936279296875, \"height\": 17.285110473632812, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 485.031982421875, \"y\": 639.0893707275391, \"width\": 9.96258544921875, \"height\": 9.962600708007812, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 494.9949951171875, \"y\": 643.4515533447266, \"width\": 3.96807861328125, \"height\": 6.9738006591796875, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 116.46800231933594, \"y\": 626.1425323486328, \"width\": 17.70355224609375, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 148.1820068359375, \"y\": 626.1425323486328, \"width\": 4.981292724609375, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 171.25538635253906, \"y\": 626.1425323486328, \"width\": 14.943878173828125, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 202.24900817871094, \"y\": 626.1425323486328, \"width\": 19.9251708984375, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 236.6199493408203, \"y\": 626.1425323486328, \"width\": 4.981292724609375, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 258.53765869140625, \"y\": 626.1425323486328, \"width\": 9.96258544921875, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 285.4366760253906, \"y\": 626.1425323486328, \"width\": 9.96258544921875, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 315.115234375, \"y\": 626.1425323486328, \"width\": 12.4532470703125, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 344.7938232421875, \"y\": 626.1425323486328, \"width\": 12.4532470703125, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 369.2021789550781, \"y\": 626.1425323486328, \"width\": 22.136871337890625, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 404.9620056152344, \"y\": 626.1425323486328, \"width\": 17.434539794921875, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 440.3092956542969, \"y\": 626.1425323486328, \"width\": 17.434539794921875, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 483.3875732421875, \"y\": 626.1425323486328, \"width\": 9.96258544921875, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 118.40599822998047, \"y\": 597.1414947509766, \"width\": 13.828086853027344, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 236.61700439453125, \"y\": 613.5055084228516, \"width\": 4.981292724609375, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 256.0440673828125, \"y\": 613.5055084228516, \"width\": 14.943878173828125, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 282.94305419921875, \"y\": 613.5055084228516, \"width\": 14.943878173828125, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 404.9620056152344, \"y\": 613.5055084228516, \"width\": 17.434539794921875, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 440.3092956542969, \"y\": 613.5055084228516, \"width\": 17.434539794921875, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 236.61700439453125, \"y\": 602.5955352783203, \"width\": 4.981292724609375, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 256.0440673828125, \"y\": 602.5955352783203, \"width\": 14.943878173828125, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 282.94305419921875, \"y\": 602.5955352783203, \"width\": 14.943878173828125, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 404.9620056152344, \"y\": 602.5955352783203, \"width\": 17.434539794921875, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 440.3092956542969, \"y\": 602.5955352783203, \"width\": 17.434539794921875, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 234.1269989013672, \"y\": 591.6865386962891, \"width\": 9.96258544921875, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 258.53533935546875, \"y\": 591.6865386962891, \"width\": 9.96258544921875, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 285.4343566894531, \"y\": 591.6865386962891, \"width\": 9.96258544921875, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 404.9620056152344, \"y\": 591.6865386962891, \"width\": 17.434539794921875, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 440.3092956542969, \"y\": 591.6865386962891, \"width\": 17.434539794921875, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 234.1269989013672, \"y\": 580.7775421142578, \"width\": 9.96258544921875, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 258.53533935546875, \"y\": 580.7775421142578, \"width\": 9.96258544921875, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 285.4343566894531, \"y\": 580.7775421142578, \"width\": 9.96258544921875, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 404.9620056152344, \"y\": 580.7775421142578, \"width\": 17.434539794921875, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 440.3092956542969, \"y\": 580.7775421142578, \"width\": 17.434539794921875, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 118.68000030517578, \"y\": 562.6855010986328, \"width\": 13.280143737792969, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 258.5350036621094, \"y\": 568.1405181884766, \"width\": 9.96258544921875, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 404.9620056152344, \"y\": 568.1405181884766, \"width\": 17.434539794921875, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 440.3092956542969, \"y\": 568.1405181884766, \"width\": 17.434539794921875, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 483.3875732421875, \"y\": 568.1405181884766, \"width\": 9.96258544921875, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 258.5350036621094, \"y\": 557.2315216064453, \"width\": 9.96258544921875, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 404.9620056152344, \"y\": 557.2315216064453, \"width\": 17.434539794921875, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 440.3092956542969, \"y\": 557.2315216064453, \"width\": 17.434539794921875, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 483.3875732421875, \"y\": 557.2315216064453, \"width\": 9.96258544921875, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 118.68000030517578, \"y\": 511.86651611328125, \"width\": 13.280143737792969, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 148.1820068359375, \"y\": 544.5935211181641, \"width\": 4.981292724609375, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 404.9620056152344, \"y\": 544.5935211181641, \"width\": 17.434539794921875, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 440.3092956542969, \"y\": 544.5935211181641, \"width\": 17.434539794921875, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 483.3875732421875, \"y\": 544.5935211181641, \"width\": 9.96258544921875, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 148.1820068359375, \"y\": 533.6845092773438, \"width\": 4.981292724609375, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 404.9620056152344, \"y\": 533.6845092773438, \"width\": 17.434539794921875, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 440.3092956542969, \"y\": 533.6845092773438, \"width\": 17.434539794921875, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 483.3875732421875, \"y\": 533.6845092773438, \"width\": 9.96258544921875, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 148.1820068359375, \"y\": 522.7755126953125, \"width\": 4.981292724609375, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 404.9620056152344, \"y\": 522.7755126953125, \"width\": 17.434539794921875, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 440.3092956542969, \"y\": 522.7755126953125, \"width\": 17.434539794921875, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 483.3875732421875, \"y\": 522.7755126953125, \"width\": 9.96258544921875, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 171.25999450683594, \"y\": 511.86651611328125, \"width\": 14.943878173828125, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 258.5323486328125, \"y\": 511.86651611328125, \"width\": 9.96258544921875, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 285.4313659667969, \"y\": 511.86651611328125, \"width\": 9.96258544921875, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 404.9620056152344, \"y\": 511.86651611328125, \"width\": 17.434539794921875, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 440.3092956542969, \"y\": 511.86651611328125, \"width\": 17.434539794921875, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 483.3875732421875, \"y\": 511.86651611328125, \"width\": 9.96258544921875, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 168.7689971923828, \"y\": 500.9574890136719, \"width\": 19.9251708984375, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 256.0413513183594, \"y\": 500.9574890136719, \"width\": 14.943878173828125, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 282.9403381347656, \"y\": 500.9574890136719, \"width\": 14.943878173828125, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 404.9620056152344, \"y\": 500.9574890136719, \"width\": 17.434539794921875, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 440.3092956542969, \"y\": 500.9574890136719, \"width\": 17.434539794921875, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 480.89691162109375, \"y\": 500.9574890136719, \"width\": 14.943878173828125, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 202.24600219726562, \"y\": 490.0484924316406, \"width\": 19.9251708984375, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 404.9620056152344, \"y\": 490.0484924316406, \"width\": 17.434539794921875, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 440.3092956542969, \"y\": 490.0484924316406, \"width\": 17.434539794921875, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 483.3875732421875, \"y\": 490.0484924316406, \"width\": 9.96258544921875, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 202.24600219726562, \"y\": 479.1394958496094, \"width\": 19.9251708984375, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 404.9620056152344, \"y\": 479.1394958496094, \"width\": 17.434539794921875, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 440.3092956542969, \"y\": 479.1394958496094, \"width\": 17.434539794921875, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 483.3875732421875, \"y\": 479.1394958496094, \"width\": 9.96258544921875, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 118.40599822998047, \"y\": 450.13751220703125, \"width\": 13.828086853027344, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 315.1130065917969, \"y\": 466.5014953613281, \"width\": 12.4532470703125, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 404.9620056152344, \"y\": 466.5014953613281, \"width\": 17.434539794921875, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 440.3092956542969, \"y\": 466.5014953613281, \"width\": 17.434539794921875, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 315.1130065917969, \"y\": 455.5924987792969, \"width\": 12.4532470703125, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 404.9620056152344, \"y\": 455.5924987792969, \"width\": 17.434539794921875, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 440.3092956542969, \"y\": 455.5924987792969, \"width\": 17.434539794921875, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 344.7919921875, \"y\": 444.6835021972656, \"width\": 12.4532470703125, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 404.9620056152344, \"y\": 444.6835021972656, \"width\": 17.434539794921875, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 440.3092956542969, \"y\": 444.6835021972656, \"width\": 17.434539794921875, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 344.7919921875, \"y\": 433.7745056152344, \"width\": 12.4532470703125, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 404.9620056152344, \"y\": 433.7745056152344, \"width\": 17.434539794921875, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 440.3092956542969, \"y\": 433.7745056152344, \"width\": 17.434539794921875, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 118.95899963378906, \"y\": 421.1365051269531, \"width\": 12.722244262695312, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}]"}, "type": "Document"}
{"page_content": "positional embedding instead of sinusoids 4.92 25.7 big 6 1024 4096 16 0.3 300K 4.33 26.4 213 development set, newstest2013. We used beam search as described in the previous section, but no checkpoint averaging. We present these results in Table 3. In Table 3 rows (A), we vary the number of attention heads and the attention key and value dimensions, keeping the amount of computation constant, as described in Section 3.2.2. While single-head attention is 0.9 BLEU worse than the best setting, quality also drops off with too many heads. In Table 3 rows (B), we observe that reducing the attention key size  d k  hurts model quality. This suggests that determining compatibility is not easy and that a more sophisticated compatibility function than dot product may be beneficial. We further observe in rows (C) and (D) that, as expected, bigger models are better, and dropout is very helpful in avoiding over-fitting. In row (E) we replace our", "metadata": {"source": "../paper/attention_is_all_you_need.pdf", "title": "", "pid": "27", "annotations": "[{\"page\": 8, \"x\": 178.63400268554688, \"y\": 421.1365051269531, \"width\": 167.1524658203125, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 404.9620056152344, \"y\": 421.1365051269531, \"width\": 17.434539794921875, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 440.3092956542969, \"y\": 421.1365051269531, \"width\": 17.434539794921875, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 118.9540023803711, \"y\": 408.49951171875, \"width\": 12.732200622558594, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 148.1820068359375, \"y\": 408.49951171875, \"width\": 4.981292724609375, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 168.76473999023438, \"y\": 408.49951171875, \"width\": 19.9251708984375, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 202.24900817871094, \"y\": 408.49951171875, \"width\": 19.9251708984375, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 234.12930297851562, \"y\": 408.49951171875, \"width\": 9.96258544921875, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 315.1152648925781, \"y\": 408.49951171875, \"width\": 12.4532470703125, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 369.20220947265625, \"y\": 408.49951171875, \"width\": 22.136871337890625, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 404.9620056152344, \"y\": 407.9017639160156, \"width\": 17.434539794921875, \"height\": 12.961334228515625, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 440.3092956542969, \"y\": 407.9017639160156, \"width\": 17.434539794921875, \"height\": 12.961334228515625, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 480.9020080566406, \"y\": 408.49951171875, \"width\": 14.943878173828125, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 108.0, \"y\": 367.8945007324219, \"width\": 395.99749755859375, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 108.0, \"y\": 356.9855041503906, \"width\": 231.06259155273438, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 108.0, \"y\": 340.59649658203125, \"width\": 397.24139404296875, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 108.0, \"y\": 329.6875, \"width\": 395.99737548828125, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 108.0, \"y\": 318.77850341796875, \"width\": 372.8003845214844, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 108.0, \"y\": 302.3894958496094, \"width\": 277.0020446777344, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 385.0020446777344, \"y\": 302.6983337402344, \"width\": 7.95050048828125, \"height\": 9.962615966796875, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 392.9570007324219, \"y\": 301.9515686035156, \"width\": 4.23309326171875, \"height\": 6.973785400390625, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 397.1900939941406, \"y\": 300.8955078125, \"width\": 106.81350708007812, \"height\": 13.498931884765625, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 108.0, \"y\": 291.4804992675781, \"width\": 396.3426818847656, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 108.0, \"y\": 280.5715026855469, \"width\": 397.2413024902344, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 108.0, \"y\": 269.66253662109375, \"width\": 396.16729736328125, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}]"}, "type": "Document"}
{"page_content": "sinusoidal positional encoding with learned positional embeddings [ 9 ], and observe nearly identical results to the base model. 6.3 English Constituency Parsing To evaluate if the Transformer can generalize to other tasks we performed experiments on English constituency parsing. This task presents specific challenges: the output is subject to strong structural constraints and is significantly longer than the input. Furthermore, RNN sequence-to-sequence models have not been able to attain state-of-the-art results in small-data regimes [37]. We trained a 4-layer transformer with  d model  = 1024  on the Wall Street Journal (WSJ) portion of the Penn Treebank [ 25 ], about 40K training sentences. We also trained it in a semi-supervised setting, using the larger high-confidence and BerkleyParser corpora from with approximately 17M sentences [ 37 ]. We used a vocabulary of 16K tokens for the WSJ only setting and a vocabulary of 32K tokens for the semi-supervised setting.", "metadata": {"source": "../paper/attention_is_all_you_need.pdf", "title": "", "pid": "28", "annotations": "[{\"page\": 8, \"x\": 108.0, \"y\": 258.75347900390625, \"width\": 271.00775146484375, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 379.010986328125, \"y\": 258.75347900390625, \"width\": 4.981292724609375, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 383.99200439453125, \"y\": 258.75347900390625, \"width\": 120.0081787109375, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 108.0, \"y\": 247.844482421875, \"width\": 101.00082397460938, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 108.0, \"y\": 220.46575927734375, \"width\": 12.4532470703125, \"height\": 12.9613037109375, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 130.4158477783203, \"y\": 220.46575927734375, \"width\": 125.55862426757812, \"height\": 12.9613037109375, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 107.69100189208984, \"y\": 200.15948486328125, \"width\": 396.30677032470703, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 108.0, \"y\": 189.25048828125, \"width\": 396.0023498535156, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 108.0, \"y\": 178.34149169921875, \"width\": 395.9974365234375, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 108.0, \"y\": 167.4324951171875, \"width\": 340.1031494140625, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 107.53199768066406, \"y\": 151.04351806640625, \"width\": 146.99697875976562, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 254.5289764404297, \"y\": 151.35235595703125, \"width\": 7.6265716552734375, \"height\": 9.96258544921875, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 262.1610107421875, \"y\": 150.60552978515625, \"width\": 21.451416015625, \"height\": 6.97381591796875, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 283.6124267578125, \"y\": 149.85833740234375, \"width\": 33.748260498046875, \"height\": 11.45660400390625, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 317.3606872558594, \"y\": 151.04351806640625, \"width\": 186.6396484375, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 108.0, \"y\": 140.134521484375, \"width\": 66.5919189453125, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 174.593994140625, \"y\": 140.134521484375, \"width\": 9.96258544921875, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 184.55599975585938, \"y\": 140.134521484375, \"width\": 320.687744140625, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 108.0, \"y\": 129.22552490234375, \"width\": 395.99798583984375, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 108.0, \"y\": 118.31646728515625, \"width\": 3.3142318725585938, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 111.31400299072266, \"y\": 118.31646728515625, \"width\": 9.962600708007812, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 121.2770004272461, \"y\": 118.31646728515625, \"width\": 382.7189407348633, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 108.0, \"y\": 107.40753173828125, \"width\": 125.07049560546875, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}]"}, "type": "Document"}
{"page_content": "We performed only a small number of experiments to select the dropout, both attention and residual (section 5.4), learning rates and beam size on the Section 22 development set, all other parameters remained unchanged from the English-to-German base translation model. During inference, we 9 Table 4: The Transformer generalizes well to English constituency parsing (Results are on Section 23 of WSJ) Parser Training WSJ 23 F1 Vinyals & Kaiser el al. (2014) [37] WSJ only, discriminative 88.3 Petrov et al. (2006) [29] WSJ only, discriminative 90.4 Zhu et al. (2013) [40] WSJ only, discriminative 90.4 Dyer et al. (2016) [8] WSJ only, discriminative 91.7 Transformer (4 layers) WSJ only, discriminative 91.3 Zhu et al. (2013) [40] semi-supervised 91.3 Huang & Harper (2009) [14] semi-supervised 91.3 McClosky et al. (2006) [26] semi-supervised 92.1 Vinyals & Kaiser el al. (2014) [37] semi-supervised 92.1 Transformer (4 layers) semi-supervised 92.7 Luong et al. (2015) [23] multi-task 93.0", "metadata": {"source": "../paper/attention_is_all_you_need.pdf", "title": "", "pid": "29", "annotations": "[{\"page\": 8, \"x\": 107.53199768066406, \"y\": 91.01849365234375, \"width\": 396.4644012451172, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 107.6709976196289, \"y\": 80.1094970703125, \"width\": 396.32698822021484, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 108.0, \"y\": 69.20050048828125, \"width\": 395.99749755859375, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 8, \"x\": 303.5090026855469, \"y\": 39.3125, \"width\": 4.981292724609375, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 9, \"x\": 107.69100189208984, \"y\": 710.4455032348633, \"width\": 396.3040542602539, \"height\": 12.004936218261719, \"color\": \"#FFFF00\"}, {\"page\": 9, \"x\": 108.0, \"y\": 699.536506652832, \"width\": 32.9263916015625, \"height\": 12.004936218261719, \"color\": \"#FFFF00\"}, {\"page\": 9, \"x\": 206.75799560546875, \"y\": 686.8197326660156, \"width\": 28.114471435546875, \"height\": 12.961341857910156, \"color\": \"#FFFF00\"}, {\"page\": 9, \"x\": 334.0840148925781, \"y\": 686.8197326660156, \"width\": 36.911407470703125, \"height\": 12.961341857910156, \"color\": \"#FFFF00\"}, {\"page\": 9, \"x\": 414.47698974609375, \"y\": 686.8197326660156, \"width\": 46.495452880859375, \"height\": 12.961341857910156, \"color\": \"#FFFF00\"}, {\"page\": 9, \"x\": 151.02699279785156, \"y\": 676.110481262207, \"width\": 139.5760040283203, \"height\": 12.004936218261719, \"color\": \"#FFFF00\"}, {\"page\": 9, \"x\": 302.5580139160156, \"y\": 676.110481262207, \"width\": 99.96469116210938, \"height\": 12.004936218261719, \"color\": \"#FFFF00\"}, {\"page\": 9, \"x\": 429.00799560546875, \"y\": 676.110481262207, \"width\": 17.434539794921875, \"height\": 12.004936218261719, \"color\": \"#FFFF00\"}, {\"page\": 9, \"x\": 172.58599853515625, \"y\": 665.2014846801758, \"width\": 96.45785522460938, \"height\": 12.004936218261719, \"color\": \"#FFFF00\"}, {\"page\": 9, \"x\": 302.5580139160156, \"y\": 665.2014846801758, \"width\": 99.96469116210938, \"height\": 12.004936218261719, \"color\": \"#FFFF00\"}, {\"page\": 9, \"x\": 429.00799560546875, \"y\": 665.2014846801758, \"width\": 17.434539794921875, \"height\": 12.004936218261719, \"color\": \"#FFFF00\"}, {\"page\": 9, \"x\": 177.4929962158203, \"y\": 654.2924957275391, \"width\": 86.64469909667969, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 9, \"x\": 302.5580139160156, \"y\": 654.2924957275391, \"width\": 99.96469116210938, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 9, \"x\": 429.00799560546875, \"y\": 654.2924957275391, \"width\": 17.434539794921875, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 9, \"x\": 178.05099487304688, \"y\": 643.3834991455078, \"width\": 85.52890014648438, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 9, \"x\": 302.5580139160156, \"y\": 643.3834991455078, \"width\": 99.96469116210938, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 9, \"x\": 429.00799560546875, \"y\": 643.3834991455078, \"width\": 17.434539794921875, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 9, \"x\": 175.8990020751953, \"y\": 632.4745025634766, \"width\": 89.83277893066406, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 9, \"x\": 302.5580139160156, \"y\": 632.4745025634766, \"width\": 99.96469116210938, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 9, \"x\": 429.00799560546875, \"y\": 632.4745025634766, \"width\": 17.434539794921875, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 9, \"x\": 177.4929962158203, \"y\": 621.5655059814453, \"width\": 86.64469909667969, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 9, \"x\": 320.1669921875, \"y\": 621.5655059814453, \"width\": 64.74691772460938, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 9, \"x\": 429.00799560546875, \"y\": 621.5655059814453, \"width\": 17.434539794921875, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 9, \"x\": 163.27099609375, \"y\": 610.6555328369141, \"width\": 115.087890625, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 9, \"x\": 320.1669921875, \"y\": 610.6555328369141, \"width\": 64.74691772460938, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 9, \"x\": 429.00799560546875, \"y\": 610.6555328369141, \"width\": 17.434539794921875, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 9, \"x\": 164.83499145507812, \"y\": 599.7465362548828, \"width\": 111.95965576171875, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 9, \"x\": 320.1669921875, \"y\": 599.7465362548828, \"width\": 64.74691772460938, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 9, \"x\": 429.00799560546875, \"y\": 599.7465362548828, \"width\": 17.434539794921875, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 9, \"x\": 151.02700805664062, \"y\": 588.8375396728516, \"width\": 139.57598876953125, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 9, \"x\": 320.1669921875, \"y\": 588.8375396728516, \"width\": 64.74691772460938, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 9, \"x\": 429.00799560546875, \"y\": 588.8375396728516, \"width\": 17.434539794921875, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 9, \"x\": 175.8990020751953, \"y\": 577.9285430908203, \"width\": 89.83277893066406, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 9, \"x\": 320.1669921875, \"y\": 577.9285430908203, \"width\": 64.74691772460938, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 9, \"x\": 429.00799560546875, \"y\": 577.9285430908203, \"width\": 17.434539794921875, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 9, \"x\": 172.51100158691406, \"y\": 567.0194854736328, \"width\": 96.60728454589844, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 9, \"x\": 332.33599853515625, \"y\": 567.0194854736328, \"width\": 40.40826416015625, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 9, \"x\": 429.00799560546875, \"y\": 567.0194854736328, \"width\": 17.434539794921875, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}]"}, "type": "Document"}
{"page_content": "Dyer et al. (2016) [8] generative 93.3 increased the maximum output length to input length +  300 . We used a beam size of  21  and  α  = 0 . 3 for both WSJ only and the semi-supervised setting. Our results in Table 4 show that despite the lack of task-specific tuning our model performs sur- prisingly well, yielding better results than all previously reported models with the exception of the Recurrent Neural Network Grammar [8]. In contrast to RNN sequence-to-sequence models [ 37 ], the Transformer outperforms the Berkeley- Parser [29] even when training only on the WSJ training set of 40K sentences. 7 Conclusion In this work, we presented the Transformer, the first sequence transduction model based entirely on attention, replacing the recurrent layers most commonly used in encoder-decoder architectures with multi-headed self-attention. For translation tasks, the Transformer can be trained significantly faster than architectures based", "metadata": {"source": "../paper/attention_is_all_you_need.pdf", "title": "", "pid": "30", "annotations": "[{\"page\": 9, \"x\": 178.05099487304688, \"y\": 556.1104888916016, \"width\": 85.52890014648438, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 9, \"x\": 331.99200439453125, \"y\": 556.1104888916016, \"width\": 41.095703125, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 9, \"x\": 429.00799560546875, \"y\": 556.1104888916016, \"width\": 17.434539794921875, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 9, \"x\": 108.0, \"y\": 519.5625, \"width\": 216.6917724609375, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 9, \"x\": 324.6917724609375, \"y\": 519.871337890625, \"width\": 17.434112548828125, \"height\": 9.962615966796875, \"color\": \"#FFFF00\"}, {\"page\": 9, \"x\": 342.1260070800781, \"y\": 519.5625, \"width\": 98.04574584960938, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 9, \"x\": 440.1717529296875, \"y\": 519.871337890625, \"width\": 12.455841064453125, \"height\": 9.962615966796875, \"color\": \"#FFFF00\"}, {\"page\": 9, \"x\": 452.6275939941406, \"y\": 519.5625, \"width\": 16.693389892578125, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 9, \"x\": 469.32098388671875, \"y\": 519.871337890625, \"width\": 8.859100341796875, \"height\": 9.962615966796875, \"color\": \"#FFFF00\"}, {\"page\": 9, \"x\": 478.1800842285156, \"y\": 519.871337890625, \"width\": 18.3187255859375, \"height\": 9.962615966796875, \"color\": \"#FFFF00\"}, {\"page\": 9, \"x\": 496.5, \"y\": 519.871337890625, \"width\": 2.7596435546875, \"height\": 9.962615966796875, \"color\": \"#FFFF00\"}, {\"page\": 9, \"x\": 499.26800537109375, \"y\": 519.871337890625, \"width\": 4.981292724609375, \"height\": 9.962615966796875, \"color\": \"#FFFF00\"}, {\"page\": 9, \"x\": 108.0, \"y\": 508.65350341796875, \"width\": 203.66537475585938, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 9, \"x\": 108.0, \"y\": 492.2644958496094, \"width\": 397.6538391113281, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 9, \"x\": 108.0, \"y\": 481.3554992675781, \"width\": 396.00115966796875, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 9, \"x\": 108.0, \"y\": 470.4465026855469, \"width\": 163.3966064453125, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 9, \"x\": 108.0, \"y\": 454.0574951171875, \"width\": 205.62771606445312, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 9, \"x\": 313.625, \"y\": 454.0574951171875, \"width\": 9.96258544921875, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 9, \"x\": 323.5870056152344, \"y\": 454.0574951171875, \"width\": 182.06951904296875, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 9, \"x\": 108.0, \"y\": 443.14849853515625, \"width\": 311.5603332519531, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 9, \"x\": 108.0, \"y\": 413.92626953125, \"width\": 5.97760009765625, \"height\": 15.5537109375, \"color\": \"#FFFF00\"}, {\"page\": 9, \"x\": 125.93280029296875, \"y\": 413.92626953125, \"width\": 57.1339111328125, \"height\": 15.5537109375, \"color\": \"#FFFF00\"}, {\"page\": 9, \"x\": 108.0, \"y\": 392.53851318359375, \"width\": 395.99725341796875, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 9, \"x\": 108.0, \"y\": 381.6294860839844, \"width\": 395.995849609375, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 9, \"x\": 108.0, \"y\": 370.7204895019531, \"width\": 110.12660217285156, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 9, \"x\": 108.0, \"y\": 354.3315124511719, \"width\": 395.9974365234375, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}]"}, "type": "Document"}
{"page_content": "on recurrent or convolutional layers. On both WMT 2014 English-to-German and WMT 2014 English-to-French translation tasks, we achieve a new state of the art. In the former task our best model outperforms even all previously reported ensembles. We are excited about the future of attention-based models and plan to apply them to other tasks. We plan to extend the Transformer to problems involving input and output modalities other than text and to investigate local, restricted attention mechanisms to efficiently handle large inputs and outputs such as images, audio and video. Making generation less sequential is another research goals of ours. The code we used to train and evaluate our models is available at  https://github.com/ tensorflow/tensor2tensor . Acknowledgements We are grateful to Nal Kalchbrenner and Stephan Gouws for their fruitful comments, corrections and inspiration. References [1]  Jimmy Lei Ba, Jamie Ryan Kiros, and Geoffrey E Hinton. Layer normalization.  arXiv preprint", "metadata": {"source": "../paper/attention_is_all_you_need.pdf", "title": "", "pid": "31", "annotations": "[{\"page\": 9, \"x\": 108.0, \"y\": 343.4224853515625, \"width\": 395.9973449707031, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 9, \"x\": 108.0, \"y\": 332.51348876953125, \"width\": 395.99761962890625, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 9, \"x\": 108.0, \"y\": 321.6044921875, \"width\": 235.92431640625, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 9, \"x\": 107.53199768066406, \"y\": 305.21649169921875, \"width\": 396.4631805419922, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 9, \"x\": 108.0, \"y\": 294.3064880371094, \"width\": 396.00054931640625, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 9, \"x\": 108.0, \"y\": 283.3974914550781, \"width\": 395.9974365234375, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 9, \"x\": 108.0, \"y\": 272.48846435546875, \"width\": 397.6082458496094, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 9, \"x\": 107.69100189208984, \"y\": 256.10052490234375, \"width\": 293.0271987915039, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 9, \"x\": 400.71820068359375, \"y\": 255.3134765625, \"width\": 104.35195922851562, \"height\": 11.9351806640625, \"color\": \"#FFFF00\"}, {\"page\": 9, \"x\": 108.0, \"y\": 244.4044189453125, \"width\": 125.51872253417969, \"height\": 11.9351806640625, \"color\": \"#FFFF00\"}, {\"page\": 9, \"x\": 233.49899291992188, \"y\": 245.19146728515625, \"width\": 2.4906463623046875, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 9, \"x\": 108.0, \"y\": 221.92877197265625, \"width\": 84.00804138183594, \"height\": 12.9613037109375, \"color\": \"#FFFF00\"}, {\"page\": 9, \"x\": 201.9720001220703, \"y\": 222.5264892578125, \"width\": 302.03062438964844, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 9, \"x\": 108.0, \"y\": 211.61749267578125, \"width\": 154.67935180664062, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 9, \"x\": 108.0, \"y\": 182.394287109375, \"width\": 55.54383850097656, \"height\": 15.5537109375, \"color\": \"#FFFF00\"}, {\"page\": 9, \"x\": 112.98100280761719, \"y\": 166.48651123046875, \"width\": 11.616386413574219, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 9, \"x\": 124.5973892211914, \"y\": 166.48651123046875, \"width\": 319.63597869873047, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 9, \"x\": 444.2333679199219, \"y\": 166.59613037109375, \"width\": 59.76947021484375, \"height\": 11.89532470703125, \"color\": \"#FFFF00\"}]"}, "type": "Document"}
{"page_content": "arXiv:1607.06450 , 2016. [2]  Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. Neural machine translation by jointly learning to align and translate.  CoRR , abs/1409.0473, 2014. [3]  Denny Britz, Anna Goldie, Minh-Thang Luong, and Quoc V. Le. Massive exploration of neural machine translation architectures.  CoRR , abs/1703.03906, 2017. [4]  Jianpeng Cheng, Li Dong, and Mirella Lapata. Long short-term memory-networks for machine reading.  arXiv preprint arXiv:1601.06733 , 2016. 10 [5]  Kyunghyun Cho, Bart van Merrienboer, Caglar Gulcehre, Fethi Bougares, Holger Schwenk, and Yoshua Bengio. Learning phrase representations using rnn encoder-decoder for statistical machine translation.  CoRR , abs/1406.1078, 2014. [6]  Francois Chollet. Xception: Deep learning with depthwise separable convolutions.  arXiv preprint arXiv:1610.02357 , 2016. [7]  Junyoung Chung, Çaglar Gülçehre, Kyunghyun Cho, and Yoshua Bengio. Empirical evaluation of gated recurrent neural networks on sequence modeling.", "metadata": {"source": "../paper/attention_is_all_you_need.pdf", "title": "", "pid": "32", "annotations": "[{\"page\": 9, \"x\": 129.57899475097656, \"y\": 155.6871337890625, \"width\": 72.7767333984375, \"height\": 11.89532470703125, \"color\": \"#FFFF00\"}, {\"page\": 9, \"x\": 202.35598754882812, \"y\": 155.5775146484375, \"width\": 27.397109985351562, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 9, \"x\": 112.98098754882812, \"y\": 137.6934814453125, \"width\": 11.616386413574219, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 9, \"x\": 124.59737396240234, \"y\": 137.6934814453125, \"width\": 379.74771881103516, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 9, \"x\": 129.57899475097656, \"y\": 126.78448486328125, \"width\": 120.91609191894531, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 9, \"x\": 250.49508666992188, \"y\": 126.89410400390625, \"width\": 27.386566162109375, \"height\": 11.89532470703125, \"color\": \"#FFFF00\"}, {\"page\": 9, \"x\": 277.8809814453125, \"y\": 126.78448486328125, \"width\": 90.76922607421875, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 9, \"x\": 112.98098754882812, \"y\": 108.9014892578125, \"width\": 11.616386413574219, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 9, \"x\": 124.59737396240234, \"y\": 108.9014892578125, \"width\": 379.40699005126953, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 9, \"x\": 129.57899475097656, \"y\": 97.99249267578125, \"width\": 134.1863250732422, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 9, \"x\": 263.76531982421875, \"y\": 98.10211181640625, \"width\": 27.38531494140625, \"height\": 11.89532470703125, \"color\": \"#FFFF00\"}, {\"page\": 9, \"x\": 291.1509704589844, \"y\": 97.99249267578125, \"width\": 95.75051879882812, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 9, \"x\": 112.98097229003906, \"y\": 80.1094970703125, \"width\": 11.616386413574219, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 9, \"x\": 124.59735870361328, \"y\": 80.1094970703125, \"width\": 379.4052047729492, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 9, \"x\": 129.57899475097656, \"y\": 69.20050048828125, \"width\": 32.36848449707031, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 9, \"x\": 161.94747924804688, \"y\": 69.31011962890625, \"width\": 135.770263671875, \"height\": 11.89532470703125, \"color\": \"#FFFF00\"}, {\"page\": 9, \"x\": 297.71697998046875, \"y\": 69.20050048828125, \"width\": 27.39715576171875, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 9, \"x\": 301.01898193359375, \"y\": 39.3125, \"width\": 9.96258544921875, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 10, \"x\": 112.98100280761719, \"y\": 707.2374954223633, \"width\": 11.616386413574219, \"height\": 12.004936218261719, \"color\": \"#FFFF00\"}, {\"page\": 10, \"x\": 124.5973892211914, \"y\": 707.2374954223633, \"width\": 380.6453170776367, \"height\": 12.004936218261719, \"color\": \"#FFFF00\"}, {\"page\": 10, \"x\": 129.57899475097656, \"y\": 696.328498840332, \"width\": 374.42494201660156, \"height\": 12.004936218261719, \"color\": \"#FFFF00\"}, {\"page\": 10, \"x\": 129.57899475097656, \"y\": 685.4195022583008, \"width\": 80.79670715332031, \"height\": 12.004936218261719, \"color\": \"#FFFF00\"}, {\"page\": 10, \"x\": 210.37570190429688, \"y\": 685.5290908813477, \"width\": 27.38592529296875, \"height\": 11.895347595214844, \"color\": \"#FFFF00\"}, {\"page\": 10, \"x\": 237.76199340820312, \"y\": 685.4195022583008, \"width\": 90.76919555664062, \"height\": 12.004936218261719, \"color\": \"#FFFF00\"}, {\"page\": 10, \"x\": 112.98099517822266, \"y\": 665.6184768676758, \"width\": 11.616386413574219, \"height\": 12.004936218261719, \"color\": \"#FFFF00\"}, {\"page\": 10, \"x\": 124.59738159179688, \"y\": 665.6184768676758, \"width\": 350.51531982421875, \"height\": 12.004997253417969, \"color\": \"#FFFF00\"}, {\"page\": 10, \"x\": 475.1127014160156, \"y\": 665.7281265258789, \"width\": 28.887939453125, \"height\": 11.895347595214844, \"color\": \"#FFFF00\"}, {\"page\": 10, \"x\": 129.57899475097656, \"y\": 654.8190765380859, \"width\": 107.55616760253906, \"height\": 11.895339965820312, \"color\": \"#FFFF00\"}, {\"page\": 10, \"x\": 237.13499450683594, \"y\": 654.7094879150391, \"width\": 27.397140502929688, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 10, \"x\": 112.98099517822266, \"y\": 634.9084625244141, \"width\": 11.616386413574219, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 10, \"x\": 124.59738159179688, \"y\": 634.9084625244141, \"width\": 379.4062805175781, \"height\": 12.004989624023438, \"color\": \"#FFFF00\"}, {\"page\": 10, \"x\": 129.57899475097656, \"y\": 623.9995269775391, \"width\": 231.1422882080078, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}]"}, "type": "Document"}
{"page_content": "CoRR , abs/1412.3555, 2014. [8]  Chris Dyer, Adhiguna Kuncoro, Miguel Ballesteros, and Noah A. Smith. Recurrent neural network grammars. In  Proc. of NAACL , 2016. [9]  Jonas Gehring, Michael Auli, David Grangier, Denis Yarats, and Yann N. Dauphin. Convolu- tional sequence to sequence learning.  arXiv preprint arXiv:1705.03122v2 , 2017. [10]  Alex Graves. Generating sequences with recurrent neural networks. arXiv preprint arXiv:1308.0850 , 2013. [11]  Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for im- age recognition. In  Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 770–778, 2016. [12]  Sepp Hochreiter, Yoshua Bengio, Paolo Frasconi, and Jürgen Schmidhuber. Gradient flow in recurrent nets: the difficulty of learning long-term dependencies, 2001. [13]  Sepp Hochreiter and Jürgen Schmidhuber. Long short-term memory.  Neural computation , 9(8):1735–1780, 1997. [14]", "metadata": {"source": "../paper/attention_is_all_you_need.pdf", "title": "", "pid": "33", "annotations": "[{\"page\": 10, \"x\": 360.7212829589844, \"y\": 624.1091156005859, \"width\": 27.386383056640625, \"height\": 11.895339965820312, \"color\": \"#FFFF00\"}, {\"page\": 10, \"x\": 388.10699462890625, \"y\": 623.9995269775391, \"width\": 90.76922607421875, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 10, \"x\": 112.98098754882812, \"y\": 604.1985015869141, \"width\": 11.616386413574219, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 10, \"x\": 124.59737396240234, \"y\": 604.1985015869141, \"width\": 379.4053421020508, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 10, \"x\": 129.57899475097656, \"y\": 593.2895050048828, \"width\": 89.25492858886719, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 10, \"x\": 218.83392333984375, \"y\": 593.3990936279297, \"width\": 67.06765747070312, \"height\": 11.895339965820312, \"color\": \"#FFFF00\"}, {\"page\": 10, \"x\": 285.9020080566406, \"y\": 593.2895050048828, \"width\": 27.39715576171875, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 10, \"x\": 112.98100280761719, \"y\": 573.4884796142578, \"width\": 11.616386413574219, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 10, \"x\": 124.5973892211914, \"y\": 573.4884796142578, \"width\": 381.0559616088867, \"height\": 12.004989624023438, \"color\": \"#FFFF00\"}, {\"page\": 10, \"x\": 129.57899475097656, \"y\": 562.5795440673828, \"width\": 148.57225036621094, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 10, \"x\": 278.1512451171875, \"y\": 562.6891326904297, \"width\": 145.17416381835938, \"height\": 11.895339965820312, \"color\": \"#FFFF00\"}, {\"page\": 10, \"x\": 423.32501220703125, \"y\": 562.5795440673828, \"width\": 27.39715576171875, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 10, \"x\": 108.0, \"y\": 542.7785186767578, \"width\": 16.597686767578125, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 10, \"x\": 124.59768676757812, \"y\": 542.7785186767578, \"width\": 60.85115051269531, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 10, \"x\": 197.99871826171875, \"y\": 542.7785186767578, \"width\": 232.63540649414062, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 10, \"x\": 443.18701171875, \"y\": 542.8881072998047, \"width\": 60.808563232421875, \"height\": 11.895339965820312, \"color\": \"#FFFF00\"}, {\"page\": 10, \"x\": 129.57899475097656, \"y\": 531.9790954589844, \"width\": 67.79544067382812, \"height\": 11.895355224609375, \"color\": \"#FFFF00\"}, {\"page\": 10, \"x\": 197.37399291992188, \"y\": 531.8695068359375, \"width\": 27.397109985351562, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 10, \"x\": 107.99999237060547, \"y\": 512.0684814453125, \"width\": 16.597686767578125, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 10, \"x\": 124.5976791381836, \"y\": 512.0684814453125, \"width\": 381.05139923095703, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 10, \"x\": 129.57899475097656, \"y\": 501.1595153808594, \"width\": 80.989990234375, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 10, \"x\": 210.56898498535156, \"y\": 501.26910400390625, \"width\": 293.43479919433594, \"height\": 11.895355224609375, \"color\": \"#FFFF00\"}, {\"page\": 10, \"x\": 129.27000427246094, \"y\": 490.3591003417969, \"width\": 48.04960632324219, \"height\": 11.895355224609375, \"color\": \"#FFFF00\"}, {\"page\": 10, \"x\": 177.32000732421875, \"y\": 490.24951171875, \"width\": 92.4229736328125, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 10, \"x\": 108.00000762939453, \"y\": 470.4485168457031, \"width\": 16.597686767578125, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 10, \"x\": 124.59769439697266, \"y\": 470.448486328125, \"width\": 379.40438079833984, \"height\": 12.004974365234375, \"color\": \"#FFFF00\"}, {\"page\": 10, \"x\": 129.57899475097656, \"y\": 459.53948974609375, \"width\": 282.56919860839844, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 10, \"x\": 107.99999237060547, \"y\": 439.7384948730469, \"width\": 16.597686767578125, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 10, \"x\": 124.5976791381836, \"y\": 439.7384948730469, \"width\": 290.4685745239258, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 10, \"x\": 415.0662536621094, \"y\": 439.84808349609375, \"width\": 87.6380615234375, \"height\": 11.895355224609375, \"color\": \"#FFFF00\"}, {\"page\": 10, \"x\": 502.7049865722656, \"y\": 439.7384948730469, \"width\": 2.54046630859375, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 10, \"x\": 129.57899475097656, \"y\": 428.8294982910156, \"width\": 91.59603881835938, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 10, \"x\": 107.99999237060547, \"y\": 409.02850341796875, \"width\": 16.597686767578125, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}]"}, "type": "Document"}
{"page_content": "Zhongqiang Huang and Mary Harper. Self-training PCFG grammars with latent annotations across languages. In  Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing , pages 832–841. ACL, August 2009. [15]  Rafal Jozefowicz, Oriol Vinyals, Mike Schuster, Noam Shazeer, and Yonghui Wu. Exploring the limits of language modeling.  arXiv preprint arXiv:1602.02410 , 2016. [16]  Łukasz Kaiser and Samy Bengio. Can active memory replace attention? In  Advances in Neural Information Processing Systems, (NIPS) , 2016. [17]  Łukasz Kaiser and Ilya Sutskever. Neural GPUs learn algorithms. In  International Conference on Learning Representations (ICLR) , 2016. [18]  Nal Kalchbrenner, Lasse Espeholt, Karen Simonyan, Aaron van den Oord, Alex Graves, and Ko- ray Kavukcuoglu. Neural machine translation in linear time.  arXiv preprint arXiv:1610.10099v2 , 2017. [19]  Yoon Kim, Carl Denton, Luong Hoang, and Alexander M. Rush. Structured attention networks. In", "metadata": {"source": "../paper/attention_is_all_you_need.pdf", "title": "", "pid": "34", "annotations": "[{\"page\": 10, \"x\": 124.5976791381836, \"y\": 409.02850341796875, \"width\": 379.4051284790039, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 10, \"x\": 129.57899475097656, \"y\": 398.1195068359375, \"width\": 84.221435546875, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 10, \"x\": 213.80043029785156, \"y\": 398.2290954589844, \"width\": 290.2010955810547, \"height\": 11.895355224609375, \"color\": \"#FFFF00\"}, {\"page\": 10, \"x\": 129.3000030517578, \"y\": 387.3200988769531, \"width\": 85.96723937988281, \"height\": 11.895355224609375, \"color\": \"#FFFF00\"}, {\"page\": 10, \"x\": 215.26699829101562, \"y\": 387.21051025390625, \"width\": 148.20361328125, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 10, \"x\": 108.0, \"y\": 367.4095153808594, \"width\": 16.597686767578125, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 10, \"x\": 124.59768676757812, \"y\": 367.4095153808594, \"width\": 379.40203857421875, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 10, \"x\": 129.57899475097656, \"y\": 356.50048828125, \"width\": 129.23484802246094, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 10, \"x\": 258.8138427734375, \"y\": 356.6100769042969, \"width\": 135.76885986328125, \"height\": 11.895355224609375, \"color\": \"#FFFF00\"}, {\"page\": 10, \"x\": 394.5830078125, \"y\": 356.50048828125, \"width\": 27.39715576171875, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 10, \"x\": 108.0, \"y\": 336.6994934082031, \"width\": 16.597686767578125, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 10, \"x\": 124.59768676757812, \"y\": 336.6994934082031, \"width\": 299.82000732421875, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 10, \"x\": 424.4176940917969, \"y\": 336.80908203125, \"width\": 79.57754516601562, \"height\": 11.895355224609375, \"color\": \"#FFFF00\"}, {\"page\": 10, \"x\": 129.41000366210938, \"y\": 325.90008544921875, \"width\": 160.59710693359375, \"height\": 11.895355224609375, \"color\": \"#FFFF00\"}, {\"page\": 10, \"x\": 290.0059814453125, \"y\": 325.7904968261719, \"width\": 27.39715576171875, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 10, \"x\": 107.99998474121094, \"y\": 305.989501953125, \"width\": 16.597686767578125, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 10, \"x\": 124.59767150878906, \"y\": 305.989501953125, \"width\": 277.08717346191406, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 10, \"x\": 401.6848449707031, \"y\": 306.0990905761719, \"width\": 102.31903076171875, \"height\": 11.895355224609375, \"color\": \"#FFFF00\"}, {\"page\": 10, \"x\": 129.57899475097656, \"y\": 295.1900939941406, \"width\": 146.0218048095703, \"height\": 11.895355224609375, \"color\": \"#FFFF00\"}, {\"page\": 10, \"x\": 275.5999755859375, \"y\": 295.08050537109375, \"width\": 27.39715576171875, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 10, \"x\": 107.99996948242188, \"y\": 275.27947998046875, \"width\": 16.597686767578125, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 10, \"x\": 124.59765625, \"y\": 275.27947998046875, \"width\": 381.0558776855469, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 10, \"x\": 129.57899475097656, \"y\": 264.37054443359375, \"width\": 232.66050720214844, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 10, \"x\": 362.239501953125, \"y\": 264.48016357421875, \"width\": 140.56192016601562, \"height\": 11.89532470703125, \"color\": \"#FFFF00\"}, {\"page\": 10, \"x\": 502.8039855957031, \"y\": 264.37054443359375, \"width\": 2.440826416015625, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 10, \"x\": 129.57899475097656, \"y\": 253.46148681640625, \"width\": 22.415817260742188, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 10, \"x\": 107.99999237060547, \"y\": 233.66046142578125, \"width\": 16.597686767578125, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 10, \"x\": 124.5976791381836, \"y\": 233.66046142578125, \"width\": 381.1499710083008, \"height\": 12.0050048828125, \"color\": \"#FFFF00\"}, {\"page\": 10, \"x\": 129.57899475097656, \"y\": 222.75152587890625, \"width\": 8.298843383789062, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}]"}, "type": "Document"}
{"page_content": "International Conference on Learning Representations , 2017. [20]  Diederik Kingma and Jimmy Ba. Adam: A method for stochastic optimization. In  ICLR , 2015. [21]  Oleksii Kuchaiev and Boris Ginsburg. Factorization tricks for LSTM networks.  arXiv preprint arXiv:1703.10722 , 2017. [22]  Zhouhan Lin, Minwei Feng, Cicero Nogueira dos Santos, Mo Yu, Bing Xiang, Bowen Zhou, and Yoshua Bengio. A structured self-attentive sentence embedding.  arXiv preprint arXiv:1703.03130 , 2017. [23]  Minh-Thang Luong, Quoc V. Le, Ilya Sutskever, Oriol Vinyals, and Lukasz Kaiser. Multi-task sequence to sequence learning.  arXiv preprint arXiv:1511.06114 , 2015. [24]  Minh-Thang Luong, Hieu Pham, and Christopher D Manning. Effective approaches to attention- based neural machine translation.  arXiv preprint arXiv:1508.04025 , 2015. 11 [25]  Mitchell P Marcus, Mary Ann Marcinkiewicz, and Beatrice Santorini. Building a large annotated corpus of english: The penn treebank.  Computational linguistics", "metadata": {"source": "../paper/attention_is_all_you_need.pdf", "title": "", "pid": "35", "annotations": "[{\"page\": 10, \"x\": 137.87783813476562, \"y\": 222.86114501953125, \"width\": 220.92010498046875, \"height\": 11.89532470703125, \"color\": \"#FFFF00\"}, {\"page\": 10, \"x\": 358.7969970703125, \"y\": 222.75152587890625, \"width\": 27.39715576171875, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 10, \"x\": 108.0, \"y\": 202.95050048828125, \"width\": 16.597686767578125, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 10, \"x\": 124.59768676757812, \"y\": 202.94952392578125, \"width\": 330.179931640625, \"height\": 12.00592041015625, \"color\": \"#FFFF00\"}, {\"page\": 10, \"x\": 454.7776184082031, \"y\": 203.05914306640625, \"width\": 23.8428955078125, \"height\": 11.89532470703125, \"color\": \"#FFFF00\"}, {\"page\": 10, \"x\": 478.6199951171875, \"y\": 202.94952392578125, \"width\": 27.1253662109375, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 10, \"x\": 108.0, \"y\": 183.14849853515625, \"width\": 16.597686767578125, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 10, \"x\": 124.59768676757812, \"y\": 183.14849853515625, \"width\": 319.3455505371094, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 10, \"x\": 443.9432373046875, \"y\": 183.25811767578125, \"width\": 60.0574951171875, \"height\": 11.89532470703125, \"color\": \"#FFFF00\"}, {\"page\": 10, \"x\": 129.57899475097656, \"y\": 172.34912109375, \"width\": 72.7767333984375, \"height\": 11.89532470703125, \"color\": \"#FFFF00\"}, {\"page\": 10, \"x\": 202.35598754882812, \"y\": 172.239501953125, \"width\": 27.397109985351562, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 10, \"x\": 107.99998474121094, \"y\": 152.43853759765625, \"width\": 16.597686767578125, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 10, \"x\": 124.59767150878906, \"y\": 152.43853759765625, \"width\": 379.4051055908203, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 10, \"x\": 129.57899475097656, \"y\": 141.52947998046875, \"width\": 310.5362091064453, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 10, \"x\": 440.1152038574219, \"y\": 141.63909912109375, \"width\": 63.881439208984375, \"height\": 11.89532470703125, \"color\": \"#FFFF00\"}, {\"page\": 10, \"x\": 129.57899475097656, \"y\": 130.7301025390625, \"width\": 72.7767333984375, \"height\": 11.89532470703125, \"color\": \"#FFFF00\"}, {\"page\": 10, \"x\": 202.35598754882812, \"y\": 130.6204833984375, \"width\": 27.397109985351562, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 10, \"x\": 107.99998474121094, \"y\": 110.81951904296875, \"width\": 16.597686767578125, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 10, \"x\": 124.59767150878906, \"y\": 110.81951904296875, \"width\": 379.6533660888672, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 10, \"x\": 129.57899475097656, \"y\": 99.9105224609375, \"width\": 123.38681030273438, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 10, \"x\": 252.96580505371094, \"y\": 100.0201416015625, \"width\": 135.76991271972656, \"height\": 11.89532470703125, \"color\": \"#FFFF00\"}, {\"page\": 10, \"x\": 388.7349853515625, \"y\": 99.9105224609375, \"width\": 27.39715576171875, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 10, \"x\": 108.0, \"y\": 80.1094970703125, \"width\": 16.597686767578125, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 10, \"x\": 124.59768676757812, \"y\": 80.1094970703125, \"width\": 381.0557861328125, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 10, \"x\": 129.57899475097656, \"y\": 69.20050048828125, \"width\": 133.3594207763672, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 10, \"x\": 262.93841552734375, \"y\": 69.31011962890625, \"width\": 135.769287109375, \"height\": 11.89532470703125, \"color\": \"#FFFF00\"}, {\"page\": 10, \"x\": 398.70697021484375, \"y\": 69.20050048828125, \"width\": 27.39715576171875, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 10, \"x\": 301.01898193359375, \"y\": 39.3125, \"width\": 9.96258544921875, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 11, \"x\": 108.0, \"y\": 707.2374954223633, \"width\": 16.597686767578125, \"height\": 12.004936218261719, \"color\": \"#FFFF00\"}, {\"page\": 11, \"x\": 124.59768676757812, \"y\": 707.2374954223633, \"width\": 379.4057922363281, \"height\": 12.004936218261719, \"color\": \"#FFFF00\"}, {\"page\": 11, \"x\": 129.57899475097656, \"y\": 696.328498840332, \"width\": 151.11268615722656, \"height\": 12.004936218261719, \"color\": \"#FFFF00\"}, {\"page\": 11, \"x\": 280.6916809082031, \"y\": 696.4380874633789, \"width\": 106.82861328125, \"height\": 11.895347595214844, \"color\": \"#FFFF00\"}]"}, "type": "Document"}
{"page_content": ", 19(2):313–330, 1993. [26]  David McClosky, Eugene Charniak, and Mark Johnson. Effective self-training for parsing. In Proceedings of the Human Language Technology Conference of the NAACL, Main Conference , pages 152–159. ACL, June 2006. [27]  Ankur Parikh, Oscar Täckström, Dipanjan Das, and Jakob Uszkoreit. A decomposable attention model. In  Empirical Methods in Natural Language Processing , 2016. [28]  Romain Paulus, Caiming Xiong, and Richard Socher. A deep reinforced model for abstractive summarization.  arXiv preprint arXiv:1705.04304 , 2017. [29]  Slav Petrov, Leon Barrett, Romain Thibaux, and Dan Klein. Learning accurate, compact, and interpretable tree annotation. In  Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the ACL , pages 433–440. ACL, July 2006. [30]  Ofir Press and Lior Wolf. Using the output embedding to improve language models.  arXiv preprint arXiv:1608.05859 , 2016. [31]", "metadata": {"source": "../paper/attention_is_all_you_need.pdf", "title": "", "pid": "36", "annotations": "[{\"page\": 11, \"x\": 387.5190124511719, \"y\": 696.328498840332, \"width\": 91.5960693359375, \"height\": 12.004936218261719, \"color\": \"#FFFF00\"}, {\"page\": 11, \"x\": 108.0, \"y\": 672.8455276489258, \"width\": 16.597686767578125, \"height\": 12.004936218261719, \"color\": \"#FFFF00\"}, {\"page\": 11, \"x\": 124.59768676757812, \"y\": 672.8455276489258, \"width\": 379.39984130859375, \"height\": 12.004936218261719, \"color\": \"#FFFF00\"}, {\"page\": 11, \"x\": 129.27000427246094, \"y\": 662.0461273193359, \"width\": 373.50498962402344, \"height\": 11.895339965820312, \"color\": \"#FFFF00\"}, {\"page\": 11, \"x\": 502.7720031738281, \"y\": 661.9365386962891, \"width\": 2.47320556640625, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 11, \"x\": 129.57899475097656, \"y\": 651.0275421142578, \"width\": 132.7017364501953, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 11, \"x\": 107.99999237060547, \"y\": 627.5445709228516, \"width\": 16.597686767578125, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 11, \"x\": 124.5976791381836, \"y\": 627.5445098876953, \"width\": 379.4058303833008, \"height\": 12.004989624023438, \"color\": \"#FFFF00\"}, {\"page\": 11, \"x\": 129.57899475097656, \"y\": 616.6355133056641, \"width\": 39.28251647949219, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 11, \"x\": 168.86151123046875, \"y\": 616.7451019287109, \"width\": 211.18698120117188, \"height\": 11.895339965820312, \"color\": \"#FFFF00\"}, {\"page\": 11, \"x\": 380.0479736328125, \"y\": 616.6355133056641, \"width\": 27.39715576171875, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 11, \"x\": 107.99996948242188, \"y\": 593.1525421142578, \"width\": 16.597686767578125, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 11, \"x\": 124.59765625, \"y\": 593.1525421142578, \"width\": 379.39984130859375, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 11, \"x\": 129.57899475097656, \"y\": 582.2435455322266, \"width\": 61.70835876464844, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 11, \"x\": 191.287353515625, \"y\": 582.3531341552734, \"width\": 135.76934814453125, \"height\": 11.895339965820312, \"color\": \"#FFFF00\"}, {\"page\": 11, \"x\": 327.05596923828125, \"y\": 582.2435455322266, \"width\": 27.39715576171875, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 11, \"x\": 107.99996948242188, \"y\": 558.7605743408203, \"width\": 16.597686767578125, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 11, \"x\": 124.59765625, \"y\": 558.7605133056641, \"width\": 380.64483642578125, \"height\": 12.004989624023438, \"color\": \"#FFFF00\"}, {\"page\": 11, \"x\": 129.57899475097656, \"y\": 547.8515167236328, \"width\": 152.27540588378906, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 11, \"x\": 281.8544006347656, \"y\": 547.9611053466797, \"width\": 222.14877319335938, \"height\": 11.895339965820312, \"color\": \"#FFFF00\"}, {\"page\": 11, \"x\": 129.25, \"y\": 537.0521087646484, \"width\": 261.3426208496094, \"height\": 11.895339965820312, \"color\": \"#FFFF00\"}, {\"page\": 11, \"x\": 390.5950012207031, \"y\": 536.9425201416016, \"width\": 113.75192260742188, \"height\": 12.004928588867188, \"color\": \"#FFFF00\"}, {\"page\": 11, \"x\": 129.57899475097656, \"y\": 526.0335083007812, \"width\": 22.415817260742188, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 11, \"x\": 107.99999237060547, \"y\": 502.5505065917969, \"width\": 16.597686767578125, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 11, \"x\": 124.5976791381836, \"y\": 502.5505065917969, \"width\": 351.98828887939453, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 11, \"x\": 476.5859680175781, \"y\": 502.66009521484375, \"width\": 27.4146728515625, \"height\": 11.895355224609375, \"color\": \"#FFFF00\"}, {\"page\": 11, \"x\": 129.57899475097656, \"y\": 491.7510986328125, \"width\": 107.55616760253906, \"height\": 11.895355224609375, \"color\": \"#FFFF00\"}, {\"page\": 11, \"x\": 237.13499450683594, \"y\": 491.6415100097656, \"width\": 27.397140502929688, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 11, \"x\": 108.0, \"y\": 468.15850830078125, \"width\": 16.597686767578125, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}]"}, "type": "Document"}
{"page_content": "Rico Sennrich, Barry Haddow, and Alexandra Birch. Neural machine translation of rare words with subword units.  arXiv preprint arXiv:1508.07909 , 2015. [32]  Noam Shazeer, Azalia Mirhoseini, Krzysztof Maziarz, Andy Davis, Quoc Le, Geoffrey Hinton, and Jeff Dean. Outrageously large neural networks: The sparsely-gated mixture-of-experts layer.  arXiv preprint arXiv:1701.06538 , 2017. [33]  Nitish Srivastava, Geoffrey E Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan Salakhutdi- nov. Dropout: a simple way to prevent neural networks from overfitting.  Journal of Machine Learning Research , 15(1):1929–1958, 2014. [34]  Sainbayar Sukhbaatar, Arthur Szlam, Jason Weston, and Rob Fergus. End-to-end memory networks. In C. Cortes, N. D. Lawrence, D. D. Lee, M. Sugiyama, and R. Garnett, editors, Advances in Neural Information Processing Systems 28 , pages 2440–2448. Curran Associates, Inc., 2015. [35]  Ilya Sutskever, Oriol Vinyals, and Quoc VV Le. Sequence to sequence learning with neural", "metadata": {"source": "../paper/attention_is_all_you_need.pdf", "title": "", "pid": "37", "annotations": "[{\"page\": 11, \"x\": 124.59768676757812, \"y\": 468.15850830078125, \"width\": 379.40447998046875, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 11, \"x\": 129.22000122070312, \"y\": 457.24951171875, \"width\": 78.77424621582031, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 11, \"x\": 207.99424743652344, \"y\": 457.3591003417969, \"width\": 135.7704315185547, \"height\": 11.895355224609375, \"color\": \"#FFFF00\"}, {\"page\": 11, \"x\": 343.76397705078125, \"y\": 457.24951171875, \"width\": 27.39715576171875, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 11, \"x\": 107.99996948242188, \"y\": 433.7665100097656, \"width\": 16.597686767578125, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 11, \"x\": 124.59765625, \"y\": 433.7665100097656, \"width\": 380.65087890625, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 11, \"x\": 129.57899475097656, \"y\": 422.8575134277344, \"width\": 374.42381286621094, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 11, \"x\": 129.57899475097656, \"y\": 411.948486328125, \"width\": 21.857955932617188, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 11, \"x\": 151.43695068359375, \"y\": 412.0580749511719, \"width\": 135.769775390625, \"height\": 11.895355224609375, \"color\": \"#FFFF00\"}, {\"page\": 11, \"x\": 287.2070007324219, \"y\": 411.948486328125, \"width\": 27.39715576171875, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 11, \"x\": 108.0, \"y\": 388.4654846191406, \"width\": 16.597686767578125, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 11, \"x\": 124.59768676757812, \"y\": 388.4654846191406, \"width\": 381.05328369140625, \"height\": 12.004974365234375, \"color\": \"#FFFF00\"}, {\"page\": 11, \"x\": 129.57899475097656, \"y\": 377.5564880371094, \"width\": 291.7124786376953, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 11, \"x\": 421.2914733886719, \"y\": 377.66607666015625, \"width\": 82.70578002929688, \"height\": 11.895355224609375, \"color\": \"#FFFF00\"}, {\"page\": 11, \"x\": 129.3000030517578, \"y\": 366.757080078125, \"width\": 75.57626342773438, \"height\": 11.895355224609375, \"color\": \"#FFFF00\"}, {\"page\": 11, \"x\": 204.87600708007812, \"y\": 366.6474914550781, \"width\": 101.55868530273438, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 11, \"x\": 108.00000762939453, \"y\": 343.16448974609375, \"width\": 16.597686767578125, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 11, \"x\": 124.59769439697266, \"y\": 343.16448974609375, \"width\": 379.75069427490234, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 11, \"x\": 129.57899475097656, \"y\": 332.2544860839844, \"width\": 375.66346740722656, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 11, \"x\": 128.9709930419922, \"y\": 321.455078125, \"width\": 221.1675567626953, \"height\": 11.895355224609375, \"color\": \"#FFFF00\"}, {\"page\": 11, \"x\": 350.1340026855469, \"y\": 321.3454895019531, \"width\": 155.11190795898438, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 11, \"x\": 129.57899475097656, \"y\": 310.4364929199219, \"width\": 42.61000061035156, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 11, \"x\": 107.99999237060547, \"y\": 286.9534912109375, \"width\": 16.597686767578125, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 11, \"x\": 124.5976791381836, \"y\": 286.9534912109375, \"width\": 379.40518951416016, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}]"}, "type": "Document"}
{"page_content": "networks. In  Advances in Neural Information Processing Systems , pages 3104–3112, 2014. [36]  Christian Szegedy, Vincent Vanhoucke, Sergey Ioffe, Jonathon Shlens, and Zbigniew Wojna. Rethinking the inception architecture for computer vision.  CoRR , abs/1512.00567, 2015. [37]  Vinyals & Kaiser, Koo, Petrov, Sutskever, and Hinton. Grammar as a foreign language. In Advances in Neural Information Processing Systems , 2015. [38]  Yonghui Wu, Mike Schuster, Zhifeng Chen, Quoc V Le, Mohammad Norouzi, Wolfgang Macherey, Maxim Krikun, Yuan Cao, Qin Gao, Klaus Macherey, et al. Google’s neural machine translation system: Bridging the gap between human and machine translation.  arXiv preprint arXiv:1609.08144 , 2016. [39]  Jie Zhou, Ying Cao, Xuguang Wang, Peng Li, and Wei Xu. Deep recurrent models with fast-forward connections for neural machine translation.  CoRR , abs/1606.04199, 2016. [40]  Muhua Zhu, Yue Zhang, Wenliang Chen, Min Zhang, and Jingbo Zhu. Fast and accurate", "metadata": {"source": "../paper/attention_is_all_you_need.pdf", "title": "", "pid": "38", "annotations": "[{\"page\": 11, \"x\": 129.57899475097656, \"y\": 276.04449462890625, \"width\": 50.799285888671875, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 11, \"x\": 180.37828063964844, \"y\": 276.15411376953125, \"width\": 211.3665313720703, \"height\": 11.89532470703125, \"color\": \"#FFFF00\"}, {\"page\": 11, \"x\": 391.74298095703125, \"y\": 276.04449462890625, \"width\": 102.3856201171875, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 11, \"x\": 107.99996948242188, \"y\": 252.56146240234375, \"width\": 16.597686767578125, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 11, \"x\": 124.59765625, \"y\": 252.56146240234375, \"width\": 381.142822265625, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 11, \"x\": 129.57899475097656, \"y\": 241.65252685546875, \"width\": 231.6005096435547, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 11, \"x\": 361.17950439453125, \"y\": 241.76214599609375, \"width\": 27.3851318359375, \"height\": 11.89532470703125, \"color\": \"#FFFF00\"}, {\"page\": 11, \"x\": 388.5649719238281, \"y\": 241.65252685546875, \"width\": 95.75051879882812, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 11, \"x\": 107.99996948242188, \"y\": 218.16949462890625, \"width\": 16.597686767578125, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 11, \"x\": 124.59765625, \"y\": 218.16949462890625, \"width\": 379.4051208496094, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 11, \"x\": 128.9709930419922, \"y\": 207.3701171875, \"width\": 208.8759002685547, \"height\": 11.89532470703125, \"color\": \"#FFFF00\"}, {\"page\": 11, \"x\": 337.84600830078125, \"y\": 207.260498046875, \"width\": 27.39715576171875, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 11, \"x\": 108.00001525878906, \"y\": 183.77752685546875, \"width\": 16.597686767578125, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 11, \"x\": 124.59770202636719, \"y\": 183.77752685546875, \"width\": 379.4051055908203, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 11, \"x\": 129.57899475097656, \"y\": 172.86846923828125, \"width\": 374.4243621826172, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 11, \"x\": 129.57899475097656, \"y\": 161.95953369140625, \"width\": 313.35777282714844, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 11, \"x\": 442.936767578125, \"y\": 162.06915283203125, \"width\": 61.0626220703125, \"height\": 11.89532470703125, \"color\": \"#FFFF00\"}, {\"page\": 11, \"x\": 129.57899475097656, \"y\": 151.16009521484375, \"width\": 72.7767333984375, \"height\": 11.89532470703125, \"color\": \"#FFFF00\"}, {\"page\": 11, \"x\": 202.35598754882812, \"y\": 151.05047607421875, \"width\": 27.397109985351562, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 11, \"x\": 107.99998474121094, \"y\": 127.5675048828125, \"width\": 16.597686767578125, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 11, \"x\": 124.59767150878906, \"y\": 127.5675048828125, \"width\": 379.4051055908203, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 11, \"x\": 129.57899475097656, \"y\": 116.65850830078125, \"width\": 223.8994598388672, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 11, \"x\": 353.47845458984375, \"y\": 116.76812744140625, \"width\": 27.38519287109375, \"height\": 11.89532470703125, \"color\": \"#FFFF00\"}, {\"page\": 11, \"x\": 380.8639831542969, \"y\": 116.65850830078125, \"width\": 95.75051879882812, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 11, \"x\": 107.99996948242188, \"y\": 93.17547607421875, \"width\": 16.597686767578125, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 11, \"x\": 124.59765625, \"y\": 93.17547607421875, \"width\": 379.4050598144531, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}]"}, "type": "Document"}
{"page_content": "shift-reduce constituent parsing. In  Proceedings of the 51st Annual Meeting of the ACL (Volume 1: Long Papers) , pages 434–443. ACL, August 2013. 12 Attention Visualizations Input-Input Layer5 It is in this spirit that a majority of American governments have passed new laws since 2009 making the registration or voting process more difficult . <EOS> <pad> <pad> <pad> <pad> <pad> <pad> It is in this spirit that a majority of American governments have passed new laws since 2009 making the registration or voting process more difficult . <EOS> <pad> <pad> <pad> <pad> <pad> <pad> Figure 3: An example of the attention mechanism following long-distance dependencies in the encoder self-attention in layer 5 of 6. Many of the attention heads attend to a distant dependency of the verb ‘making’, completing the phrase ‘making...more difficult’. Attentions here shown only for the word ‘making’. Different colors represent different heads. Best viewed in color. 13 Input-Input Layer5 The Law will", "metadata": {"source": "../paper/attention_is_all_you_need.pdf", "title": "", "pid": "39", "annotations": "[{\"page\": 11, \"x\": 129.57899475097656, \"y\": 82.2664794921875, \"width\": 136.9797821044922, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 11, \"x\": 266.55877685546875, \"y\": 82.3760986328125, \"width\": 237.438232421875, \"height\": 11.89532470703125, \"color\": \"#FFFF00\"}, {\"page\": 11, \"x\": 128.83200073242188, \"y\": 71.46710205078125, \"width\": 65.00593566894531, \"height\": 11.89532470703125, \"color\": \"#FFFF00\"}, {\"page\": 11, \"x\": 193.83799743652344, \"y\": 71.35748291015625, \"width\": 148.20359802246094, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 11, \"x\": 301.01898193359375, \"y\": 39.3125, \"width\": 9.96258544921875, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 12, \"x\": 108.0, \"y\": 705.9602661132812, \"width\": 122.76795959472656, \"height\": 15.5537109375, \"color\": \"#FFFF00\"}, {\"page\": 12, \"x\": 108.0, \"y\": 711.2875671386719, \"width\": 142.4979248046875, \"height\": 18.249927520751953, \"color\": \"#FFFF00\"}, {\"page\": 12, \"x\": 120.40522766113281, \"y\": 631.5146484375, \"width\": 8.690399169921875, \"height\": 4.32373046875, \"color\": \"#FFFF00\"}, {\"page\": 12, \"x\": 132.0734100341797, \"y\": 631.5151672363281, \"width\": 8.690383911132812, \"height\": 5.616302490234375, \"color\": \"#FFFF00\"}, {\"page\": 12, \"x\": 143.74166870117188, \"y\": 631.5156860351562, \"width\": 8.690383911132812, \"height\": 6.0531005859375, \"color\": \"#FFFF00\"}, {\"page\": 12, \"x\": 155.4098358154297, \"y\": 631.5156860351562, \"width\": 8.690383911132812, \"height\": 12.103836059570312, \"color\": \"#FFFF00\"}, {\"page\": 12, \"x\": 167.07850646972656, \"y\": 631.5151672363281, \"width\": 8.690383911132812, \"height\": 16.419769287109375, \"color\": \"#FFFF00\"}, {\"page\": 12, \"x\": 178.7467803955078, \"y\": 631.5156860351562, \"width\": 8.690383911132812, \"height\": 12.973770141601562, \"color\": \"#FFFF00\"}, {\"page\": 12, \"x\": 190.41494750976562, \"y\": 631.5151672363281, \"width\": 8.690383911132812, \"height\": 4.326202392578125, \"color\": \"#FFFF00\"}, {\"page\": 12, \"x\": 202.08311462402344, \"y\": 631.5156860351562, \"width\": 8.690383911132812, \"height\": 27.225845336914062, \"color\": \"#FFFF00\"}, {\"page\": 12, \"x\": 213.7513885498047, \"y\": 631.5151672363281, \"width\": 8.690383911132812, \"height\": 6.486236572265625, \"color\": \"#FFFF00\"}, {\"page\": 12, \"x\": 225.42005920410156, \"y\": 631.5151672363281, \"width\": 8.690383911132812, \"height\": 32.851104736328125, \"color\": \"#FFFF00\"}, {\"page\": 12, \"x\": 237.08824157714844, \"y\": 631.5156860351562, \"width\": 8.690383911132812, \"height\": 44.9615478515625, \"color\": \"#FFFF00\"}, {\"page\": 12, \"x\": 248.75650024414062, \"y\": 631.5151672363281, \"width\": 8.690399169921875, \"height\": 16.865646362304688, \"color\": \"#FFFF00\"}, {\"page\": 12, \"x\": 260.4246520996094, \"y\": 631.5156860351562, \"width\": 8.690399169921875, \"height\": 25.080078125, \"color\": \"#FFFF00\"}, {\"page\": 12, \"x\": 272.0928039550781, \"y\": 631.5151672363281, \"width\": 8.690399169921875, \"height\": 14.267654418945312, \"color\": \"#FFFF00\"}, {\"page\": 12, \"x\": 283.7610778808594, \"y\": 631.5151672363281, \"width\": 8.690399169921875, \"height\": 15.5576171875, \"color\": \"#FFFF00\"}, {\"page\": 12, \"x\": 295.4297790527344, \"y\": 631.5156860351562, \"width\": 8.690399169921875, \"height\": 18.15692138671875, \"color\": \"#FFFF00\"}, {\"page\": 12, \"x\": 307.0979309082031, \"y\": 631.5151672363281, \"width\": 8.690399169921875, \"height\": 17.301254272460938, \"color\": \"#FFFF00\"}, {\"page\": 12, \"x\": 318.7662048339844, \"y\": 631.5156860351562, \"width\": 8.690399169921875, \"height\": 25.072296142578125, \"color\": \"#FFFF00\"}, {\"page\": 12, \"x\": 330.4343566894531, \"y\": 631.5151672363281, \"width\": 8.690399169921875, \"height\": 10.813735961914062, \"color\": \"#FFFF00\"}, {\"page\": 12, \"x\": 342.1026306152344, \"y\": 631.5146484375, \"width\": 8.690399169921875, \"height\": 38.475189208984375, \"color\": \"#FFFF00\"}, {\"page\": 12, \"x\": 353.7707824707031, \"y\": 631.5156860351562, \"width\": 8.690399169921875, \"height\": 6.915435791015625, \"color\": \"#FFFF00\"}, {\"page\": 12, \"x\": 365.4394836425781, \"y\": 631.5160980224609, \"width\": 8.690399169921875, \"height\": 20.755050659179688, \"color\": \"#FFFF00\"}, {\"page\": 12, \"x\": 377.1077575683594, \"y\": 631.5156860351562, \"width\": 8.690399169921875, \"height\": 27.233627319335938, \"color\": \"#FFFF00\"}, {\"page\": 12, \"x\": 388.7759094238281, \"y\": 631.5151672363281, \"width\": 8.690399169921875, \"height\": 17.721328735351562, \"color\": \"#FFFF00\"}, {\"page\": 12, \"x\": 400.4435729980469, \"y\": 631.5146484375, \"width\": 8.690399169921875, \"height\": 24.06634521484375, \"color\": \"#FFFF00\"}, {\"page\": 12, \"x\": 412.11273193359375, \"y\": 631.5151672363281, \"width\": 8.690399169921875, \"height\": 2.1612091064453125, \"color\": \"#FFFF00\"}, {\"page\": 12, \"x\": 423.781005859375, \"y\": 631.5160980224609, \"width\": 8.690399169921875, \"height\": 25.514389038085938, \"color\": \"#FFFF00\"}, {\"page\": 12, \"x\": 435.44970703125, \"y\": 631.5156860351562, \"width\": 8.690399169921875, \"height\": 22.060592651367188, \"color\": \"#FFFF00\"}, {\"page\": 12, \"x\": 447.1174621582031, \"y\": 631.5151672363281, \"width\": 8.690399169921875, \"height\": 22.060592651367188, \"color\": \"#FFFF00\"}, {\"page\": 12, \"x\": 458.7851257324219, \"y\": 631.5146484375, \"width\": 8.690399169921875, \"height\": 22.060577392578125, \"color\": \"#FFFF00\"}, {\"page\": 12, \"x\": 470.45379638671875, \"y\": 631.5151672363281, \"width\": 8.690399169921875, \"height\": 22.060592651367188, \"color\": \"#FFFF00\"}, {\"page\": 12, \"x\": 482.12255859375, \"y\": 631.5160980224609, \"width\": 8.690399169921875, \"height\": 22.060592651367188, \"color\": \"#FFFF00\"}, {\"page\": 12, \"x\": 493.791259765625, \"y\": 631.5156860351562, \"width\": 8.690399169921875, \"height\": 22.060592651367188, \"color\": \"#FFFF00\"}, {\"page\": 12, \"x\": 120.40522766113281, \"y\": 546.2929534912109, \"width\": 8.690399169921875, \"height\": 4.3237152099609375, \"color\": \"#FFFF00\"}, {\"page\": 12, \"x\": 132.0734100341797, \"y\": 544.9977111816406, \"width\": 8.690383911132812, \"height\": 5.616302490234375, \"color\": \"#FFFF00\"}, {\"page\": 12, \"x\": 143.74166870117188, \"y\": 544.5601959228516, \"width\": 8.690383911132812, \"height\": 6.0531005859375, \"color\": \"#FFFF00\"}, {\"page\": 12, \"x\": 155.4103546142578, \"y\": 538.5104217529297, \"width\": 8.690383911132812, \"height\": 12.103836059570312, \"color\": \"#FFFF00\"}, {\"page\": 12, \"x\": 167.07850646972656, \"y\": 534.1913146972656, \"width\": 8.690383911132812, \"height\": 16.419784545898438, \"color\": \"#FFFF00\"}, {\"page\": 12, \"x\": 178.7467803955078, \"y\": 537.6404724121094, \"width\": 8.690383911132812, \"height\": 12.9737548828125, \"color\": \"#FFFF00\"}, {\"page\": 12, \"x\": 190.41494750976562, \"y\": 546.288818359375, \"width\": 8.690383911132812, \"height\": 4.326202392578125, \"color\": \"#FFFF00\"}, {\"page\": 12, \"x\": 202.08311462402344, \"y\": 523.3849182128906, \"width\": 8.690383911132812, \"height\": 27.225845336914062, \"color\": \"#FFFF00\"}, {\"page\": 12, \"x\": 213.7513885498047, \"y\": 544.1277618408203, \"width\": 8.690383911132812, \"height\": 6.486236572265625, \"color\": \"#FFFF00\"}, {\"page\": 12, \"x\": 225.42005920410156, \"y\": 517.7609558105469, \"width\": 8.690383911132812, \"height\": 32.851104736328125, \"color\": \"#FFFF00\"}, {\"page\": 12, \"x\": 237.08824157714844, \"y\": 505.6476135253906, \"width\": 8.690383911132812, \"height\": 44.961517333984375, \"color\": \"#FFFF00\"}, {\"page\": 12, \"x\": 248.75650024414062, \"y\": 533.7467651367188, \"width\": 8.690399169921875, \"height\": 16.865646362304688, \"color\": \"#FFFF00\"}, {\"page\": 12, \"x\": 260.4246520996094, \"y\": 525.53076171875, \"width\": 8.690399169921875, \"height\": 25.080062866210938, \"color\": \"#FFFF00\"}, {\"page\": 12, \"x\": 272.0933532714844, \"y\": 536.34521484375, \"width\": 8.690399169921875, \"height\": 14.267669677734375, \"color\": \"#FFFF00\"}, {\"page\": 12, \"x\": 283.7615966796875, \"y\": 535.0541381835938, \"width\": 8.690399169921875, \"height\": 15.5576171875, \"color\": \"#FFFF00\"}, {\"page\": 12, \"x\": 295.4297790527344, \"y\": 532.4560852050781, \"width\": 8.690399169921875, \"height\": 18.15692138671875, \"color\": \"#FFFF00\"}, {\"page\": 12, \"x\": 307.0979309082031, \"y\": 533.3102722167969, \"width\": 8.690399169921875, \"height\": 17.30126953125, \"color\": \"#FFFF00\"}, {\"page\": 12, \"x\": 318.7662048339844, \"y\": 525.5384216308594, \"width\": 8.690399169921875, \"height\": 25.072280883789062, \"color\": \"#FFFF00\"}, {\"page\": 12, \"x\": 330.4343566894531, \"y\": 539.8016204833984, \"width\": 8.690399169921875, \"height\": 10.813735961914062, \"color\": \"#FFFF00\"}, {\"page\": 12, \"x\": 342.1026306152344, \"y\": 512.1354064941406, \"width\": 8.690399169921875, \"height\": 38.47520446777344, \"color\": \"#FFFF00\"}, {\"page\": 12, \"x\": 353.77130126953125, \"y\": 543.6989440917969, \"width\": 8.690399169921875, \"height\": 6.915435791015625, \"color\": \"#FFFF00\"}, {\"page\": 12, \"x\": 365.4394836425781, \"y\": 529.8575134277344, \"width\": 8.690399169921875, \"height\": 20.755050659179688, \"color\": \"#FFFF00\"}, {\"page\": 12, \"x\": 377.1077575683594, \"y\": 523.3782958984375, \"width\": 8.690399169921875, \"height\": 27.233612060546875, \"color\": \"#FFFF00\"}, {\"page\": 12, \"x\": 388.7759094238281, \"y\": 532.8925476074219, \"width\": 8.690399169921875, \"height\": 17.7213134765625, \"color\": \"#FFFF00\"}, {\"page\": 12, \"x\": 400.4435729980469, \"y\": 526.5458068847656, \"width\": 8.690399169921875, \"height\": 24.066360473632812, \"color\": \"#FFFF00\"}, {\"page\": 12, \"x\": 412.1123352050781, \"y\": 548.4540100097656, \"width\": 8.690399169921875, \"height\": 2.1612091064453125, \"color\": \"#FFFF00\"}, {\"page\": 12, \"x\": 423.781005859375, \"y\": 525.1019287109375, \"width\": 8.690399169921875, \"height\": 25.514389038085938, \"color\": \"#FFFF00\"}, {\"page\": 12, \"x\": 435.44866943359375, \"y\": 528.5510864257812, \"width\": 8.690399169921875, \"height\": 22.060592651367188, \"color\": \"#FFFF00\"}, {\"page\": 12, \"x\": 447.1174621582031, \"y\": 528.5510864257812, \"width\": 8.690399169921875, \"height\": 22.060592651367188, \"color\": \"#FFFF00\"}, {\"page\": 12, \"x\": 458.7851257324219, \"y\": 528.5516052246094, \"width\": 8.690399169921875, \"height\": 22.060592651367188, \"color\": \"#FFFF00\"}, {\"page\": 12, \"x\": 470.45379638671875, \"y\": 528.5510864257812, \"width\": 8.690399169921875, \"height\": 22.060592651367188, \"color\": \"#FFFF00\"}, {\"page\": 12, \"x\": 482.12255859375, \"y\": 528.5506591796875, \"width\": 8.690399169921875, \"height\": 22.06060791015625, \"color\": \"#FFFF00\"}, {\"page\": 12, \"x\": 493.791259765625, \"y\": 528.5510864257812, \"width\": 8.690399169921875, \"height\": 22.060592651367188, \"color\": \"#FFFF00\"}, {\"page\": 12, \"x\": 108.0, \"y\": 469.2585144042969, \"width\": 395.9972839355469, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 12, \"x\": 108.0, \"y\": 458.3485107421875, \"width\": 395.9971923828125, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 12, \"x\": 108.0, \"y\": 447.43951416015625, \"width\": 396.1712646484375, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 12, \"x\": 108.0, \"y\": 436.5304870605469, \"width\": 332.91021728515625, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 12, \"x\": 301.01898193359375, \"y\": 39.3125, \"width\": 9.96258544921875, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 13, \"x\": 108.0, \"y\": 672.3383407592773, \"width\": 170.6871337890625, \"height\": 21.86016082763672, \"color\": \"#FFFF00\"}, {\"page\": 13, \"x\": 122.85926055908203, \"y\": 576.7845916748047, \"width\": 10.409538269042969, \"height\": 16.055694580078125, \"color\": \"#FFFF00\"}, {\"page\": 13, \"x\": 136.8356475830078, \"y\": 576.7852172851562, \"width\": 10.409530639648438, \"height\": 17.090087890625, \"color\": \"#FFFF00\"}, {\"page\": 13, \"x\": 150.81216430664062, \"y\": 576.7858428955078, \"width\": 10.409530639648438, \"height\": 12.9344482421875, \"color\": \"#FFFF00\"}]"}, "type": "Document"}
{"page_content": "never be perfect , but its application should be just - this is what we are missing , in my opinion . <EOS> <pad> The Law will never be perfect , but its application should be just - this is what we are missing , in my opinion . <EOS> <pad> Input-Input Layer5 The Law will never be perfect , but its application should be just - this is what we are missing , in my opinion . <EOS> <pad> The Law will never be perfect , but its application should be just - this is what we are missing , in my opinion . <EOS> <pad> Figure 4: Two attention heads, also in layer 5 of 6, apparently involved in anaphora resolution. Top: Full attentions for head 5. Bottom: Isolated attentions from just the word ‘its’ for attention heads 5 and 6. Note that the attentions are very sharp for this word. 14 Input-Input Layer5 The Law will never be perfect , but its application should be just - this is what we are missing , in my opinion . <EOS> <pad> The Law will never be perfect , but its application should be just -", "metadata": {"source": "../paper/attention_is_all_you_need.pdf", "title": "", "pid": "40", "annotations": "[{\"page\": 13, \"x\": 164.78854370117188, \"y\": 576.7858428955078, \"width\": 10.409530639648438, \"height\": 23.303451538085938, \"color\": \"#FFFF00\"}, {\"page\": 13, \"x\": 178.76553344726562, \"y\": 576.7852172851562, \"width\": 10.409530639648438, \"height\": 10.36260986328125, \"color\": \"#FFFF00\"}, {\"page\": 13, \"x\": 192.7420654296875, \"y\": 576.7858428955078, \"width\": 10.409530639648438, \"height\": 28.482406616210938, \"color\": \"#FFFF00\"}, {\"page\": 13, \"x\": 206.71844482421875, \"y\": 576.7852172851562, \"width\": 10.409530639648438, \"height\": 2.5887298583984375, \"color\": \"#FFFF00\"}, {\"page\": 13, \"x\": 220.69482421875, \"y\": 576.7858428955078, \"width\": 10.409530639648438, \"height\": 12.949920654296875, \"color\": \"#FFFF00\"}, {\"page\": 13, \"x\": 234.6713409423828, \"y\": 576.7852172851562, \"width\": 10.409530639648438, \"height\": 9.317626953125, \"color\": \"#FFFF00\"}, {\"page\": 13, \"x\": 248.6483154296875, \"y\": 576.7852172851562, \"width\": 10.4095458984375, \"height\": 44.53965759277344, \"color\": \"#FFFF00\"}, {\"page\": 13, \"x\": 262.6247253417969, \"y\": 576.7858428955078, \"width\": 10.4095458984375, \"height\": 27.451141357421875, \"color\": \"#FFFF00\"}, {\"page\": 13, \"x\": 276.6012268066406, \"y\": 576.7852172851562, \"width\": 10.4095458984375, \"height\": 10.36260986328125, \"color\": \"#FFFF00\"}, {\"page\": 13, \"x\": 290.5776062011719, \"y\": 576.7858428955078, \"width\": 10.4095458984375, \"height\": 14.496658325195312, \"color\": \"#FFFF00\"}, {\"page\": 13, \"x\": 304.5539855957031, \"y\": 576.7852172851562, \"width\": 10.4095458984375, \"height\": 3.10284423828125, \"color\": \"#FFFF00\"}, {\"page\": 13, \"x\": 318.530517578125, \"y\": 576.7852172851562, \"width\": 10.4095458984375, \"height\": 14.49822998046875, \"color\": \"#FFFF00\"}, {\"page\": 13, \"x\": 332.50750732421875, \"y\": 576.7858428955078, \"width\": 10.4095458984375, \"height\": 6.727325439453125, \"color\": \"#FFFF00\"}, {\"page\": 13, \"x\": 346.48388671875, \"y\": 576.7852172851562, \"width\": 10.4095458984375, \"height\": 19.677261352539062, \"color\": \"#FFFF00\"}, {\"page\": 13, \"x\": 360.46038818359375, \"y\": 576.7858428955078, \"width\": 10.4095458984375, \"height\": 11.909347534179688, \"color\": \"#FFFF00\"}, {\"page\": 13, \"x\": 374.4367980957031, \"y\": 576.7852172851562, \"width\": 10.4095458984375, \"height\": 13.46539306640625, \"color\": \"#FFFF00\"}, {\"page\": 13, \"x\": 388.4132995605469, \"y\": 576.7845916748047, \"width\": 10.4095458984375, \"height\": 31.578857421875, \"color\": \"#FFFF00\"}, {\"page\": 13, \"x\": 402.3896789550781, \"y\": 576.7858428955078, \"width\": 10.4095458984375, \"height\": 2.5887298583984375, \"color\": \"#FFFF00\"}, {\"page\": 13, \"x\": 416.3666687011719, \"y\": 576.7864532470703, \"width\": 10.4095458984375, \"height\": 7.2505340576171875, \"color\": \"#FFFF00\"}, {\"page\": 13, \"x\": 430.34320068359375, \"y\": 576.7858428955078, \"width\": 10.4095458984375, \"height\": 12.420394897460938, \"color\": \"#FFFF00\"}, {\"page\": 13, \"x\": 444.3195495605469, \"y\": 576.7852172851562, \"width\": 10.4095458984375, \"height\": 30.04144287109375, \"color\": \"#FFFF00\"}, {\"page\": 13, \"x\": 458.29534912109375, \"y\": 576.7845916748047, \"width\": 10.4095458984375, \"height\": 2.5887298583984375, \"color\": \"#FFFF00\"}, {\"page\": 13, \"x\": 472.27294921875, \"y\": 576.7852172851562, \"width\": 10.4095458984375, \"height\": 30.561660766601562, \"color\": \"#FFFF00\"}, {\"page\": 13, \"x\": 486.24945068359375, \"y\": 576.7864532470703, \"width\": 10.4095458984375, \"height\": 26.424652099609375, \"color\": \"#FFFF00\"}, {\"page\": 13, \"x\": 122.85926055908203, \"y\": 463.8263854980469, \"width\": 10.409538269042969, \"height\": 16.055694580078125, \"color\": \"#FFFF00\"}, {\"page\": 13, \"x\": 136.8356475830078, \"y\": 462.7886962890625, \"width\": 10.409530639648438, \"height\": 17.090087890625, \"color\": \"#FFFF00\"}, {\"page\": 13, \"x\": 150.81216430664062, \"y\": 466.9413757324219, \"width\": 10.409530639648438, \"height\": 12.934417724609375, \"color\": \"#FFFF00\"}, {\"page\": 13, \"x\": 164.78915405273438, \"y\": 456.5737609863281, \"width\": 10.409530639648438, \"height\": 23.303466796875, \"color\": \"#FFFF00\"}, {\"page\": 13, \"x\": 178.76553344726562, \"y\": 469.51727294921875, \"width\": 10.409530639648438, \"height\": 10.36260986328125, \"color\": \"#FFFF00\"}, {\"page\": 13, \"x\": 192.7420654296875, \"y\": 451.3965148925781, \"width\": 10.409530639648438, \"height\": 28.482452392578125, \"color\": \"#FFFF00\"}, {\"page\": 13, \"x\": 206.71844482421875, \"y\": 477.292724609375, \"width\": 10.409530639648438, \"height\": 2.5887451171875, \"color\": \"#FFFF00\"}, {\"page\": 13, \"x\": 220.69482421875, \"y\": 466.9281005859375, \"width\": 10.409530639648438, \"height\": 12.949951171875, \"color\": \"#FFFF00\"}, {\"page\": 13, \"x\": 234.6713409423828, \"y\": 470.56414794921875, \"width\": 10.409530639648438, \"height\": 9.317626953125, \"color\": \"#FFFF00\"}, {\"page\": 13, \"x\": 248.6483154296875, \"y\": 435.3319396972656, \"width\": 10.4095458984375, \"height\": 44.539703369140625, \"color\": \"#FFFF00\"}, {\"page\": 13, \"x\": 262.6247253417969, \"y\": 452.4246520996094, \"width\": 10.4095458984375, \"height\": 27.451202392578125, \"color\": \"#FFFF00\"}, {\"page\": 13, \"x\": 276.6012268066406, \"y\": 469.51727294921875, \"width\": 10.4095458984375, \"height\": 10.36260986328125, \"color\": \"#FFFF00\"}, {\"page\": 13, \"x\": 290.5776062011719, \"y\": 465.3808288574219, \"width\": 10.4095458984375, \"height\": 14.496673583984375, \"color\": \"#FFFF00\"}, {\"page\": 13, \"x\": 304.55462646484375, \"y\": 476.7784729003906, \"width\": 10.4095458984375, \"height\": 3.10284423828125, \"color\": \"#FFFF00\"}, {\"page\": 13, \"x\": 318.5311279296875, \"y\": 465.3826904296875, \"width\": 10.4095458984375, \"height\": 14.49822998046875, \"color\": \"#FFFF00\"}, {\"page\": 13, \"x\": 332.50750732421875, \"y\": 473.1527099609375, \"width\": 10.4095458984375, \"height\": 6.727325439453125, \"color\": \"#FFFF00\"}, {\"page\": 13, \"x\": 346.48388671875, \"y\": 460.19952392578125, \"width\": 10.4095458984375, \"height\": 19.677276611328125, \"color\": \"#FFFF00\"}, {\"page\": 13, \"x\": 360.46038818359375, \"y\": 467.9695129394531, \"width\": 10.4095458984375, \"height\": 11.909332275390625, \"color\": \"#FFFF00\"}, {\"page\": 13, \"x\": 374.4367980957031, \"y\": 466.4143371582031, \"width\": 10.4095458984375, \"height\": 13.465362548828125, \"color\": \"#FFFF00\"}, {\"page\": 13, \"x\": 388.4132995605469, \"y\": 448.29852294921875, \"width\": 10.4095458984375, \"height\": 31.578857421875, \"color\": \"#FFFF00\"}, {\"page\": 13, \"x\": 402.3902893066406, \"y\": 477.292724609375, \"width\": 10.4095458984375, \"height\": 2.5887451171875, \"color\": \"#FFFF00\"}, {\"page\": 13, \"x\": 416.3666687011719, \"y\": 472.6292724609375, \"width\": 10.4095458984375, \"height\": 7.25054931640625, \"color\": \"#FFFF00\"}, {\"page\": 13, \"x\": 430.34320068359375, \"y\": 467.4599609375, \"width\": 10.4095458984375, \"height\": 12.42041015625, \"color\": \"#FFFF00\"}, {\"page\": 13, \"x\": 444.3195495605469, \"y\": 449.8311462402344, \"width\": 10.4095458984375, \"height\": 30.041473388671875, \"color\": \"#FFFF00\"}, {\"page\": 13, \"x\": 458.29534912109375, \"y\": 477.2933349609375, \"width\": 10.4095458984375, \"height\": 2.5887451171875, \"color\": \"#FFFF00\"}, {\"page\": 13, \"x\": 472.2724609375, \"y\": 449.32171630859375, \"width\": 10.4095458984375, \"height\": 30.561676025390625, \"color\": \"#FFFF00\"}, {\"page\": 13, \"x\": 486.24945068359375, \"y\": 453.45208740234375, \"width\": 10.4095458984375, \"height\": 26.42462158203125, \"color\": \"#FFFF00\"}, {\"page\": 13, \"x\": 108.0, \"y\": 456.15997314453125, \"width\": 172.60491943359375, \"height\": 22.10577392578125, \"color\": \"#FFFF00\"}, {\"page\": 13, \"x\": 123.0262222290039, \"y\": 359.5326232910156, \"width\": 10.526496887207031, \"height\": 16.236053466796875, \"color\": \"#FFFF00\"}, {\"page\": 13, \"x\": 137.15963745117188, \"y\": 359.53326416015625, \"width\": 10.5264892578125, \"height\": 17.2821044921875, \"color\": \"#FFFF00\"}, {\"page\": 13, \"x\": 151.29318237304688, \"y\": 359.53387451171875, \"width\": 10.5264892578125, \"height\": 13.0797119140625, \"color\": \"#FFFF00\"}, {\"page\": 13, \"x\": 165.42660522460938, \"y\": 359.53387451171875, \"width\": 10.5264892578125, \"height\": 23.5653076171875, \"color\": \"#FFFF00\"}, {\"page\": 13, \"x\": 179.56063842773438, \"y\": 359.53326416015625, \"width\": 10.526504516601562, \"height\": 10.47900390625, \"color\": \"#FFFF00\"}, {\"page\": 13, \"x\": 193.69418334960938, \"y\": 359.53387451171875, \"width\": 10.526504516601562, \"height\": 28.802459716796875, \"color\": \"#FFFF00\"}, {\"page\": 13, \"x\": 207.82760620117188, \"y\": 359.53326416015625, \"width\": 10.526504516601562, \"height\": 2.617828369140625, \"color\": \"#FFFF00\"}, {\"page\": 13, \"x\": 221.96102905273438, \"y\": 359.53387451171875, \"width\": 10.5264892578125, \"height\": 13.095428466796875, \"color\": \"#FFFF00\"}, {\"page\": 13, \"x\": 236.09457397460938, \"y\": 359.53326416015625, \"width\": 10.526504516601562, \"height\": 9.42230224609375, \"color\": \"#FFFF00\"}, {\"page\": 13, \"x\": 250.22860717773438, \"y\": 359.53326416015625, \"width\": 10.526519775390625, \"height\": 45.040069580078125, \"color\": \"#FFFF00\"}, {\"page\": 13, \"x\": 264.3620300292969, \"y\": 359.53387451171875, \"width\": 10.526519775390625, \"height\": 27.75958251953125, \"color\": \"#FFFF00\"}, {\"page\": 13, \"x\": 278.4955749511719, \"y\": 359.53326416015625, \"width\": 10.526519775390625, \"height\": 10.47900390625, \"color\": \"#FFFF00\"}, {\"page\": 13, \"x\": 292.62896728515625, \"y\": 359.53387451171875, \"width\": 10.526519775390625, \"height\": 14.6595458984375, \"color\": \"#FFFF00\"}, {\"page\": 13, \"x\": 306.76239013671875, \"y\": 359.53326416015625, \"width\": 10.526519775390625, \"height\": 3.1376953125, \"color\": \"#FFFF00\"}, {\"page\": 13, \"x\": 320.89593505859375, \"y\": 359.53326416015625, \"width\": 10.526519775390625, \"height\": 14.661102294921875, \"color\": \"#FFFF00\"}, {\"page\": 13, \"x\": 335.030029296875, \"y\": 359.53387451171875, \"width\": 10.526519775390625, \"height\": 6.802886962890625, \"color\": \"#FFFF00\"}, {\"page\": 13, \"x\": 349.1634216308594, \"y\": 359.53326416015625, \"width\": 10.526519775390625, \"height\": 19.898345947265625, \"color\": \"#FFFF00\"}, {\"page\": 13, \"x\": 363.2969665527344, \"y\": 359.53387451171875, \"width\": 10.526519775390625, \"height\": 12.04315185546875, \"color\": \"#FFFF00\"}, {\"page\": 13, \"x\": 377.4303894042969, \"y\": 359.53326416015625, \"width\": 10.526519775390625, \"height\": 13.616668701171875, \"color\": \"#FFFF00\"}, {\"page\": 13, \"x\": 391.5639343261719, \"y\": 359.5326232910156, \"width\": 10.526519775390625, \"height\": 31.93365478515625, \"color\": \"#FFFF00\"}, {\"page\": 13, \"x\": 405.6973571777344, \"y\": 359.53387451171875, \"width\": 10.526519775390625, \"height\": 2.617828369140625, \"color\": \"#FFFF00\"}, {\"page\": 13, \"x\": 419.8313903808594, \"y\": 359.53436279296875, \"width\": 10.526519775390625, \"height\": 7.332000732421875, \"color\": \"#FFFF00\"}, {\"page\": 13, \"x\": 433.9649658203125, \"y\": 359.53387451171875, \"width\": 10.526519775390625, \"height\": 12.559967041015625, \"color\": \"#FFFF00\"}, {\"page\": 13, \"x\": 448.0983581542969, \"y\": 359.53326416015625, \"width\": 10.526519775390625, \"height\": 30.37896728515625, \"color\": \"#FFFF00\"}, {\"page\": 13, \"x\": 462.2311706542969, \"y\": 359.5326232910156, \"width\": 10.526519775390625, \"height\": 2.617828369140625, \"color\": \"#FFFF00\"}, {\"page\": 13, \"x\": 476.3658142089844, \"y\": 359.53326416015625, \"width\": 10.526519775390625, \"height\": 30.905059814453125, \"color\": \"#FFFF00\"}, {\"page\": 13, \"x\": 490.4993591308594, \"y\": 359.53436279296875, \"width\": 10.526519775390625, \"height\": 26.7215576171875, \"color\": \"#FFFF00\"}, {\"page\": 13, \"x\": 123.0262222290039, \"y\": 245.30523681640625, \"width\": 10.526496887207031, \"height\": 16.236083984375, \"color\": \"#FFFF00\"}, {\"page\": 13, \"x\": 137.15963745117188, \"y\": 244.2557373046875, \"width\": 10.5264892578125, \"height\": 17.28216552734375, \"color\": \"#FFFF00\"}, {\"page\": 13, \"x\": 151.29318237304688, \"y\": 248.4552001953125, \"width\": 10.5264892578125, \"height\": 13.07977294921875, \"color\": \"#FFFF00\"}, {\"page\": 13, \"x\": 165.42721557617188, \"y\": 237.97113037109375, \"width\": 10.526504516601562, \"height\": 23.56524658203125, \"color\": \"#FFFF00\"}, {\"page\": 13, \"x\": 179.56063842773438, \"y\": 251.06005859375, \"width\": 10.526504516601562, \"height\": 10.47906494140625, \"color\": \"#FFFF00\"}, {\"page\": 13, \"x\": 193.69418334960938, \"y\": 232.7357177734375, \"width\": 10.526504516601562, \"height\": 28.80242919921875, \"color\": \"#FFFF00\"}, {\"page\": 13, \"x\": 207.82760620117188, \"y\": 258.92291259765625, \"width\": 10.526504516601562, \"height\": 2.6177978515625, \"color\": \"#FFFF00\"}, {\"page\": 13, \"x\": 221.96102905273438, \"y\": 248.4417724609375, \"width\": 10.5264892578125, \"height\": 13.095458984375, \"color\": \"#FFFF00\"}, {\"page\": 13, \"x\": 236.09457397460938, \"y\": 252.11859130859375, \"width\": 10.526504516601562, \"height\": 9.42236328125, \"color\": \"#FFFF00\"}, {\"page\": 13, \"x\": 250.22860717773438, \"y\": 216.49066162109375, \"width\": 10.526519775390625, \"height\": 45.04010009765625, \"color\": \"#FFFF00\"}, {\"page\": 13, \"x\": 264.3620300292969, \"y\": 233.7752685546875, \"width\": 10.526519775390625, \"height\": 27.7596435546875, \"color\": \"#FFFF00\"}, {\"page\": 13, \"x\": 278.4955749511719, \"y\": 251.06005859375, \"width\": 10.526519775390625, \"height\": 10.47906494140625, \"color\": \"#FFFF00\"}, {\"page\": 13, \"x\": 292.62896728515625, \"y\": 246.87713623046875, \"width\": 10.526519775390625, \"height\": 14.6595458984375, \"color\": \"#FFFF00\"}, {\"page\": 13, \"x\": 306.7630615234375, \"y\": 258.4027099609375, \"width\": 10.526519775390625, \"height\": 3.1376953125, \"color\": \"#FFFF00\"}, {\"page\": 13, \"x\": 320.8966064453125, \"y\": 246.8790283203125, \"width\": 10.526519775390625, \"height\": 14.66119384765625, \"color\": \"#FFFF00\"}, {\"page\": 13, \"x\": 335.030029296875, \"y\": 254.736328125, \"width\": 10.526519775390625, \"height\": 6.802978515625, \"color\": \"#FFFF00\"}, {\"page\": 13, \"x\": 349.1634216308594, \"y\": 241.63751220703125, \"width\": 10.526519775390625, \"height\": 19.8983154296875, \"color\": \"#FFFF00\"}, {\"page\": 13, \"x\": 363.2969665527344, \"y\": 249.49481201171875, \"width\": 10.526519775390625, \"height\": 12.04315185546875, \"color\": \"#FFFF00\"}, {\"page\": 13, \"x\": 377.4303894042969, \"y\": 247.9222412109375, \"width\": 10.526519775390625, \"height\": 13.61669921875, \"color\": \"#FFFF00\"}, {\"page\": 13, \"x\": 391.5639343261719, \"y\": 229.602783203125, \"width\": 10.526519775390625, \"height\": 31.9337158203125, \"color\": \"#FFFF00\"}, {\"page\": 13, \"x\": 405.6979675292969, \"y\": 258.92291259765625, \"width\": 10.526519775390625, \"height\": 2.6177978515625, \"color\": \"#FFFF00\"}, {\"page\": 13, \"x\": 419.8313903808594, \"y\": 254.20703125, \"width\": 10.526519775390625, \"height\": 7.33197021484375, \"color\": \"#FFFF00\"}, {\"page\": 13, \"x\": 433.9649658203125, \"y\": 248.97967529296875, \"width\": 10.526519775390625, \"height\": 12.5599365234375, \"color\": \"#FFFF00\"}, {\"page\": 13, \"x\": 448.0983581542969, \"y\": 231.15277099609375, \"width\": 10.526519775390625, \"height\": 30.37896728515625, \"color\": \"#FFFF00\"}, {\"page\": 13, \"x\": 462.2311706542969, \"y\": 258.92352294921875, \"width\": 10.526519775390625, \"height\": 2.6177978515625, \"color\": \"#FFFF00\"}, {\"page\": 13, \"x\": 476.3653259277344, \"y\": 230.63763427734375, \"width\": 10.526519775390625, \"height\": 30.905029296875, \"color\": \"#FFFF00\"}, {\"page\": 13, \"x\": 490.4993591308594, \"y\": 234.81439208984375, \"width\": 10.526519775390625, \"height\": 26.7215576171875, \"color\": \"#FFFF00\"}, {\"page\": 13, \"x\": 108.0, \"y\": 167.36346435546875, \"width\": 397.3879699707031, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 13, \"x\": 108.0, \"y\": 156.45452880859375, \"width\": 395.9976806640625, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 13, \"x\": 108.0, \"y\": 145.54547119140625, \"width\": 235.25680541992188, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 13, \"x\": 301.01898193359375, \"y\": 39.3125, \"width\": 9.96258544921875, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 14, \"x\": 106.9734878540039, \"y\": 658.0395660400391, \"width\": 171.13838958740234, \"height\": 21.917953491210938, \"color\": \"#FFFF00\"}, {\"page\": 14, \"x\": 121.87202453613281, \"y\": 562.2332000732422, \"width\": 10.437057495117188, \"height\": 16.09814453125, \"color\": \"#FFFF00\"}, {\"page\": 14, \"x\": 135.88536071777344, \"y\": 562.2338256835938, \"width\": 10.437057495117188, \"height\": 17.135284423828125, \"color\": \"#FFFF00\"}, {\"page\": 14, \"x\": 149.89881896972656, \"y\": 562.2344512939453, \"width\": 10.437057495117188, \"height\": 12.9686279296875, \"color\": \"#FFFF00\"}, {\"page\": 14, \"x\": 163.9121551513672, \"y\": 562.2344512939453, \"width\": 10.437057495117188, \"height\": 23.365066528320312, \"color\": \"#FFFF00\"}, {\"page\": 14, \"x\": 177.92611694335938, \"y\": 562.2338256835938, \"width\": 10.437057495117188, \"height\": 10.3900146484375, \"color\": \"#FFFF00\"}, {\"page\": 14, \"x\": 191.93955993652344, \"y\": 562.2344512939453, \"width\": 10.437057495117188, \"height\": 28.5577392578125, \"color\": \"#FFFF00\"}, {\"page\": 14, \"x\": 205.95289611816406, \"y\": 562.2338256835938, \"width\": 10.437057495117188, \"height\": 2.5955810546875, \"color\": \"#FFFF00\"}, {\"page\": 14, \"x\": 219.96624755859375, \"y\": 562.2344512939453, \"width\": 10.437057495117188, \"height\": 12.984176635742188, \"color\": \"#FFFF00\"}, {\"page\": 14, \"x\": 233.9796905517578, \"y\": 562.2338256835938, \"width\": 10.437057495117188, \"height\": 9.342254638671875, \"color\": \"#FFFF00\"}, {\"page\": 14, \"x\": 247.99365234375, \"y\": 562.2338256835938, \"width\": 10.43707275390625, \"height\": 44.65742492675781, \"color\": \"#FFFF00\"}, {\"page\": 14, \"x\": 262.0069885253906, \"y\": 562.2344512939453, \"width\": 10.43707275390625, \"height\": 27.523712158203125, \"color\": \"#FFFF00\"}, {\"page\": 14, \"x\": 276.02044677734375, \"y\": 562.2338256835938, \"width\": 10.43707275390625, \"height\": 10.3900146484375, \"color\": \"#FFFF00\"}, {\"page\": 14, \"x\": 290.0337829589844, \"y\": 562.2344512939453, \"width\": 10.43707275390625, \"height\": 14.534988403320312, \"color\": \"#FFFF00\"}, {\"page\": 14, \"x\": 304.047119140625, \"y\": 562.2338256835938, \"width\": 10.43707275390625, \"height\": 3.111053466796875, \"color\": \"#FFFF00\"}, {\"page\": 14, \"x\": 318.0605773925781, \"y\": 562.2338256835938, \"width\": 10.43707275390625, \"height\": 14.53656005859375, \"color\": \"#FFFF00\"}, {\"page\": 14, \"x\": 332.07452392578125, \"y\": 562.2344512939453, \"width\": 10.43707275390625, \"height\": 6.7451171875, \"color\": \"#FFFF00\"}, {\"page\": 14, \"x\": 346.0878601074219, \"y\": 562.2338256835938, \"width\": 10.43707275390625, \"height\": 19.729293823242188, \"color\": \"#FFFF00\"}, {\"page\": 14, \"x\": 360.101318359375, \"y\": 562.2344512939453, \"width\": 10.43707275390625, \"height\": 11.940841674804688, \"color\": \"#FFFF00\"}, {\"page\": 14, \"x\": 374.1146545410156, \"y\": 562.2338256835938, \"width\": 10.43707275390625, \"height\": 13.500991821289062, \"color\": \"#FFFF00\"}, {\"page\": 14, \"x\": 388.12811279296875, \"y\": 562.2332000732422, \"width\": 10.43707275390625, \"height\": 31.662353515625, \"color\": \"#FFFF00\"}, {\"page\": 14, \"x\": 402.1414489746094, \"y\": 562.2344512939453, \"width\": 10.43707275390625, \"height\": 2.5955810546875, \"color\": \"#FFFF00\"}, {\"page\": 14, \"x\": 416.1553955078125, \"y\": 562.2349395751953, \"width\": 10.43707275390625, \"height\": 7.26971435546875, \"color\": \"#FFFF00\"}, {\"page\": 14, \"x\": 430.1688537597656, \"y\": 562.2344512939453, \"width\": 10.43707275390625, \"height\": 12.453231811523438, \"color\": \"#FFFF00\"}, {\"page\": 14, \"x\": 444.18218994140625, \"y\": 562.2338256835938, \"width\": 10.43707275390625, \"height\": 30.120864868164062, \"color\": \"#FFFF00\"}, {\"page\": 14, \"x\": 458.1949157714844, \"y\": 562.2332000732422, \"width\": 10.43707275390625, \"height\": 2.5955810546875, \"color\": \"#FFFF00\"}, {\"page\": 14, \"x\": 472.2095947265625, \"y\": 562.2338256835938, \"width\": 10.43707275390625, \"height\": 30.642471313476562, \"color\": \"#FFFF00\"}, {\"page\": 14, \"x\": 486.2229309082031, \"y\": 562.2349395751953, \"width\": 10.43707275390625, \"height\": 26.4945068359375, \"color\": \"#FFFF00\"}, {\"page\": 14, \"x\": 121.87202453613281, \"y\": 448.97637939453125, \"width\": 10.437057495117188, \"height\": 16.098114013671875, \"color\": \"#FFFF00\"}, {\"page\": 14, \"x\": 135.88536071777344, \"y\": 447.935791015625, \"width\": 10.437057495117188, \"height\": 17.135284423828125, \"color\": \"#FFFF00\"}, {\"page\": 14, \"x\": 149.89881896972656, \"y\": 452.0995788574219, \"width\": 10.437057495117188, \"height\": 12.968658447265625, \"color\": \"#FFFF00\"}, {\"page\": 14, \"x\": 163.91278076171875, \"y\": 441.7045593261719, \"width\": 10.437057495117188, \"height\": 23.365081787109375, \"color\": \"#FFFF00\"}, {\"page\": 14, \"x\": 177.92611694335938, \"y\": 454.6822814941406, \"width\": 10.437057495117188, \"height\": 10.3900146484375, \"color\": \"#FFFF00\"}, {\"page\": 14, \"x\": 191.93955993652344, \"y\": 436.51361083984375, \"width\": 10.437057495117188, \"height\": 28.5577392578125, \"color\": \"#FFFF00\"}, {\"page\": 14, \"x\": 205.95289611816406, \"y\": 462.4783020019531, \"width\": 10.437057495117188, \"height\": 2.5955810546875, \"color\": \"#FFFF00\"}, {\"page\": 14, \"x\": 219.96624755859375, \"y\": 452.0862731933594, \"width\": 10.437057495117188, \"height\": 12.984161376953125, \"color\": \"#FFFF00\"}, {\"page\": 14, \"x\": 233.9796905517578, \"y\": 455.7318115234375, \"width\": 10.437057495117188, \"height\": 9.34228515625, \"color\": \"#FFFF00\"}, {\"page\": 14, \"x\": 247.99365234375, \"y\": 420.4065856933594, \"width\": 10.43707275390625, \"height\": 44.657440185546875, \"color\": \"#FFFF00\"}, {\"page\": 14, \"x\": 262.0069885253906, \"y\": 437.54437255859375, \"width\": 10.43707275390625, \"height\": 27.523712158203125, \"color\": \"#FFFF00\"}, {\"page\": 14, \"x\": 276.02044677734375, \"y\": 454.6822814941406, \"width\": 10.43707275390625, \"height\": 10.3900146484375, \"color\": \"#FFFF00\"}, {\"page\": 14, \"x\": 290.0337829589844, \"y\": 450.534912109375, \"width\": 10.43707275390625, \"height\": 14.535003662109375, \"color\": \"#FFFF00\"}, {\"page\": 14, \"x\": 304.0477600097656, \"y\": 461.9625549316406, \"width\": 10.43707275390625, \"height\": 3.111053466796875, \"color\": \"#FFFF00\"}]"}, "type": "Document"}
{"page_content": "this is what we are missing , in my opinion . <EOS> <pad> Input-Input Layer5 The Law will never be perfect , but its application should be just - this is what we are missing , in my opinion . <EOS> <pad> The Law will never be perfect , but its application should be just - this is what we are missing , in my opinion . <EOS> <pad> Figure 5: Many of the attention heads exhibit behaviour that seems related to the structure of the sentence. We give two such examples above, from two different heads from the encoder self-attention at layer 5 of 6. The heads clearly learned to perform different tasks. 15", "metadata": {"source": "../paper/attention_is_all_you_need.pdf", "title": "", "pid": "41", "annotations": "[{\"page\": 14, \"x\": 318.0611877441406, \"y\": 450.5367736816406, \"width\": 10.43707275390625, \"height\": 14.536590576171875, \"color\": \"#FFFF00\"}, {\"page\": 14, \"x\": 332.07452392578125, \"y\": 458.32733154296875, \"width\": 10.43707275390625, \"height\": 6.7451171875, \"color\": \"#FFFF00\"}, {\"page\": 14, \"x\": 346.0878601074219, \"y\": 445.33978271484375, \"width\": 10.43707275390625, \"height\": 19.729278564453125, \"color\": \"#FFFF00\"}, {\"page\": 14, \"x\": 360.101318359375, \"y\": 453.13031005859375, \"width\": 10.43707275390625, \"height\": 11.940826416015625, \"color\": \"#FFFF00\"}, {\"page\": 14, \"x\": 374.1146545410156, \"y\": 451.5711364746094, \"width\": 10.43707275390625, \"height\": 13.5009765625, \"color\": \"#FFFF00\"}, {\"page\": 14, \"x\": 388.12811279296875, \"y\": 433.4073486328125, \"width\": 10.43707275390625, \"height\": 31.662322998046875, \"color\": \"#FFFF00\"}, {\"page\": 14, \"x\": 402.1420593261719, \"y\": 462.4783020019531, \"width\": 10.43707275390625, \"height\": 2.5955810546875, \"color\": \"#FFFF00\"}, {\"page\": 14, \"x\": 416.1553955078125, \"y\": 457.8025207519531, \"width\": 10.43707275390625, \"height\": 7.269683837890625, \"color\": \"#FFFF00\"}, {\"page\": 14, \"x\": 430.1688537597656, \"y\": 452.6195373535156, \"width\": 10.43707275390625, \"height\": 12.453277587890625, \"color\": \"#FFFF00\"}, {\"page\": 14, \"x\": 444.18218994140625, \"y\": 434.9441223144531, \"width\": 10.43707275390625, \"height\": 30.120880126953125, \"color\": \"#FFFF00\"}, {\"page\": 14, \"x\": 458.1949157714844, \"y\": 462.47894287109375, \"width\": 10.43707275390625, \"height\": 2.5955810546875, \"color\": \"#FFFF00\"}, {\"page\": 14, \"x\": 472.208984375, \"y\": 434.433349609375, \"width\": 10.43707275390625, \"height\": 30.642486572265625, \"color\": \"#FFFF00\"}, {\"page\": 14, \"x\": 486.2229309082031, \"y\": 438.5746154785156, \"width\": 10.43707275390625, \"height\": 26.494537353515625, \"color\": \"#FFFF00\"}, {\"page\": 14, \"x\": 106.76576232910156, \"y\": 439.779296875, \"width\": 171.2223358154297, \"height\": 21.928680419921875, \"color\": \"#FFFF00\"}, {\"page\": 14, \"x\": 121.6716079711914, \"y\": 343.92596435546875, \"width\": 10.442176818847656, \"height\": 16.106048583984375, \"color\": \"#FFFF00\"}, {\"page\": 14, \"x\": 135.69180297851562, \"y\": 343.92657470703125, \"width\": 10.442184448242188, \"height\": 17.1436767578125, \"color\": \"#FFFF00\"}, {\"page\": 14, \"x\": 149.71214294433594, \"y\": 343.92718505859375, \"width\": 10.442184448242188, \"height\": 12.975006103515625, \"color\": \"#FFFF00\"}, {\"page\": 14, \"x\": 163.7323455810547, \"y\": 343.92718505859375, \"width\": 10.442184448242188, \"height\": 23.376556396484375, \"color\": \"#FFFF00\"}, {\"page\": 14, \"x\": 177.753173828125, \"y\": 343.92657470703125, \"width\": 10.442184448242188, \"height\": 10.395111083984375, \"color\": \"#FFFF00\"}, {\"page\": 14, \"x\": 191.77349853515625, \"y\": 343.92718505859375, \"width\": 10.442184448242188, \"height\": 28.571746826171875, \"color\": \"#FFFF00\"}, {\"page\": 14, \"x\": 205.793701171875, \"y\": 343.92657470703125, \"width\": 10.442184448242188, \"height\": 2.59686279296875, \"color\": \"#FFFF00\"}, {\"page\": 14, \"x\": 219.81390380859375, \"y\": 343.92718505859375, \"width\": 10.442184448242188, \"height\": 12.990570068359375, \"color\": \"#FFFF00\"}, {\"page\": 14, \"x\": 233.83424377441406, \"y\": 343.92657470703125, \"width\": 10.442184448242188, \"height\": 9.34686279296875, \"color\": \"#FFFF00\"}, {\"page\": 14, \"x\": 247.85507202148438, \"y\": 343.92657470703125, \"width\": 10.442169189453125, \"height\": 44.6793212890625, \"color\": \"#FFFF00\"}, {\"page\": 14, \"x\": 261.8752746582031, \"y\": 343.92718505859375, \"width\": 10.442169189453125, \"height\": 27.5372314453125, \"color\": \"#FFFF00\"}, {\"page\": 14, \"x\": 275.8955993652344, \"y\": 343.92657470703125, \"width\": 10.442169189453125, \"height\": 10.395111083984375, \"color\": \"#FFFF00\"}, {\"page\": 14, \"x\": 289.9158020019531, \"y\": 343.92718505859375, \"width\": 10.442169189453125, \"height\": 14.542144775390625, \"color\": \"#FFFF00\"}, {\"page\": 14, \"x\": 303.9360046386719, \"y\": 343.92657470703125, \"width\": 10.442169189453125, \"height\": 3.112579345703125, \"color\": \"#FFFF00\"}, {\"page\": 14, \"x\": 317.9563293457031, \"y\": 343.92657470703125, \"width\": 10.442169189453125, \"height\": 14.543701171875, \"color\": \"#FFFF00\"}, {\"page\": 14, \"x\": 331.9772033691406, \"y\": 343.92718505859375, \"width\": 10.442169189453125, \"height\": 6.748443603515625, \"color\": \"#FFFF00\"}, {\"page\": 14, \"x\": 345.99737548828125, \"y\": 343.92657470703125, \"width\": 10.442169189453125, \"height\": 19.738983154296875, \"color\": \"#FFFF00\"}, {\"page\": 14, \"x\": 360.0177001953125, \"y\": 343.92718505859375, \"width\": 10.442169189453125, \"height\": 11.94671630859375, \"color\": \"#FFFF00\"}, {\"page\": 14, \"x\": 374.0379333496094, \"y\": 343.92657470703125, \"width\": 10.442169189453125, \"height\": 13.507598876953125, \"color\": \"#FFFF00\"}, {\"page\": 14, \"x\": 388.0582580566406, \"y\": 343.92596435546875, \"width\": 10.442169189453125, \"height\": 31.6778564453125, \"color\": \"#FFFF00\"}, {\"page\": 14, \"x\": 402.0784606933594, \"y\": 343.92718505859375, \"width\": 10.442169189453125, \"height\": 2.59686279296875, \"color\": \"#FFFF00\"}, {\"page\": 14, \"x\": 416.0992736816406, \"y\": 343.9278259277344, \"width\": 10.442169189453125, \"height\": 7.27325439453125, \"color\": \"#FFFF00\"}, {\"page\": 14, \"x\": 430.11962890625, \"y\": 343.92718505859375, \"width\": 10.442169189453125, \"height\": 12.459381103515625, \"color\": \"#FFFF00\"}, {\"page\": 14, \"x\": 444.1398010253906, \"y\": 343.92657470703125, \"width\": 10.442169189453125, \"height\": 30.135650634765625, \"color\": \"#FFFF00\"}, {\"page\": 14, \"x\": 458.159423828125, \"y\": 343.92596435546875, \"width\": 10.442169189453125, \"height\": 2.59686279296875, \"color\": \"#FFFF00\"}, {\"page\": 14, \"x\": 472.18035888671875, \"y\": 343.92657470703125, \"width\": 10.442169189453125, \"height\": 30.657501220703125, \"color\": \"#FFFF00\"}, {\"page\": 14, \"x\": 486.201171875, \"y\": 343.9278259277344, \"width\": 10.442169189453125, \"height\": 26.50750732421875, \"color\": \"#FFFF00\"}, {\"page\": 14, \"x\": 121.6716079711914, \"y\": 230.61358642578125, \"width\": 10.442176818847656, \"height\": 16.10601806640625, \"color\": \"#FFFF00\"}, {\"page\": 14, \"x\": 135.69180297851562, \"y\": 229.5726318359375, \"width\": 10.442184448242188, \"height\": 17.1436767578125, \"color\": \"#FFFF00\"}, {\"page\": 14, \"x\": 149.71214294433594, \"y\": 233.73834228515625, \"width\": 10.442184448242188, \"height\": 12.9749755859375, \"color\": \"#FFFF00\"}, {\"page\": 14, \"x\": 163.73297119140625, \"y\": 223.33819580078125, \"width\": 10.442184448242188, \"height\": 23.37652587890625, \"color\": \"#FFFF00\"}, {\"page\": 14, \"x\": 177.753173828125, \"y\": 236.322265625, \"width\": 10.442184448242188, \"height\": 10.3951416015625, \"color\": \"#FFFF00\"}, {\"page\": 14, \"x\": 191.77349853515625, \"y\": 218.14471435546875, \"width\": 10.442184448242188, \"height\": 28.57177734375, \"color\": \"#FFFF00\"}, {\"page\": 14, \"x\": 205.793701171875, \"y\": 244.12213134765625, \"width\": 10.442184448242188, \"height\": 2.59686279296875, \"color\": \"#FFFF00\"}, {\"page\": 14, \"x\": 219.81390380859375, \"y\": 233.7249755859375, \"width\": 10.442184448242188, \"height\": 12.9906005859375, \"color\": \"#FFFF00\"}, {\"page\": 14, \"x\": 233.83424377441406, \"y\": 237.372314453125, \"width\": 10.442184448242188, \"height\": 9.34686279296875, \"color\": \"#FFFF00\"}, {\"page\": 14, \"x\": 247.85507202148438, \"y\": 202.02978515625, \"width\": 10.442169189453125, \"height\": 44.6793212890625, \"color\": \"#FFFF00\"}, {\"page\": 14, \"x\": 261.8752746582031, \"y\": 219.17596435546875, \"width\": 10.442169189453125, \"height\": 27.5372314453125, \"color\": \"#FFFF00\"}, {\"page\": 14, \"x\": 275.8955993652344, \"y\": 236.322265625, \"width\": 10.442169189453125, \"height\": 10.3951416015625, \"color\": \"#FFFF00\"}, {\"page\": 14, \"x\": 289.9158020019531, \"y\": 232.17291259765625, \"width\": 10.442169189453125, \"height\": 14.5421142578125, \"color\": \"#FFFF00\"}, {\"page\": 14, \"x\": 303.9360046386719, \"y\": 243.60614013671875, \"width\": 10.442169189453125, \"height\": 3.112548828125, \"color\": \"#FFFF00\"}, {\"page\": 14, \"x\": 317.95697021484375, \"y\": 232.17474365234375, \"width\": 10.442169189453125, \"height\": 14.543701171875, \"color\": \"#FFFF00\"}, {\"page\": 14, \"x\": 331.9772033691406, \"y\": 239.9691162109375, \"width\": 10.442169189453125, \"height\": 6.7484130859375, \"color\": \"#FFFF00\"}, {\"page\": 14, \"x\": 345.99737548828125, \"y\": 226.9752197265625, \"width\": 10.442169189453125, \"height\": 19.73895263671875, \"color\": \"#FFFF00\"}, {\"page\": 14, \"x\": 360.0177001953125, \"y\": 234.76959228515625, \"width\": 10.442169189453125, \"height\": 11.9466552734375, \"color\": \"#FFFF00\"}, {\"page\": 14, \"x\": 374.0379333496094, \"y\": 233.20965576171875, \"width\": 10.442169189453125, \"height\": 13.507568359375, \"color\": \"#FFFF00\"}, {\"page\": 14, \"x\": 388.0582580566406, \"y\": 215.03704833984375, \"width\": 10.442169189453125, \"height\": 31.6778564453125, \"color\": \"#FFFF00\"}, {\"page\": 14, \"x\": 402.0790710449219, \"y\": 244.12213134765625, \"width\": 10.442169189453125, \"height\": 2.59686279296875, \"color\": \"#FFFF00\"}, {\"page\": 14, \"x\": 416.0992736816406, \"y\": 239.44403076171875, \"width\": 10.442169189453125, \"height\": 7.27325439453125, \"color\": \"#FFFF00\"}, {\"page\": 14, \"x\": 430.11962890625, \"y\": 234.258544921875, \"width\": 10.442169189453125, \"height\": 12.4593505859375, \"color\": \"#FFFF00\"}, {\"page\": 14, \"x\": 444.1398010253906, \"y\": 216.574462890625, \"width\": 10.442169189453125, \"height\": 30.1356201171875, \"color\": \"#FFFF00\"}, {\"page\": 14, \"x\": 458.159423828125, \"y\": 244.12274169921875, \"width\": 10.442169189453125, \"height\": 2.59686279296875, \"color\": \"#FFFF00\"}, {\"page\": 14, \"x\": 472.18035888671875, \"y\": 216.06341552734375, \"width\": 10.442169189453125, \"height\": 30.65753173828125, \"color\": \"#FFFF00\"}, {\"page\": 14, \"x\": 486.201171875, \"y\": 220.20672607421875, \"width\": 10.442169189453125, \"height\": 26.507568359375, \"color\": \"#FFFF00\"}, {\"page\": 14, \"x\": 108.0, \"y\": 179.2464599609375, \"width\": 395.9974365234375, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 14, \"x\": 108.0, \"y\": 168.33746337890625, \"width\": 396.0014953613281, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 14, \"x\": 108.0, \"y\": 157.42742919921875, \"width\": 269.2591552734375, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}, {\"page\": 14, \"x\": 301.01898193359375, \"y\": 39.31243896484375, \"width\": 9.96258544921875, \"height\": 12.00494384765625, \"color\": \"#FFFF00\"}]"}, "type": "Document"}
